{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f90048-1997-4fae-8b04-802c7cac2cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99902839-b5f5-468d-9001-eb6da6f63cc1",
   "metadata": {},
   "source": [
    "# 파일 불러오기\n",
    "- 날짜 없는 원본 파일 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cabc4285-a175-4e58-af80-963485adf376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_Now</th>\n",
       "      <th>Blanking_Util</th>\n",
       "      <th>Blanking_SKU1_Queue</th>\n",
       "      <th>Blanking_SKU2_Queue</th>\n",
       "      <th>Blanking_SKU3_Queue</th>\n",
       "      <th>Blanking_SKU4_Queue</th>\n",
       "      <th>Press1_Util</th>\n",
       "      <th>Press2_Util</th>\n",
       "      <th>Press3_Util</th>\n",
       "      <th>Press4_Util</th>\n",
       "      <th>...</th>\n",
       "      <th>SKU3_NVA_Time</th>\n",
       "      <th>SKU3_Transport_Time</th>\n",
       "      <th>SKU3_Wait_Time</th>\n",
       "      <th>SKU3_Other_Time</th>\n",
       "      <th>SKU4_VA_Time</th>\n",
       "      <th>SKU4_NVA_Time</th>\n",
       "      <th>SKU4_Transport_Time</th>\n",
       "      <th>SKU4_Wait_Time</th>\n",
       "      <th>SKU4_Other_Time</th>\n",
       "      <th>Blanking_Queue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>0.846367</td>\n",
       "      <td>0.045715</td>\n",
       "      <td>0.056373</td>\n",
       "      <td>0.055737</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.410297</td>\n",
       "      <td>0.434561</td>\n",
       "      <td>0.481388</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537617</td>\n",
       "      <td>0.453650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536243</td>\n",
       "      <td>0.473453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.361452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>0.851097</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>0.052934</td>\n",
       "      <td>0.038512</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>0.455471</td>\n",
       "      <td>0.454445</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.442986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536764</td>\n",
       "      <td>0.473677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534992</td>\n",
       "      <td>0.464380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.830599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0.846115</td>\n",
       "      <td>0.052210</td>\n",
       "      <td>0.047499</td>\n",
       "      <td>0.043181</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.496717</td>\n",
       "      <td>0.450816</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.352829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535925</td>\n",
       "      <td>0.424090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535077</td>\n",
       "      <td>0.475330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.365867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>0.841306</td>\n",
       "      <td>0.051769</td>\n",
       "      <td>0.035436</td>\n",
       "      <td>0.046788</td>\n",
       "      <td>0.052362</td>\n",
       "      <td>0.433749</td>\n",
       "      <td>0.363004</td>\n",
       "      <td>0.443909</td>\n",
       "      <td>0.456036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535232</td>\n",
       "      <td>0.430992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533233</td>\n",
       "      <td>0.463801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.698528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0.859599</td>\n",
       "      <td>0.045874</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>0.044507</td>\n",
       "      <td>0.057210</td>\n",
       "      <td>0.418329</td>\n",
       "      <td>0.396826</td>\n",
       "      <td>0.499273</td>\n",
       "      <td>0.472454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538142</td>\n",
       "      <td>0.502614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537223</td>\n",
       "      <td>0.449320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.784631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time_Now  Blanking_Util  Blanking_SKU1_Queue  Blanking_SKU2_Queue  \\\n",
       "0        24       0.846367             0.045715             0.056373   \n",
       "1        24       0.851097             0.051937             0.052934   \n",
       "2        24       0.846115             0.052210             0.047499   \n",
       "3        24       0.841306             0.051769             0.035436   \n",
       "4        24       0.859599             0.045874             0.046802   \n",
       "\n",
       "   Blanking_SKU3_Queue  Blanking_SKU4_Queue  Press1_Util  Press2_Util  \\\n",
       "0             0.055737             0.035849     0.410297     0.434561   \n",
       "1             0.038512             0.042248     0.455471     0.454445   \n",
       "2             0.043181             0.040979     0.496717     0.450816   \n",
       "3             0.046788             0.052362     0.433749     0.363004   \n",
       "4             0.044507             0.057210     0.418329     0.396826   \n",
       "\n",
       "   Press3_Util  Press4_Util  ...  SKU3_NVA_Time  SKU3_Transport_Time  \\\n",
       "0     0.481388     0.399992  ...            0.0             0.537617   \n",
       "1     0.387975     0.442986  ...            0.0             0.536764   \n",
       "2     0.417308     0.352829  ...            0.0             0.535925   \n",
       "3     0.443909     0.456036  ...            0.0             0.535232   \n",
       "4     0.499273     0.472454  ...            0.0             0.538142   \n",
       "\n",
       "   SKU3_Wait_Time  SKU3_Other_Time  SKU4_VA_Time  SKU4_NVA_Time  \\\n",
       "0        0.453650              0.0      1.523338            0.0   \n",
       "1        0.473677              0.0      1.523344            0.0   \n",
       "2        0.424090              0.0      1.523403            0.0   \n",
       "3        0.430992              0.0      1.523381            0.0   \n",
       "4        0.502614              0.0      1.523363            0.0   \n",
       "\n",
       "   SKU4_Transport_Time  SKU4_Wait_Time  SKU4_Other_Time  Blanking_Queue  \n",
       "0             0.536243        0.473453              0.0       58.361452  \n",
       "1             0.534992        0.464380              0.0       62.830599  \n",
       "2             0.535077        0.475330              0.0       59.365867  \n",
       "3             0.533233        0.463801              0.0       56.698528  \n",
       "4             0.537223        0.449320              0.0       65.784631  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"./Final Results Extended.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb967fc-51e3-4e5d-88d6-5fd6eae2e2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a21236e6-bd74-4190-8f77-73451e7069fe",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26583c78-b2d2-41d7-89ad-0a1c4202bb93",
   "metadata": {},
   "source": [
    "## 상수컬럼 및 전부 0인 컬럼 제거\n",
    "- Time_Now에 동일한 24 값 -> 제거\n",
    "- 결과적으로 22개 컬럼 제거\n",
    "- Queue 변수 중 제거된 거 : 'Paint1_Queue', 'Paint2_Queue', 'Cell1_Queue', 'Cell2_Queue', 'Cell3_Queue', 'Cell4_Queue'\n",
    "- Cell별 SKU 생산량 변수 중 제거된 거 : 'c_Cell1_SKU3', 'c_Cell2_SKU1', 'c_Cell2_SKU3', 'c_Cell3_SKU1', 'c_Cell3_SKU4', 'c_Cell4_SKU1', 'c_Cell4_SKU2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc04b5d6-3f56-43a8-8d5b-5a959b8c52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑 제거 대상 컬럼 수: 22개\n",
      "['Paint1_Queue', 'c_Cell4__SKU2', 'Cell3_Queue', 'Cell4_Queue', 'Time_Now', 'c_Cell3__SKU1', 'SKU2_Other_Time', 'SKU2_NVA_Time', 'c_Cell2__SKU1', 'SKU3_Other_Time', 'Cell1_Queue', 'SKU4_Other_Time', 'SKU1_Other_Time', 'SKU4_NVA_Time', 'SKU3_NVA_Time', 'Cell2_Queue', 'Paint2_Queue', 'c_Cell3__SKU4', 'c_Cell1__SKU3', 'c_Cell2__SKU3', 'SKU1_NVA_Time', 'c_Cell4__SKU1']\n",
      "✅ 제거 후 컬럼 수: 56\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1. 상수컬럼 및 전부 0인 컬럼 제거\n",
    "# =========================\n",
    "\n",
    "# (1) 상수컬럼: 데이터가 모두 같은 값인 컬럼\n",
    "const_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "\n",
    "# (2) 전부 0인 컬럼\n",
    "zero_cols = [col for col in df.columns if (df[col] == 0).all()]\n",
    "\n",
    "# 합치기 (중복 제거)\n",
    "drop_cols = list(set(const_cols + zero_cols))\n",
    "\n",
    "print(f\"🗑 제거 대상 컬럼 수: {len(drop_cols)}개\")\n",
    "print(drop_cols)\n",
    "\n",
    "# 실제 제거\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "print(f\"✅ 제거 후 컬럼 수: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea35f3-73f7-4d62-a594-5bdd912ae28a",
   "metadata": {},
   "source": [
    "## 결측치 확인 -> 1~3개씩 존재 => 해당 행 drop (행 3개 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c20fe5-bb9b-4ed3-ac8b-9b291bb04cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 결측치 요약:\n",
      "Blanking_SKU4_Queue        1\n",
      "Press1_Util                1\n",
      "Press2_Util                1\n",
      "Press3_Util                1\n",
      "Press4_Util                1\n",
      "Press1_Queue               1\n",
      "Press2_Queue               1\n",
      "Press3_Queue               1\n",
      "Press4_Queue               1\n",
      "Cell1_Util                 1\n",
      "Cell2_Util                 1\n",
      "Cell3_Util                 1\n",
      "Cell4_Util                 1\n",
      "Warehouse1_Queue           1\n",
      "Warehouse_2_Queue          1\n",
      "Warehouse_3_Queue          1\n",
      "Warehouse_4_Queue          1\n",
      "c_Cycle1                   1\n",
      "c_Cycle2                   1\n",
      "c_Cycle3                   1\n",
      "c_Cycle4                   1\n",
      "c_Cell1_SKU1               1\n",
      "c_Cell1__SKU2              1\n",
      "c_Cell1__SKU4              1\n",
      "c_Cell2__SKU2              1\n",
      "c_Cell2__SKU4              1\n",
      "c_Cell3__SKU2              1\n",
      "c_Cell3__SKU3              1\n",
      "c_Cell4__SKU3              1\n",
      "c_Cell4__SKU4              1\n",
      "Paint1_Util                1\n",
      "Paint2_Util                1\n",
      "Quality_Util               1\n",
      "Quality_Queue              1\n",
      "Forklift_Util              1\n",
      "Forklift_Blanking_Queue    1\n",
      "Forklift_Press_Queue       1\n",
      "Forklift_Assembly_Queue    1\n",
      "c_TotalProducts            1\n",
      "SKU1_VA_Time               1\n",
      "SKU1_Transport_Time        2\n",
      "SKU1_Wait_Time             3\n",
      "SKU2_VA_Time               3\n",
      "SKU2_Transport_Time        3\n",
      "SKU2_Wait_Time             3\n",
      "SKU3_VA_Time               3\n",
      "SKU3_Transport_Time        3\n",
      "SKU3_Wait_Time             3\n",
      "SKU4_VA_Time               3\n",
      "SKU4_Transport_Time        3\n",
      "SKU4_Wait_Time             3\n",
      "Blanking_Queue             3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 2. 결측치 확인\n",
    "# =========================\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0]\n",
    "\n",
    "if missing_summary.empty:\n",
    "    print(\"✅ 결측치 없음\")\n",
    "else:\n",
    "    print(\"⚠️ 결측치 요약:\")\n",
    "    print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e9eba4-cafd-4a07-a6f6-fd352b574dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 결측치가 있는 행 3개 제거 완료 (남은 행: 132673)\n",
      "\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3. 결측치 제거\n",
    "# =========================\n",
    "if not missing_summary.empty:\n",
    "    before = df.shape[0]\n",
    "    df = df.dropna()  # 결측치가 하나라도 있는 행 제거\n",
    "    after = df.shape[0]\n",
    "    print(f\"✅ 결측치가 있는 행 {before - after}개 제거 완료 (남은 행: {after})\")\n",
    "\n",
    "print()\n",
    "missing_summary2 = df.isnull().sum()\n",
    "missing_summary2 = missing_summary2[missing_summary2 > 0]\n",
    "print(missing_summary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57289df3-3796-4915-8864-56d95db7cf45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79615a1-baf7-4108-bb56-28bbf12efcf2",
   "metadata": {},
   "source": [
    "# Warehouse Queue -> 네이밍을 Cell Queue 로 변경 (with 넘버링 매핑)\n",
    "- 이름 변경 매핑: {'Warehouse1_Queue': 'Cell1_Queue', 'Warehouse_2_Queue': 'Cell2_Queue', 'Warehouse_3_Queue': 'Cell3_Queue', 'Warehouse_4_Queue': 'Cell4_Queue'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095d67f7-7159-459a-88f0-b6ef0385b8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse Queue cols: ['Warehouse1_Queue', 'Warehouse_2_Queue', 'Warehouse_3_Queue', 'Warehouse_4_Queue']\n",
      "✅ 이름 변경 매핑: {'Warehouse1_Queue': 'Cell1_Queue', 'Warehouse_2_Queue': 'Cell2_Queue', 'Warehouse_3_Queue': 'Cell3_Queue', 'Warehouse_4_Queue': 'Cell4_Queue'}\n",
      "변경 후 Queue 관련 컬럼: ['Blanking_SKU1_Queue', 'Blanking_SKU2_Queue', 'Blanking_SKU3_Queue', 'Blanking_SKU4_Queue', 'Press1_Queue', 'Press2_Queue', 'Press3_Queue', 'Press4_Queue', 'Cell1_Queue', 'Cell2_Queue', 'Cell3_Queue', 'Cell4_Queue', 'Quality_Queue', 'Forklift_Blanking_Queue', 'Forklift_Press_Queue', 'Forklift_Assembly_Queue', 'Blanking_Queue']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Warehouse Queue 컬럼 찾기\n",
    "# =========================\n",
    "warehouse_cols = [c for c in df.columns if \"warehouse\" in c.lower() and \"queue\" in c.lower()]\n",
    "print(\"Warehouse Queue cols:\", warehouse_cols)\n",
    "\n",
    "# =========================\n",
    "# 2) Warehouse 번호 → Cell 번호로 변환\n",
    "# =========================\n",
    "rename_map = {}\n",
    "for w in warehouse_cols:\n",
    "    # 숫자 추출 (예: Warehouse1_Queue → 1)\n",
    "    num = ''.join(filter(str.isdigit, w))\n",
    "    if num:\n",
    "        new_name = f\"Cell{num}_Queue\"\n",
    "        rename_map[w] = new_name\n",
    "\n",
    "# =========================\n",
    "# 3) 컬럼명 변경\n",
    "# =========================\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "print(\"✅ 이름 변경 매핑:\", rename_map)\n",
    "print(\"변경 후 Queue 관련 컬럼:\", [c for c in df.columns if \"queue\" in c.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd543ca4-2604-4edf-80e9-5d1122e0d354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7641e6e2-21fd-4d74-80a1-a0a157b83625",
   "metadata": {},
   "source": [
    "# Target 컬럼 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f03179-0f0e-403e-92fc-97162f8a0dda",
   "metadata": {},
   "source": [
    "## 전체 기준 병목 파악 -> 새 컬럼에 추가 (Bottleneck_actual , Bottleneck_actual_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d963b2a-8d65-43ea-b2e6-dc278222745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue 관련 컬럼 수: 17\n",
      "['Blanking_SKU1_Queue', 'Blanking_SKU2_Queue', 'Blanking_SKU3_Queue', 'Blanking_SKU4_Queue', 'Press1_Queue', 'Press2_Queue', 'Press3_Queue', 'Press4_Queue', 'Cell1_Queue', 'Cell2_Queue']\n",
      "              Bottleneck_actual  Bottleneck_val\n",
      "132670  Forklift_Blanking_Queue      153.012984\n",
      "132671              Cell1_Queue      185.031493\n",
      "132672              Cell1_Queue      302.349198\n",
      "132673              Cell1_Queue      295.667368\n",
      "132674              Cell1_Queue      166.628981\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Queue 컬럼 찾기 (대소문자 무시)\n",
    "# =========================\n",
    "queue_cols = [col for col in df.columns if \"queue\" in col.lower()]\n",
    "\n",
    "print(f\"Queue 관련 컬럼 수: {len(queue_cols)}\")\n",
    "print(queue_cols[:10])  # 앞 10개만 확인\n",
    "\n",
    "# =========================\n",
    "# 2) 병목 공정 컬럼 생성\n",
    "# =========================\n",
    "# 각 행에서 queue 값이 가장 큰 컬럼명\n",
    "df[\"Bottleneck_actual\"] = df[queue_cols].idxmax(axis=1)\n",
    "\n",
    "# 해당 queue의 실제 최대값도 같이 기록하고 싶다면\n",
    "df[\"Bottleneck_val\"] = df[queue_cols].max(axis=1)\n",
    "\n",
    "# =========================\n",
    "# 3) 결과 확인\n",
    "# =========================\n",
    "print(df[[\"Bottleneck_actual\", \"Bottleneck_val\"]].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589409bc-252c-4c50-a9d7-5f26eb9f9556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck_actual\n",
       "Cell1_Queue                77629\n",
       "Forklift_Blanking_Queue    53681\n",
       "Cell3_Queue                 1307\n",
       "Cell4_Queue                   36\n",
       "Forklift_Press_Queue           9\n",
       "Press4_Queue                   6\n",
       "Press2_Queue                   5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bottleneck 컬럼의 빈도 계산\n",
    "bottleneck_counts = df[\"Bottleneck_actual\"].value_counts().head(10)\n",
    "\n",
    "bottleneck_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426fd05-4efd-4b15-a349-209a14f0181b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c685ddab-8ac2-4f5d-a11a-317d5298b51f",
   "metadata": {},
   "source": [
    "## 주요 공정 단계(블랭킹, 프레스, 조립셀) 기준 병목 파악 -> 새 컬럼에 추가\n",
    "- Bottleneck_actual_Blanking , Bottleneck_actual_Press , Bottleneck_actual_Cell\n",
    "- Bottleneck_val_Blanking , Bottleneck_val_Press , Bottleneck_val_Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a117a4aa-9ff0-4e85-b14b-1eaaddda3807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Bottleneck_actual  Bottleneck_val Bottleneck_actual_Blanking  \\\n",
      "0  Forklift_Blanking_Queue      157.256741        Blanking_SKU2_Queue   \n",
      "1  Forklift_Blanking_Queue      166.488725        Blanking_SKU2_Queue   \n",
      "2              Cell1_Queue      335.401556        Blanking_SKU1_Queue   \n",
      "3  Forklift_Blanking_Queue      147.448407        Blanking_SKU4_Queue   \n",
      "4  Forklift_Blanking_Queue      150.397600        Blanking_SKU4_Queue   \n",
      "\n",
      "   Bottleneck_val_Blanking Bottleneck_actual_Press  Bottleneck_val_Press  \\\n",
      "0                 0.056373            Press2_Queue             65.273786   \n",
      "1                 0.052934            Press1_Queue             74.772823   \n",
      "2                 0.052210            Press2_Queue             72.901066   \n",
      "3                 0.052362            Press1_Queue             65.091192   \n",
      "4                 0.057210            Press1_Queue             65.075312   \n",
      "\n",
      "  Bottleneck_actual_Cell  Bottleneck_val_Cell  \n",
      "0            Cell1_Queue            98.155568  \n",
      "1            Cell1_Queue           162.632374  \n",
      "2            Cell1_Queue           335.401556  \n",
      "3            Cell1_Queue           112.173074  \n",
      "4            Cell1_Queue           107.982827  \n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 11. 공정별 실제 병목 레이블 & 값 생성\n",
    "# ================================\n",
    "stage_groups = {\n",
    "    \"Blanking\": [\"Blanking_SKU1_Queue\", \"Blanking_SKU2_Queue\",\n",
    "                 \"Blanking_SKU3_Queue\", \"Blanking_SKU4_Queue\"],\n",
    "    \"Press\":    [\"Press1_Queue\", \"Press2_Queue\", \"Press3_Queue\", \"Press4_Queue\"],\n",
    "    \"Cell\":     [\"Cell1_Queue\", \"Cell2_Queue\", \"Cell3_Queue\", \"Cell4_Queue\"]\n",
    "}\n",
    "\n",
    "for stage, cols in stage_groups.items():\n",
    "    # 병목 컬럼명 (어느 라인/설비가 병목인지)\n",
    "    df[f\"Bottleneck_actual_{stage}\"] = df[cols].idxmax(axis=1)\n",
    "    # 병목 값 (queue 크기)\n",
    "    df[f\"Bottleneck_val_{stage}\"] = df[cols].max(axis=1)\n",
    "\n",
    "# ================================\n",
    "# 12. 결과 확인\n",
    "# ================================\n",
    "check_cols = [c for c in df.columns if c.startswith(\"Bottleneck_\")]\n",
    "print(df[check_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0e538-b06c-4f0c-8af2-54b12664feed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550760c-34f9-4bc7-a772-6e9362c7580d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bae1ba67-7dc8-41e2-b4f3-78e37533aa42",
   "metadata": {},
   "source": [
    "## 제품군(SKU) 기준 병목 파악 -> 새 컬럼에 추가\n",
    "- Bottleneck_actual_SKU1 , Bottleneck_actual_SKU2 , Bottleneck_actual_SKU3 , Bottleneck_actual_SKU4\n",
    "- Bottleneck_val_SKU1 , Bottleneck_val_SKU2 , Bottleneck_val_SKU3, Bottleneck_val_SKU4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783807f3-4dce-4614-a65e-3ad7f6370c75",
   "metadata": {},
   "source": [
    "### 컬럼명 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "646105d1-ea4a-4d17-81c9-0084d51e71ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKU1 ['c_Cell1_SKU1']\n",
      "SKU2 ['c_Cell1_SKU2', 'c_Cell2_SKU2', 'c_Cell3_SKU2']\n",
      "SKU3 ['c_Cell3_SKU3', 'c_Cell4_SKU3']\n",
      "SKU4 ['c_Cell1_SKU4', 'c_Cell2_SKU4', 'c_Cell4_SKU4']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 컬럼명 정규화: 언더스코어 여러 개 → 1개로 통일\n",
    "# =========================\n",
    "df.columns = df.columns.str.replace(r\"__+\", \"_\", regex=True)\n",
    "\n",
    "# 확인\n",
    "for sku in [\"SKU1\",\"SKU2\",\"SKU3\",\"SKU4\"]:\n",
    "    related_cols = [c for c in df.columns if f\"Cell\" in c and sku in c]\n",
    "    print(sku, related_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada261e-e478-494c-b62a-85a522958f8d",
   "metadata": {},
   "source": [
    "### 조립셀 Queue 값 -> SKU별로 분배\n",
    "- 각 Cell Queue 전체량을 SKU별 담당 비율에 따라 나눠서, SKU별 Cell Queue를 생성 -> SKU별로 여러 Cell에서 받은 몫을 합쳐 최종 SKU Cell Queue를 계산\n",
    "- 각 행에 대해 동적으로 SKU별 분배 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb147a1-927e-4301-8b31-0594494d3756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKU1 ['c_Cell1_SKU1']\n",
      "SKU2 ['c_Cell1_SKU2', 'c_Cell2_SKU2', 'c_Cell3_SKU2']\n",
      "SKU3 ['c_Cell3_SKU3', 'c_Cell4_SKU3']\n",
      "SKU4 ['c_Cell1_SKU4', 'c_Cell2_SKU4', 'c_Cell4_SKU4']\n"
     ]
    }
   ],
   "source": [
    "for sku in [\"SKU1\",\"SKU2\",\"SKU3\",\"SKU4\"]:\n",
    "    related_cols = [c for c in df.columns if f\"_{sku}\" in c and \"c_Cell\" in c]\n",
    "    print(sku, related_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf64e3f8-c547-4ba7-b3ff-41ba37e33253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SKU별로 분배된 Cell Queue (앞부분 10행) ===\n",
      "   Cell_SKU1_Queue  Cell_SKU2_Queue  Cell_SKU3_Queue  Cell_SKU4_Queue\n",
      "0     1.370939e+06     1.192535e+06     1.247366e+06     8.856453e+05\n",
      "1     2.451033e+06     1.958747e+06     9.126624e+05     1.182048e+06\n",
      "2     5.568672e+06     3.817909e+06     9.283182e+05     1.242360e+06\n",
      "3     1.647598e+06     1.114051e+06     1.090078e+06     1.048065e+06\n",
      "4     1.553549e+06     1.232362e+06     1.476219e+06     1.102118e+06\n",
      "5     2.101007e+06     1.931448e+06     1.167199e+06     1.028449e+06\n",
      "6     1.851074e+06     1.886183e+06     6.287604e+05     8.966812e+05\n",
      "7     2.972045e+06     2.248654e+06     1.170633e+06     1.487739e+06\n",
      "8     5.720726e+06     4.591313e+06     9.949638e+05     1.545606e+06\n",
      "9     5.471222e+06     3.388148e+06     7.908985e+05     1.160693e+06\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 2. SKU 경로 정의\n",
    "# ================================\n",
    "sku_paths = {\n",
    "    \"SKU1\": {\"blanking\": \"Blanking_SKU1_Queue\",\"press\": \"Press1_Queue\"},\n",
    "    \"SKU2\": {\"blanking\": \"Blanking_SKU2_Queue\",\"press\": \"Press2_Queue\"},\n",
    "    \"SKU3\": {\"blanking\": \"Blanking_SKU3_Queue\",\"press\": \"Press3_Queue\"},\n",
    "    \"SKU4\": {\"blanking\": \"Blanking_SKU4_Queue\",\"press\": \"Press4_Queue\"},\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# 3. Cell → SKU 비율 기반 분배\n",
    "# ================================\n",
    "sku_cell_vals = {sku: pd.Series(0, index=df.index) for sku in sku_paths}\n",
    "\n",
    "for cell_num in range(1, 5):  # Cell1 ~ Cell4\n",
    "    cell_col = f\"Cell{cell_num}_Queue\"\n",
    "    \n",
    "    if cell_col not in df.columns:\n",
    "        continue\n",
    "    \n",
    "    # 해당 Cell Queue 값\n",
    "    cell_vals = df[cell_col]\n",
    "    \n",
    "    for sku in sku_paths.keys():\n",
    "        ratio_col = f\"c_Cell{cell_num}_{sku}\"\n",
    "        if ratio_col in df.columns:\n",
    "            # SKU별 Cell Queue = Cell Queue × 비율\n",
    "            sku_cell_vals[sku] += cell_vals * df[ratio_col]\n",
    "\n",
    "# ================================\n",
    "# 4. 결과 DataFrame 구성 (컬럼명 변경)\n",
    "# ================================\n",
    "sku_cell_df = pd.DataFrame({\n",
    "    f\"Cell_{sku}_Queue\": vals for sku, vals in sku_cell_vals.items()\n",
    "})\n",
    "\n",
    "print(\"=== SKU별로 분배된 Cell Queue (앞부분 10행) ===\")\n",
    "print(sku_cell_df.head(10))\n",
    "\n",
    "# 원래 df에 붙이고 싶다면:\n",
    "df = pd.concat([df, sku_cell_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a574f272-8b18-42a1-b34e-693b09b2a537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Bottleneck_actual_Blanking Bottleneck_actual_Press Bottleneck_actual_Cell  \\\n",
      "0        Blanking_SKU2_Queue            Press2_Queue            Cell1_Queue   \n",
      "1        Blanking_SKU2_Queue            Press1_Queue            Cell1_Queue   \n",
      "2        Blanking_SKU1_Queue            Press2_Queue            Cell1_Queue   \n",
      "3        Blanking_SKU4_Queue            Press1_Queue            Cell1_Queue   \n",
      "4        Blanking_SKU4_Queue            Press1_Queue            Cell1_Queue   \n",
      "\n",
      "  Bottleneck_actual_SKU1 Bottleneck_actual_SKU2 Bottleneck_actual_SKU3  \\\n",
      "0                   Cell                   Cell                   Cell   \n",
      "1                   Cell                   Cell                   Cell   \n",
      "2                   Cell                   Cell                   Cell   \n",
      "3                   Cell                   Cell                   Cell   \n",
      "4                   Cell                   Cell                   Cell   \n",
      "\n",
      "  Bottleneck_actual_SKU4  \n",
      "0                   Cell  \n",
      "1                   Cell  \n",
      "2                   Cell  \n",
      "3                   Cell  \n",
      "4                   Cell  \n",
      "   Bottleneck_val_Blanking  Bottleneck_val_Press  Bottleneck_val_Cell  \\\n",
      "0                 0.056373             65.273786            98.155568   \n",
      "1                 0.052934             74.772823           162.632374   \n",
      "2                 0.052210             72.901066           335.401556   \n",
      "3                 0.052362             65.091192           112.173074   \n",
      "4                 0.057210             65.075312           107.982827   \n",
      "\n",
      "   Bottleneck_val_SKU1  Bottleneck_val_SKU2  Bottleneck_val_SKU3  \\\n",
      "0         1.370939e+06         1.192535e+06         1.247366e+06   \n",
      "1         2.451033e+06         1.958747e+06         9.126624e+05   \n",
      "2         5.568672e+06         3.817909e+06         9.283182e+05   \n",
      "3         1.647598e+06         1.114051e+06         1.090078e+06   \n",
      "4         1.553549e+06         1.232362e+06         1.476219e+06   \n",
      "\n",
      "   Bottleneck_val_SKU4  \n",
      "0         8.856453e+05  \n",
      "1         1.182048e+06  \n",
      "2         1.242360e+06  \n",
      "3         1.048065e+06  \n",
      "4         1.102118e+06  \n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 7. SKU별 병목 공정 예측\n",
    "# ================================\n",
    "sku_paths = {\n",
    "    \"SKU1\": {\"blanking\": \"Blanking_SKU1_Queue\",\"press\": \"Press1_Queue\", \"cell\": \"Cell_SKU1_Queue\"},\n",
    "    \"SKU2\": {\"blanking\": \"Blanking_SKU2_Queue\",\"press\": \"Press2_Queue\", \"cell\": \"Cell_SKU2_Queue\"},\n",
    "    \"SKU3\": {\"blanking\": \"Blanking_SKU3_Queue\",\"press\": \"Press3_Queue\", \"cell\": \"Cell_SKU3_Queue\"},\n",
    "    \"SKU4\": {\"blanking\": \"Blanking_SKU4_Queue\",\"press\": \"Press4_Queue\", \"cell\": \"Cell_SKU4_Queue\"},\n",
    "}\n",
    "\n",
    "for sku, paths in sku_paths.items():\n",
    "    # 각 SKU별 병목 후보 Stage 값 모으기\n",
    "    stage_df = df[[paths[\"blanking\"], paths[\"press\"], paths[\"cell\"]]].copy()\n",
    "    stage_df.columns = [\"Blanking\", \"Press\", \"Cell\"]  # 축 이름 단순화\n",
    "    \n",
    "    # 각 시점별 최대값 컬럼명 → 병목 공정\n",
    "    df[f\"Bottleneck_actual_{sku}\"] = stage_df.idxmax(axis=1)\n",
    "\n",
    "    # 각 시점별 병목 수치 (최대값)\n",
    "    df[f\"Bottleneck_val_{sku}\"] = stage_df.max(axis=1)\n",
    "\n",
    "# ================================\n",
    "# 8. 결과 확인\n",
    "# ================================\n",
    "print(df[[c for c in df.columns if c.startswith(\"Bottleneck_actual_\")]].head())\n",
    "print(df[[c for c in df.columns if c.startswith(\"Bottleneck_val_\")]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c8c63-485d-45d1-b9c2-21b20184f680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cb5e3-28dd-4699-9535-c430564bb08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf0d42b4-fdb4-4259-829d-1c65132e0999",
   "metadata": {},
   "source": [
    "# 랜덤 분할 - Train 70 : Val 15 : Test 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff1c5fe1-a1eb-4351-be5c-6eac9832e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42, shuffle=True)\n",
    "# train_df, val_df = train_test_split(train_val_df, test_size=0.1765, random_state=42, shuffle=True)\n",
    "# # 0.1765 ≈ 15% / 85%\n",
    "\n",
    "# print(f\"Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b8de1fc-f4c7-408b-abe3-368a93af523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 저장 경로 지정 (원하는 폴더로 바꾸세요)\n",
    "# train_path = \"./bottleneck_train.csv\"\n",
    "# val_path   = \"./bottleneck_val.csv\"\n",
    "# test_path  = \"./bottleneck_test.csv\"\n",
    "\n",
    "# # CSV 저장 (인덱스 제외)\n",
    "# train_df.to_csv(train_path, index=False, encoding=\"utf-8-sig\")\n",
    "# val_df.to_csv(val_path, index=False, encoding=\"utf-8-sig\")\n",
    "# test_df.to_csv(test_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# print(\"✅ CSV 저장 완료\")\n",
    "# print(f\"Train → {train_path} ({train_df.shape})\")\n",
    "# print(f\"Val   → {val_path} ({val_df.shape})\")\n",
    "# print(f\"Test  → {test_path} ({test_df.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b88f8771-f8c9-419b-ba7a-2fd0fefde14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 불러오기 완료\n",
      "Train: (92867, 76) Val: (19905, 76) Test: (19901, 76)\n",
      "전체 df: (132673, 76)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 경로 지정\n",
    "train_path = \"./bottleneck_train.csv\"\n",
    "val_path   = \"./bottleneck_val.csv\"\n",
    "test_path  = \"./bottleneck_test.csv\"\n",
    "\n",
    "# 불러오기\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df   = pd.read_csv(val_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "# 하나로 합치고 싶으면\n",
    "df = pd.concat([train_df, val_df, test_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(\"✅ 불러오기 완료\")\n",
    "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape, \"Test:\", test_df.shape)\n",
    "print(\"전체 df:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8719fc-b556-42f7-baee-57b4058729c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f229ea7-345e-442e-9402-df353732501b",
   "metadata": {},
   "source": [
    "# 독립변수 분리\n",
    "- 전체 기준 병목 예측\n",
    "    - 분류 : Bottleneck_actual\n",
    "    - 회귀 : Bottleneck_actual_val \n",
    "- 공정 단계 기준 병목 예측\n",
    "    - 분류 : Bottleneck_actual_Blanking , Bottleneck_actual_Press , Bottleneck_actual_Cell\n",
    "    - 회귀 : Bottleneck_val_Blanking , Bottleneck_val_Press , Bottleneck_val_Cell \n",
    "- 제품군(SKU) 기준 병목 예측\n",
    "    - 분류 : Bottleneck_actual_SKU1 , Bottleneck_actual_SKU2 , Bottleneck_actual_SKU3 , Bottleneck_actual_SKU4\n",
    "    - 회귀 : Bottleneck_val_SKU1 , Bottleneck_val_SKU2 , Bottleneck_val_SKU3, Bottleneck_val_SKU4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e003e859-53b4-4b57-9e05-d0ecf253a2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 독립변수 컬럼 수: 60\n",
      "예시 컬럼: ['Blanking_Util', 'Blanking_SKU1_Queue', 'Blanking_SKU2_Queue', 'Blanking_SKU3_Queue', 'Blanking_SKU4_Queue', 'Press1_Util', 'Press2_Util', 'Press3_Util', 'Press4_Util', 'Press1_Queue']\n"
     ]
    }
   ],
   "source": [
    "# 타깃 후보 컬럼 전부 정리\n",
    "target_cols = [\n",
    "    # 전체 기준\n",
    "    \"Bottleneck_actual\", \"Bottleneck_val\",\n",
    "    # 공정 단계 기준\n",
    "    \"Bottleneck_actual_Blanking\", \"Bottleneck_actual_Press\", \"Bottleneck_actual_Cell\",\n",
    "    \"Bottleneck_val_Blanking\", \"Bottleneck_val_Press\", \"Bottleneck_val_Cell\",\n",
    "    # SKU 기준\n",
    "    \"Bottleneck_actual_SKU1\", \"Bottleneck_actual_SKU2\", \"Bottleneck_actual_SKU3\", \"Bottleneck_actual_SKU4\",\n",
    "    \"Bottleneck_val_SKU1\", \"Bottleneck_val_SKU2\", \"Bottleneck_val_SKU3\", \"Bottleneck_val_SKU4\"\n",
    "]\n",
    "\n",
    "# 독립변수(X)는 이 타깃 후보들을 제외한 것들만\n",
    "X_train = train_df.drop(columns=[c for c in target_cols if c in train_df.columns])\n",
    "X_val   = val_df.drop(columns=[c for c in target_cols if c in val_df.columns])\n",
    "X_test  = test_df.drop(columns=[c for c in target_cols if c in test_df.columns])\n",
    "\n",
    "print(\"✅ 독립변수 컬럼 수:\", X_train.shape[1])\n",
    "print(\"예시 컬럼:\", X_train.columns[:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04073411-c48c-490e-b3ed-6ff5d87340c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d40dcb-1926-488e-acae-90067c6e07f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfad498-c8c8-4d50-ada2-b63c1bf2027a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd5c128e-c802-4daf-9564-dbb70aefa138",
   "metadata": {},
   "source": [
    "# 전체 기준 병목 예측 모델링\n",
    "- 분류 : Bottleneck_actual\n",
    "- 회귀 : Bottleneck_actual_val "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58eca6d-e29e-41af-87db-9c0b7fe4832c",
   "metadata": {},
   "source": [
    "### 추가 처리\n",
    "- 트리 기반 모델(RandomForest, XGB) → 그대로 둠 (스케일링 불필요)\n",
    "- Logistic / Ridge / MLP → StandardScaler 적용\n",
    "- MLP → PyTorch 기반 GPU 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54802d30-20bc-4897-993b-e869c2fdc9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "✅ Best Logistic Params: {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__penalty': 'l1'}\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Project\\Python_Source\\Test01\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best XGBoost Params: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'scale_pos_weight': 1, 'subsample': 1.0}\n",
      "\n",
      "=== TorchMLP trial: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001} ===\n",
      "[Epoch 1] Train=0.2735, Val=0.0883\n",
      "[Epoch 2] Train=0.0878, Val=0.0585\n",
      "[Epoch 3] Train=0.0652, Val=0.0512\n",
      "[Epoch 4] Train=0.0566, Val=0.0425\n",
      "[Epoch 5] Train=0.0469, Val=0.0384\n",
      "[Epoch 6] Train=0.0434, Val=0.0363\n",
      "[Epoch 7] Train=0.0414, Val=0.0338\n",
      "[Epoch 8] Train=0.0373, Val=0.0427\n",
      "[Epoch 9] Train=0.0355, Val=0.0279\n",
      "[Epoch 10] Train=0.0344, Val=0.0272\n",
      "[Epoch 11] Train=0.0321, Val=0.0274\n",
      "[Epoch 12] Train=0.0301, Val=0.0280\n",
      "[Epoch 13] Train=0.0288, Val=0.0240\n",
      "[Epoch 14] Train=0.0273, Val=0.0287\n",
      "[Epoch 15] Train=0.0271, Val=0.0254\n",
      "[Epoch 16] Train=0.0268, Val=0.0251\n",
      "[Epoch 17] Train=0.0258, Val=0.0256\n",
      "[Epoch 18] Train=0.0257, Val=0.0215\n",
      "[Epoch 19] Train=0.0251, Val=0.0255\n",
      "[Epoch 20] Train=0.0247, Val=0.0214\n",
      "[Epoch 21] Train=0.0238, Val=0.0195\n",
      "[Epoch 22] Train=0.0230, Val=0.0255\n",
      "[Epoch 23] Train=0.0240, Val=0.0206\n",
      "[Epoch 24] Train=0.0221, Val=0.0201\n",
      "[Epoch 25] Train=0.0221, Val=0.0176\n",
      "[Epoch 26] Train=0.0221, Val=0.0219\n",
      "[Epoch 27] Train=0.0209, Val=0.0226\n",
      "[Epoch 28] Train=0.0208, Val=0.0243\n",
      "[Epoch 29] Train=0.0214, Val=0.0204\n",
      "[Epoch 30] Train=0.0218, Val=0.0217\n",
      "⏹ Early stopping triggered\n",
      "Validation F1=0.489\n",
      "\n",
      "=== TorchMLP trial: {'hidden_dim': 256, 'dropout': 0.4, 'lr': 0.0005} ===\n",
      "[Epoch 1] Train=0.3100, Val=0.1090\n",
      "[Epoch 2] Train=0.1091, Val=0.0733\n",
      "[Epoch 3] Train=0.0807, Val=0.0591\n",
      "[Epoch 4] Train=0.0687, Val=0.0518\n",
      "[Epoch 5] Train=0.0590, Val=0.0448\n",
      "[Epoch 6] Train=0.0533, Val=0.0450\n",
      "[Epoch 7] Train=0.0484, Val=0.0414\n",
      "[Epoch 8] Train=0.0446, Val=0.0366\n",
      "[Epoch 9] Train=0.0430, Val=0.0357\n",
      "[Epoch 10] Train=0.0382, Val=0.0309\n",
      "[Epoch 11] Train=0.0364, Val=0.0320\n",
      "[Epoch 12] Train=0.0350, Val=0.0281\n",
      "[Epoch 13] Train=0.0333, Val=0.0313\n",
      "[Epoch 14] Train=0.0312, Val=0.0260\n",
      "[Epoch 15] Train=0.0298, Val=0.0262\n",
      "[Epoch 16] Train=0.0280, Val=0.0253\n",
      "[Epoch 17] Train=0.0273, Val=0.0248\n",
      "[Epoch 18] Train=0.0265, Val=0.0247\n",
      "[Epoch 19] Train=0.0260, Val=0.0234\n",
      "[Epoch 20] Train=0.0257, Val=0.0225\n",
      "[Epoch 21] Train=0.0252, Val=0.0220\n",
      "[Epoch 22] Train=0.0239, Val=0.0223\n",
      "[Epoch 23] Train=0.0243, Val=0.0208\n",
      "[Epoch 24] Train=0.0226, Val=0.0205\n",
      "[Epoch 25] Train=0.0221, Val=0.0212\n",
      "[Epoch 26] Train=0.0226, Val=0.0213\n",
      "[Epoch 27] Train=0.0218, Val=0.0240\n",
      "[Epoch 28] Train=0.0211, Val=0.0217\n",
      "[Epoch 29] Train=0.0205, Val=0.0216\n",
      "⏹ Early stopping triggered\n",
      "Validation F1=0.487\n",
      "\n",
      "=== TorchMLP trial: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.0001} ===\n",
      "[Epoch 1] Train=0.6742, Val=0.3079\n",
      "[Epoch 2] Train=0.2859, Val=0.2008\n",
      "[Epoch 3] Train=0.2096, Val=0.1489\n",
      "[Epoch 4] Train=0.1664, Val=0.1213\n",
      "[Epoch 5] Train=0.1420, Val=0.1045\n",
      "[Epoch 6] Train=0.1287, Val=0.0943\n",
      "[Epoch 7] Train=0.1154, Val=0.0861\n",
      "[Epoch 8] Train=0.1086, Val=0.0803\n",
      "[Epoch 9] Train=0.1006, Val=0.0752\n",
      "[Epoch 10] Train=0.0932, Val=0.0707\n",
      "[Epoch 11] Train=0.0895, Val=0.0672\n",
      "[Epoch 12] Train=0.0847, Val=0.0644\n",
      "[Epoch 13] Train=0.0824, Val=0.0622\n",
      "[Epoch 14] Train=0.0776, Val=0.0593\n",
      "[Epoch 15] Train=0.0745, Val=0.0576\n",
      "[Epoch 16] Train=0.0705, Val=0.0545\n",
      "[Epoch 17] Train=0.0680, Val=0.0532\n",
      "[Epoch 18] Train=0.0663, Val=0.0507\n",
      "[Epoch 19] Train=0.0641, Val=0.0504\n",
      "[Epoch 20] Train=0.0630, Val=0.0485\n",
      "[Epoch 21] Train=0.0604, Val=0.0468\n",
      "[Epoch 22] Train=0.0595, Val=0.0457\n",
      "[Epoch 23] Train=0.0574, Val=0.0446\n",
      "[Epoch 24] Train=0.0562, Val=0.0431\n",
      "[Epoch 25] Train=0.0543, Val=0.0422\n",
      "[Epoch 26] Train=0.0525, Val=0.0407\n",
      "[Epoch 27] Train=0.0499, Val=0.0400\n",
      "[Epoch 28] Train=0.0497, Val=0.0388\n",
      "[Epoch 29] Train=0.0489, Val=0.0389\n",
      "[Epoch 30] Train=0.0476, Val=0.0372\n",
      "[Epoch 31] Train=0.0461, Val=0.0359\n",
      "[Epoch 32] Train=0.0462, Val=0.0356\n",
      "[Epoch 33] Train=0.0438, Val=0.0347\n",
      "[Epoch 34] Train=0.0432, Val=0.0350\n",
      "[Epoch 35] Train=0.0422, Val=0.0334\n",
      "[Epoch 36] Train=0.0412, Val=0.0339\n",
      "[Epoch 37] Train=0.0404, Val=0.0329\n",
      "[Epoch 38] Train=0.0391, Val=0.0319\n",
      "[Epoch 39] Train=0.0388, Val=0.0312\n",
      "[Epoch 40] Train=0.0365, Val=0.0312\n",
      "[Epoch 41] Train=0.0375, Val=0.0309\n",
      "[Epoch 42] Train=0.0365, Val=0.0303\n",
      "[Epoch 43] Train=0.0358, Val=0.0294\n",
      "[Epoch 44] Train=0.0354, Val=0.0292\n",
      "[Epoch 45] Train=0.0347, Val=0.0284\n",
      "[Epoch 46] Train=0.0344, Val=0.0291\n",
      "[Epoch 47] Train=0.0331, Val=0.0286\n",
      "[Epoch 48] Train=0.0332, Val=0.0275\n",
      "[Epoch 49] Train=0.0327, Val=0.0272\n",
      "[Epoch 50] Train=0.0321, Val=0.0266\n",
      "Validation F1=0.441\n",
      "✅ Best TorchMLP Params: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001}\n",
      "Logistic | Acc=0.995, F1=0.868, BalAcc=0.887\n",
      "XGBoost | Acc=0.997, F1=0.615, BalAcc=0.590\n",
      "TorchMLP | Acc=0.992, F1=0.567, BalAcc=0.543\n",
      "✅ Tuned results saved to classification_tuned_results.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----- 타깃 준비 -----\n",
    "y_train_cls = train_df[\"Bottleneck_actual\"]\n",
    "y_val_cls   = val_df[\"Bottleneck_actual\"]\n",
    "y_test_cls  = test_df[\"Bottleneck_actual\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_cls = le.fit_transform(y_train_cls)\n",
    "y_val_cls   = le.transform(y_val_cls)\n",
    "y_test_cls  = le.transform(y_test_cls)\n",
    "\n",
    "# ==================================================\n",
    "# 1) Logistic Regression 튜닝\n",
    "# ==================================================\n",
    "log_reg = LogisticRegression(max_iter=5000, solver=\"saga\")\n",
    "\n",
    "log_params = {\n",
    "    \"logisticregression__C\": [0.01, 0.1, 1, 10],\n",
    "    \"logisticregression__penalty\": [\"l1\", \"l2\"],\n",
    "    \"logisticregression__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "grid_log = GridSearchCV(\n",
    "    make_pipeline(StandardScaler(), log_reg),\n",
    "    param_grid=log_params,\n",
    "    cv=3,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_log.fit(X_train, y_train_cls)\n",
    "\n",
    "best_log_model = grid_log.best_estimator_\n",
    "print(\"✅ Best Logistic Params:\", grid_log.best_params_)\n",
    "\n",
    "# ==================================================\n",
    "# 2) XGBoost 튜닝\n",
    "# ==================================================\n",
    "xgb = XGBClassifier(tree_method=\"hist\", random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [200, 500],\n",
    "    \"max_depth\": [3, 6, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"scale_pos_weight\": [1, 2, 5]  # 불균형 대응\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    xgb,\n",
    "    param_grid=xgb_params,\n",
    "    cv=3,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_xgb.fit(X_train, y_train_cls)\n",
    "\n",
    "best_xgb_model = grid_xgb.best_estimator_\n",
    "print(\"✅ Best XGBoost Params:\", grid_xgb.best_params_)\n",
    "\n",
    "# ==================================================\n",
    "# 3) TorchMLP 튜닝 (수동 루프 기반)\n",
    "# ==================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Dataset & DataLoader\n",
    "class NumpyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(NumpyDataset(X_train_scaled, y_train_cls), batch_size=256, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(NumpyDataset(X_val_scaled, y_val_cls), batch_size=256, shuffle=False)\n",
    "test_tensor  = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# 모델 정의\n",
    "class TorchMLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, hidden_dim=128, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "def train_mlp(train_loader, val_loader, input_dim, num_classes, hidden_dim=128, dropout=0.3, lr=1e-3, epochs=50, patience=5):\n",
    "    model = TorchMLPClassifier(input_dim, num_classes, hidden_dim, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    patience_cnt = 0\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(xb)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                val_loss += loss.item() * len(xb)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Train={train_loss:.4f}, Val={val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_cnt = 0\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt >= patience:\n",
    "                print(\"⏹ Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "# 간단한 튜닝 루프\n",
    "mlp_param_grid = [\n",
    "    {\"hidden_dim\": 128, \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "    {\"hidden_dim\": 256, \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "    {\"hidden_dim\": 256, \"dropout\": 0.5, \"lr\": 1e-4}\n",
    "]\n",
    "\n",
    "best_score = -np.inf\n",
    "best_mlp_params = None\n",
    "best_mlp_model = None\n",
    "\n",
    "for params in mlp_param_grid:\n",
    "    print(f\"\\n=== TorchMLP trial: {params} ===\")\n",
    "    model = train_mlp(train_loader, val_loader, X_train.shape[1], len(le.classes_),\n",
    "                      hidden_dim=params[\"hidden_dim\"], dropout=params[\"dropout\"], lr=params[\"lr\"],\n",
    "                      epochs=50)\n",
    "    # 검증 성능 측정\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.tensor(X_val_scaled, dtype=torch.float32).to(device))\n",
    "        y_val_pred = torch.argmax(logits, axis=1).cpu().numpy()\n",
    "    f1_val = f1_score(y_val_cls, y_val_pred, average=\"macro\")\n",
    "    print(f\"Validation F1={f1_val:.3f}\")\n",
    "\n",
    "    if f1_val > best_score:\n",
    "        best_score = f1_val\n",
    "        best_mlp_model = model\n",
    "        best_mlp_params = params\n",
    "\n",
    "print(\"✅ Best TorchMLP Params:\", best_mlp_params)\n",
    "\n",
    "# ==================================================\n",
    "# 최종 테스트 성능 비교\n",
    "# ==================================================\n",
    "models = {\n",
    "    \"Logistic\": best_log_model,\n",
    "    \"XGBoost\": best_xgb_model,\n",
    "    \"TorchMLP\": best_mlp_model\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    if name == \"TorchMLP\":\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(test_tensor)\n",
    "            y_pred = torch.argmax(logits, axis=1).cpu().numpy()\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test_cls, y_pred)\n",
    "    f1 = f1_score(y_test_cls, y_pred, average=\"macro\")\n",
    "    bal_acc = balanced_accuracy_score(y_test_cls, y_pred)\n",
    "    results.append({\"name\": name, \"Acc\": acc, \"F1\": f1, \"BalAcc\": bal_acc})\n",
    "    print(f\"{name} | Acc={acc:.3f}, F1={f1:.3f}, BalAcc={bal_acc:.3f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"classification_tuned_results.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"✅ Tuned results saved to classification_tuned_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d51cd2-a3eb-4af3-8d15-b54e0b19ace6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1de757-309a-4647-9838-31afe807285e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8f252-a01d-41c6-80d0-29c28df82a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 RandomForest Hyperparameter Tuning...\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# ----- 타깃 준비 -----\n",
    "y_train_reg = train_df[\"Bottleneck_val\"]\n",
    "y_val_reg   = val_df[\"Bottleneck_val\"]\n",
    "y_test_reg  = test_df[\"Bottleneck_val\"]\n",
    "\n",
    "# ----- 학습/검증 합쳐서 튜닝 데이터로 사용 -----\n",
    "X_train_full = pd.concat([X_train, X_val])\n",
    "y_train_full = np.concatenate([y_train_reg.values, y_val_reg.values])\n",
    "\n",
    "# ----- 랜덤포레스트 + 그리드서치 -----\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 50],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"🔍 RandomForest Hyperparameter Tuning...\")\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"✅ Best Params:\", grid.best_params_)\n",
    "print(\"✅ Best CV R2:\", grid.best_score_)\n",
    "\n",
    "# ----- 최적 모델로 테스트 -----\n",
    "best_rf = grid.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred))\n",
    "r2 = r2_score(y_test_reg, y_pred)\n",
    "\n",
    "print(f\"🎯 RandomForest Tuned | MAE={mae:.3f} | RMSE={rmse:.3f} | R2={r2:.3f}\")\n",
    "\n",
    "# ----- 모델 저장 -----\n",
    "joblib.dump(best_rf, \"best_model_reg_RandomForest.pkl\")\n",
    "print(\"💾 Saved tuned RandomForest model: best_model_reg_RandomForest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9526ce-bc06-4b1c-96c6-dc55123ea56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab7297-8c50-408f-a358-6f588165ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b10ef-3d01-48e8-a3b5-4c99bbeed5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
