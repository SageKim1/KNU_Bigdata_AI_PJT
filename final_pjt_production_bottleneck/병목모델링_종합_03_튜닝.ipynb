{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f90048-1997-4fae-8b04-802c7cac2cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99902839-b5f5-468d-9001-eb6da6f63cc1",
   "metadata": {},
   "source": [
    "# ÌååÏùº Î∂àÎü¨Ïò§Í∏∞\n",
    "- ÎÇ†Ïßú ÏóÜÎäî ÏõêÎ≥∏ ÌååÏùº ÏÇ¨Ïö©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cabc4285-a175-4e58-af80-963485adf376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_Now</th>\n",
       "      <th>Blanking_Util</th>\n",
       "      <th>Blanking_SKU1_Queue</th>\n",
       "      <th>Blanking_SKU2_Queue</th>\n",
       "      <th>Blanking_SKU3_Queue</th>\n",
       "      <th>Blanking_SKU4_Queue</th>\n",
       "      <th>Press1_Util</th>\n",
       "      <th>Press2_Util</th>\n",
       "      <th>Press3_Util</th>\n",
       "      <th>Press4_Util</th>\n",
       "      <th>...</th>\n",
       "      <th>SKU3_NVA_Time</th>\n",
       "      <th>SKU3_Transport_Time</th>\n",
       "      <th>SKU3_Wait_Time</th>\n",
       "      <th>SKU3_Other_Time</th>\n",
       "      <th>SKU4_VA_Time</th>\n",
       "      <th>SKU4_NVA_Time</th>\n",
       "      <th>SKU4_Transport_Time</th>\n",
       "      <th>SKU4_Wait_Time</th>\n",
       "      <th>SKU4_Other_Time</th>\n",
       "      <th>Blanking_Queue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>0.846367</td>\n",
       "      <td>0.045715</td>\n",
       "      <td>0.056373</td>\n",
       "      <td>0.055737</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.410297</td>\n",
       "      <td>0.434561</td>\n",
       "      <td>0.481388</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537617</td>\n",
       "      <td>0.453650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536243</td>\n",
       "      <td>0.473453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.361452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>0.851097</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>0.052934</td>\n",
       "      <td>0.038512</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>0.455471</td>\n",
       "      <td>0.454445</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.442986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536764</td>\n",
       "      <td>0.473677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534992</td>\n",
       "      <td>0.464380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.830599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0.846115</td>\n",
       "      <td>0.052210</td>\n",
       "      <td>0.047499</td>\n",
       "      <td>0.043181</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.496717</td>\n",
       "      <td>0.450816</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.352829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535925</td>\n",
       "      <td>0.424090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535077</td>\n",
       "      <td>0.475330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.365867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>0.841306</td>\n",
       "      <td>0.051769</td>\n",
       "      <td>0.035436</td>\n",
       "      <td>0.046788</td>\n",
       "      <td>0.052362</td>\n",
       "      <td>0.433749</td>\n",
       "      <td>0.363004</td>\n",
       "      <td>0.443909</td>\n",
       "      <td>0.456036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535232</td>\n",
       "      <td>0.430992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533233</td>\n",
       "      <td>0.463801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.698528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0.859599</td>\n",
       "      <td>0.045874</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>0.044507</td>\n",
       "      <td>0.057210</td>\n",
       "      <td>0.418329</td>\n",
       "      <td>0.396826</td>\n",
       "      <td>0.499273</td>\n",
       "      <td>0.472454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538142</td>\n",
       "      <td>0.502614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.523363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537223</td>\n",
       "      <td>0.449320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.784631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time_Now  Blanking_Util  Blanking_SKU1_Queue  Blanking_SKU2_Queue  \\\n",
       "0        24       0.846367             0.045715             0.056373   \n",
       "1        24       0.851097             0.051937             0.052934   \n",
       "2        24       0.846115             0.052210             0.047499   \n",
       "3        24       0.841306             0.051769             0.035436   \n",
       "4        24       0.859599             0.045874             0.046802   \n",
       "\n",
       "   Blanking_SKU3_Queue  Blanking_SKU4_Queue  Press1_Util  Press2_Util  \\\n",
       "0             0.055737             0.035849     0.410297     0.434561   \n",
       "1             0.038512             0.042248     0.455471     0.454445   \n",
       "2             0.043181             0.040979     0.496717     0.450816   \n",
       "3             0.046788             0.052362     0.433749     0.363004   \n",
       "4             0.044507             0.057210     0.418329     0.396826   \n",
       "\n",
       "   Press3_Util  Press4_Util  ...  SKU3_NVA_Time  SKU3_Transport_Time  \\\n",
       "0     0.481388     0.399992  ...            0.0             0.537617   \n",
       "1     0.387975     0.442986  ...            0.0             0.536764   \n",
       "2     0.417308     0.352829  ...            0.0             0.535925   \n",
       "3     0.443909     0.456036  ...            0.0             0.535232   \n",
       "4     0.499273     0.472454  ...            0.0             0.538142   \n",
       "\n",
       "   SKU3_Wait_Time  SKU3_Other_Time  SKU4_VA_Time  SKU4_NVA_Time  \\\n",
       "0        0.453650              0.0      1.523338            0.0   \n",
       "1        0.473677              0.0      1.523344            0.0   \n",
       "2        0.424090              0.0      1.523403            0.0   \n",
       "3        0.430992              0.0      1.523381            0.0   \n",
       "4        0.502614              0.0      1.523363            0.0   \n",
       "\n",
       "   SKU4_Transport_Time  SKU4_Wait_Time  SKU4_Other_Time  Blanking_Queue  \n",
       "0             0.536243        0.473453              0.0       58.361452  \n",
       "1             0.534992        0.464380              0.0       62.830599  \n",
       "2             0.535077        0.475330              0.0       59.365867  \n",
       "3             0.533233        0.463801              0.0       56.698528  \n",
       "4             0.537223        0.449320              0.0       65.784631  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"./Final Results Extended.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb967fc-51e3-4e5d-88d6-5fd6eae2e2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a21236e6-bd74-4190-8f77-73451e7069fe",
   "metadata": {},
   "source": [
    "# Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26583c78-b2d2-41d7-89ad-0a1c4202bb93",
   "metadata": {},
   "source": [
    "## ÏÉÅÏàòÏª¨Îüº Î∞è Ï†ÑÎ∂Ä 0Ïù∏ Ïª¨Îüº Ï†úÍ±∞\n",
    "- Time_NowÏóê ÎèôÏùºÌïú 24 Í∞í -> Ï†úÍ±∞\n",
    "- Í≤∞Í≥ºÏ†ÅÏúºÎ°ú 22Í∞ú Ïª¨Îüº Ï†úÍ±∞\n",
    "- Queue Î≥ÄÏàò Ï§ë Ï†úÍ±∞Îêú Í±∞ : 'Paint1_Queue', 'Paint2_Queue', 'Cell1_Queue', 'Cell2_Queue', 'Cell3_Queue', 'Cell4_Queue'\n",
    "- CellÎ≥Ñ SKU ÏÉùÏÇ∞Îüâ Î≥ÄÏàò Ï§ë Ï†úÍ±∞Îêú Í±∞ : 'c_Cell1_SKU3', 'c_Cell2_SKU1', 'c_Cell2_SKU3', 'c_Cell3_SKU1', 'c_Cell3_SKU4', 'c_Cell4_SKU1', 'c_Cell4_SKU2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc04b5d6-3f56-43a8-8d5b-5a959b8c52eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóë Ï†úÍ±∞ ÎåÄÏÉÅ Ïª¨Îüº Ïàò: 22Í∞ú\n",
      "['Paint1_Queue', 'c_Cell4__SKU2', 'Cell3_Queue', 'Cell4_Queue', 'Time_Now', 'c_Cell3__SKU1', 'SKU2_Other_Time', 'SKU2_NVA_Time', 'c_Cell2__SKU1', 'SKU3_Other_Time', 'Cell1_Queue', 'SKU4_Other_Time', 'SKU1_Other_Time', 'SKU4_NVA_Time', 'SKU3_NVA_Time', 'Cell2_Queue', 'Paint2_Queue', 'c_Cell3__SKU4', 'c_Cell1__SKU3', 'c_Cell2__SKU3', 'SKU1_NVA_Time', 'c_Cell4__SKU1']\n",
      "‚úÖ Ï†úÍ±∞ ÌõÑ Ïª¨Îüº Ïàò: 56\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1. ÏÉÅÏàòÏª¨Îüº Î∞è Ï†ÑÎ∂Ä 0Ïù∏ Ïª¨Îüº Ï†úÍ±∞\n",
    "# =========================\n",
    "\n",
    "# (1) ÏÉÅÏàòÏª¨Îüº: Îç∞Ïù¥ÌÑ∞Í∞Ä Î™®Îëê Í∞ôÏùÄ Í∞íÏù∏ Ïª¨Îüº\n",
    "const_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "\n",
    "# (2) Ï†ÑÎ∂Ä 0Ïù∏ Ïª¨Îüº\n",
    "zero_cols = [col for col in df.columns if (df[col] == 0).all()]\n",
    "\n",
    "# Ìï©ÏπòÍ∏∞ (Ï§ëÎ≥µ Ï†úÍ±∞)\n",
    "drop_cols = list(set(const_cols + zero_cols))\n",
    "\n",
    "print(f\"üóë Ï†úÍ±∞ ÎåÄÏÉÅ Ïª¨Îüº Ïàò: {len(drop_cols)}Í∞ú\")\n",
    "print(drop_cols)\n",
    "\n",
    "# Ïã§Ï†ú Ï†úÍ±∞\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "print(f\"‚úÖ Ï†úÍ±∞ ÌõÑ Ïª¨Îüº Ïàò: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea35f3-73f7-4d62-a594-5bdd912ae28a",
   "metadata": {},
   "source": [
    "## Í≤∞Ï∏°Ïπò ÌôïÏù∏ -> 1~3Í∞úÏî© Ï°¥Ïû¨ => Ìï¥Îãπ Ìñâ drop (Ìñâ 3Í∞ú Ï†úÍ±∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c20fe5-bb9b-4ed3-ac8b-9b291bb04cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Í≤∞Ï∏°Ïπò ÏöîÏïΩ:\n",
      "Blanking_SKU4_Queue        1\n",
      "Press1_Util                1\n",
      "Press2_Util                1\n",
      "Press3_Util                1\n",
      "Press4_Util                1\n",
      "Press1_Queue               1\n",
      "Press2_Queue               1\n",
      "Press3_Queue               1\n",
      "Press4_Queue               1\n",
      "Cell1_Util                 1\n",
      "Cell2_Util                 1\n",
      "Cell3_Util                 1\n",
      "Cell4_Util                 1\n",
      "Warehouse1_Queue           1\n",
      "Warehouse_2_Queue          1\n",
      "Warehouse_3_Queue          1\n",
      "Warehouse_4_Queue          1\n",
      "c_Cycle1                   1\n",
      "c_Cycle2                   1\n",
      "c_Cycle3                   1\n",
      "c_Cycle4                   1\n",
      "c_Cell1_SKU1               1\n",
      "c_Cell1__SKU2              1\n",
      "c_Cell1__SKU4              1\n",
      "c_Cell2__SKU2              1\n",
      "c_Cell2__SKU4              1\n",
      "c_Cell3__SKU2              1\n",
      "c_Cell3__SKU3              1\n",
      "c_Cell4__SKU3              1\n",
      "c_Cell4__SKU4              1\n",
      "Paint1_Util                1\n",
      "Paint2_Util                1\n",
      "Quality_Util               1\n",
      "Quality_Queue              1\n",
      "Forklift_Util              1\n",
      "Forklift_Blanking_Queue    1\n",
      "Forklift_Press_Queue       1\n",
      "Forklift_Assembly_Queue    1\n",
      "c_TotalProducts            1\n",
      "SKU1_VA_Time               1\n",
      "SKU1_Transport_Time        2\n",
      "SKU1_Wait_Time             3\n",
      "SKU2_VA_Time               3\n",
      "SKU2_Transport_Time        3\n",
      "SKU2_Wait_Time             3\n",
      "SKU3_VA_Time               3\n",
      "SKU3_Transport_Time        3\n",
      "SKU3_Wait_Time             3\n",
      "SKU4_VA_Time               3\n",
      "SKU4_Transport_Time        3\n",
      "SKU4_Wait_Time             3\n",
      "Blanking_Queue             3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 2. Í≤∞Ï∏°Ïπò ÌôïÏù∏\n",
    "# =========================\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_summary = missing_summary[missing_summary > 0]\n",
    "\n",
    "if missing_summary.empty:\n",
    "    print(\"‚úÖ Í≤∞Ï∏°Ïπò ÏóÜÏùå\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Í≤∞Ï∏°Ïπò ÏöîÏïΩ:\")\n",
    "    print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e9eba4-cafd-4a07-a6f6-fd352b574dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Í≤∞Ï∏°ÏπòÍ∞Ä ÏûàÎäî Ìñâ 3Í∞ú Ï†úÍ±∞ ÏôÑÎ£å (ÎÇ®ÏùÄ Ìñâ: 132673)\n",
      "\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3. Í≤∞Ï∏°Ïπò Ï†úÍ±∞\n",
    "# =========================\n",
    "if not missing_summary.empty:\n",
    "    before = df.shape[0]\n",
    "    df = df.dropna()  # Í≤∞Ï∏°ÏπòÍ∞Ä ÌïòÎÇòÎùºÎèÑ ÏûàÎäî Ìñâ Ï†úÍ±∞\n",
    "    after = df.shape[0]\n",
    "    print(f\"‚úÖ Í≤∞Ï∏°ÏπòÍ∞Ä ÏûàÎäî Ìñâ {before - after}Í∞ú Ï†úÍ±∞ ÏôÑÎ£å (ÎÇ®ÏùÄ Ìñâ: {after})\")\n",
    "\n",
    "print()\n",
    "missing_summary2 = df.isnull().sum()\n",
    "missing_summary2 = missing_summary2[missing_summary2 > 0]\n",
    "print(missing_summary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57289df3-3796-4915-8864-56d95db7cf45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79615a1-baf7-4108-bb56-28bbf12efcf2",
   "metadata": {},
   "source": [
    "# Warehouse Queue -> ÎÑ§Ïù¥Î∞çÏùÑ Cell Queue Î°ú Î≥ÄÍ≤Ω (with ÎÑòÎ≤ÑÎßÅ Îß§Ìïë)\n",
    "- Ïù¥Î¶Ñ Î≥ÄÍ≤Ω Îß§Ìïë: {'Warehouse1_Queue': 'Cell1_Queue', 'Warehouse_2_Queue': 'Cell2_Queue', 'Warehouse_3_Queue': 'Cell3_Queue', 'Warehouse_4_Queue': 'Cell4_Queue'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095d67f7-7159-459a-88f0-b6ef0385b8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse Queue cols: ['Warehouse1_Queue', 'Warehouse_2_Queue', 'Warehouse_3_Queue', 'Warehouse_4_Queue']\n",
      "‚úÖ Ïù¥Î¶Ñ Î≥ÄÍ≤Ω Îß§Ìïë: {'Warehouse1_Queue': 'Cell1_Queue', 'Warehouse_2_Queue': 'Cell2_Queue', 'Warehouse_3_Queue': 'Cell3_Queue', 'Warehouse_4_Queue': 'Cell4_Queue'}\n",
      "Î≥ÄÍ≤Ω ÌõÑ Queue Í¥ÄÎ†® Ïª¨Îüº: ['Blanking_SKU1_Queue', 'Blanking_SKU2_Queue', 'Blanking_SKU3_Queue', 'Blanking_SKU4_Queue', 'Press1_Queue', 'Press2_Queue', 'Press3_Queue', 'Press4_Queue', 'Cell1_Queue', 'Cell2_Queue', 'Cell3_Queue', 'Cell4_Queue', 'Quality_Queue', 'Forklift_Blanking_Queue', 'Forklift_Press_Queue', 'Forklift_Assembly_Queue', 'Blanking_Queue']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Warehouse Queue Ïª¨Îüº Ï∞æÍ∏∞\n",
    "# =========================\n",
    "warehouse_cols = [c for c in df.columns if \"warehouse\" in c.lower() and \"queue\" in c.lower()]\n",
    "print(\"Warehouse Queue cols:\", warehouse_cols)\n",
    "\n",
    "# =========================\n",
    "# 2) Warehouse Î≤àÌò∏ ‚Üí Cell Î≤àÌò∏Î°ú Î≥ÄÌôò\n",
    "# =========================\n",
    "rename_map = {}\n",
    "for w in warehouse_cols:\n",
    "    # Ïà´Ïûê Ï∂îÏ∂ú (Ïòà: Warehouse1_Queue ‚Üí 1)\n",
    "    num = ''.join(filter(str.isdigit, w))\n",
    "    if num:\n",
    "        new_name = f\"Cell{num}_Queue\"\n",
    "        rename_map[w] = new_name\n",
    "\n",
    "# =========================\n",
    "# 3) Ïª¨ÎüºÎ™Ö Î≥ÄÍ≤Ω\n",
    "# =========================\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "print(\"‚úÖ Ïù¥Î¶Ñ Î≥ÄÍ≤Ω Îß§Ìïë:\", rename_map)\n",
    "print(\"Î≥ÄÍ≤Ω ÌõÑ Queue Í¥ÄÎ†® Ïª¨Îüº:\", [c for c in df.columns if \"queue\" in c.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd543ca4-2604-4edf-80e9-5d1122e0d354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7641e6e2-21fd-4d74-80a1-a0a157b83625",
   "metadata": {},
   "source": [
    "# Target Ïª¨Îüº ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f03179-0f0e-403e-92fc-97162f8a0dda",
   "metadata": {},
   "source": [
    "## Ï†ÑÏ≤¥ Í∏∞Ï§Ä Î≥ëÎ™© ÌååÏïÖ -> ÏÉà Ïª¨ÎüºÏóê Ï∂îÍ∞Ä (Bottleneck_actual , Bottleneck_actual_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d963b2a-8d65-43ea-b2e6-dc278222745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue Í¥ÄÎ†® Ïª¨Îüº Ïàò: 17\n",
      "['Blanking_SKU1_Queue', 'Blanking_SKU2_Queue', 'Blanking_SKU3_Queue', 'Blanking_SKU4_Queue', 'Press1_Queue', 'Press2_Queue', 'Press3_Queue', 'Press4_Queue', 'Cell1_Queue', 'Cell2_Queue']\n",
      "              Bottleneck_actual  Bottleneck_val\n",
      "132670  Forklift_Blanking_Queue      153.012984\n",
      "132671              Cell1_Queue      185.031493\n",
      "132672              Cell1_Queue      302.349198\n",
      "132673              Cell1_Queue      295.667368\n",
      "132674              Cell1_Queue      166.628981\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Queue Ïª¨Îüº Ï∞æÍ∏∞ (ÎåÄÏÜåÎ¨∏Ïûê Î¨¥Ïãú)\n",
    "# =========================\n",
    "queue_cols = [col for col in df.columns if \"queue\" in col.lower()]\n",
    "\n",
    "print(f\"Queue Í¥ÄÎ†® Ïª¨Îüº Ïàò: {len(queue_cols)}\")\n",
    "print(queue_cols[:10])  # Ïïû 10Í∞úÎßå ÌôïÏù∏\n",
    "\n",
    "# =========================\n",
    "# 2) Î≥ëÎ™© Í≥µÏ†ï Ïª¨Îüº ÏÉùÏÑ±\n",
    "# =========================\n",
    "# Í∞Å ÌñâÏóêÏÑú queue Í∞íÏù¥ Í∞ÄÏû• ÌÅ∞ Ïª¨ÎüºÎ™Ö\n",
    "df[\"Bottleneck_actual\"] = df[queue_cols].idxmax(axis=1)\n",
    "\n",
    "# Ìï¥Îãπ queueÏùò Ïã§Ï†ú ÏµúÎåÄÍ∞íÎèÑ Í∞ôÏù¥ Í∏∞Î°ùÌïòÍ≥† Ïã∂Îã§Î©¥\n",
    "df[\"Bottleneck_val\"] = df[queue_cols].max(axis=1)\n",
    "\n",
    "# =========================\n",
    "# 3) Í≤∞Í≥º ÌôïÏù∏\n",
    "# =========================\n",
    "print(df[[\"Bottleneck_actual\", \"Bottleneck_val\"]].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "589409bc-252c-4c50-a9d7-5f26eb9f9556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck_actual\n",
       "Cell1_Queue                77629\n",
       "Forklift_Blanking_Queue    53681\n",
       "Cell3_Queue                 1307\n",
       "Cell4_Queue                   36\n",
       "Forklift_Press_Queue           9\n",
       "Press4_Queue                   6\n",
       "Press2_Queue                   5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bottleneck Ïª¨ÎüºÏùò ÎπàÎèÑ Í≥ÑÏÇ∞\n",
    "bottleneck_counts = df[\"Bottleneck_actual\"].value_counts().head(10)\n",
    "\n",
    "bottleneck_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7426fd05-4efd-4b15-a349-209a14f0181b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c685ddab-8ac2-4f5d-a11a-317d5298b51f",
   "metadata": {},
   "source": [
    "## Ï£ºÏöî Í≥µÏ†ï Îã®Í≥Ñ(Î∏îÎû≠ÌÇπ, ÌîÑÎ†àÏä§, Ï°∞Î¶ΩÏÖÄ) Í∏∞Ï§Ä Î≥ëÎ™© ÌååÏïÖ -> ÏÉà Ïª¨ÎüºÏóê Ï∂îÍ∞Ä\n",
    "- Bottleneck_actual_Blanking , Bottleneck_actual_Press , Bottleneck_actual_Cell\n",
    "- Bottleneck_val_Blanking , Bottleneck_val_Press , Bottleneck_val_Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a117a4aa-9ff0-4e85-b14b-1eaaddda3807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Bottleneck_actual  Bottleneck_val Bottleneck_actual_Blanking  \\\n",
      "0  Forklift_Blanking_Queue      157.256741        Blanking_SKU2_Queue   \n",
      "1  Forklift_Blanking_Queue      166.488725        Blanking_SKU2_Queue   \n",
      "2              Cell1_Queue      335.401556        Blanking_SKU1_Queue   \n",
      "3  Forklift_Blanking_Queue      147.448407        Blanking_SKU4_Queue   \n",
      "4  Forklift_Blanking_Queue      150.397600        Blanking_SKU4_Queue   \n",
      "\n",
      "   Bottleneck_val_Blanking Bottleneck_actual_Press  Bottleneck_val_Press  \\\n",
      "0                 0.056373            Press2_Queue             65.273786   \n",
      "1                 0.052934            Press1_Queue             74.772823   \n",
      "2                 0.052210            Press2_Queue             72.901066   \n",
      "3                 0.052362            Press1_Queue             65.091192   \n",
      "4                 0.057210            Press1_Queue             65.075312   \n",
      "\n",
      "  Bottleneck_actual_Cell  Bottleneck_val_Cell  \n",
      "0            Cell1_Queue            98.155568  \n",
      "1            Cell1_Queue           162.632374  \n",
      "2            Cell1_Queue           335.401556  \n",
      "3            Cell1_Queue           112.173074  \n",
      "4            Cell1_Queue           107.982827  \n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 11. Í≥µÏ†ïÎ≥Ñ Ïã§Ï†ú Î≥ëÎ™© Î†àÏù¥Î∏î & Í∞í ÏÉùÏÑ±\n",
    "# ================================\n",
    "stage_groups = {\n",
    "    \"Blanking\": [\"Blanking_SKU1_Queue\", \"Blanking_SKU2_Queue\",\n",
    "                 \"Blanking_SKU3_Queue\", \"Blanking_SKU4_Queue\"],\n",
    "    \"Press\":    [\"Press1_Queue\", \"Press2_Queue\", \"Press3_Queue\", \"Press4_Queue\"],\n",
    "    \"Cell\":     [\"Cell1_Queue\", \"Cell2_Queue\", \"Cell3_Queue\", \"Cell4_Queue\"]\n",
    "}\n",
    "\n",
    "for stage, cols in stage_groups.items():\n",
    "    # Î≥ëÎ™© Ïª¨ÎüºÎ™Ö (Ïñ¥Îäê ÎùºÏù∏/ÏÑ§ÎπÑÍ∞Ä Î≥ëÎ™©Ïù∏ÏßÄ)\n",
    "    df[f\"Bottleneck_actual_{stage}\"] = df[cols].idxmax(axis=1)\n",
    "    # Î≥ëÎ™© Í∞í (queue ÌÅ¨Í∏∞)\n",
    "    df[f\"Bottleneck_val_{stage}\"] = df[cols].max(axis=1)\n",
    "\n",
    "# ================================\n",
    "# 12. Í≤∞Í≥º ÌôïÏù∏\n",
    "# ================================\n",
    "check_cols = [c for c in df.columns if c.startswith(\"Bottleneck_\")]\n",
    "print(df[check_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad0e538-b06c-4f0c-8af2-54b12664feed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550760c-34f9-4bc7-a772-6e9362c7580d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bae1ba67-7dc8-41e2-b4f3-78e37533aa42",
   "metadata": {},
   "source": [
    "## Ï†úÌíàÍµ∞(SKU) Í∏∞Ï§Ä Î≥ëÎ™© ÌååÏïÖ -> ÏÉà Ïª¨ÎüºÏóê Ï∂îÍ∞Ä\n",
    "- Bottleneck_actual_SKU1 , Bottleneck_actual_SKU2 , Bottleneck_actual_SKU3 , Bottleneck_actual_SKU4\n",
    "- Bottleneck_val_SKU1 , Bottleneck_val_SKU2 , Bottleneck_val_SKU3, Bottleneck_val_SKU4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783807f3-4dce-4614-a65e-3ad7f6370c75",
   "metadata": {},
   "source": [
    "### Ïª¨ÎüºÎ™Ö ÎßûÏ∂îÍ∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "646105d1-ea4a-4d17-81c9-0084d51e71ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKU1 ['c_Cell1_SKU1']\n",
      "SKU2 ['c_Cell1_SKU2', 'c_Cell2_SKU2', 'c_Cell3_SKU2']\n",
      "SKU3 ['c_Cell3_SKU3', 'c_Cell4_SKU3']\n",
      "SKU4 ['c_Cell1_SKU4', 'c_Cell2_SKU4', 'c_Cell4_SKU4']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Ïª¨ÎüºÎ™Ö Ï†ïÍ∑úÌôî: Ïñ∏ÎçîÏä§ÏΩîÏñ¥ Ïó¨Îü¨ Í∞ú ‚Üí 1Í∞úÎ°ú ÌÜµÏùº\n",
    "# =========================\n",
    "df.columns = df.columns.str.replace(r\"__+\", \"_\", regex=True)\n",
    "\n",
    "# ÌôïÏù∏\n",
    "for sku in [\"SKU1\",\"SKU2\",\"SKU3\",\"SKU4\"]:\n",
    "    related_cols = [c for c in df.columns if f\"Cell\" in c and sku in c]\n",
    "    print(sku, related_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada261e-e478-494c-b62a-85a522958f8d",
   "metadata": {},
   "source": [
    "### Ï°∞Î¶ΩÏÖÄ Queue Í∞í -> SKUÎ≥ÑÎ°ú Î∂ÑÎ∞∞\n",
    "- Í∞Å Cell Queue Ï†ÑÏ≤¥ÎüâÏùÑ SKUÎ≥Ñ Îã¥Îãπ ÎπÑÏú®Ïóê Îî∞Îùº ÎÇòÎà†ÏÑú, SKUÎ≥Ñ Cell QueueÎ•º ÏÉùÏÑ± -> SKUÎ≥ÑÎ°ú Ïó¨Îü¨ CellÏóêÏÑú Î∞õÏùÄ Î™´ÏùÑ Ìï©Ï≥ê ÏµúÏ¢Ö SKU Cell QueueÎ•º Í≥ÑÏÇ∞\n",
    "- Í∞Å ÌñâÏóê ÎåÄÌï¥ ÎèôÏ†ÅÏúºÎ°ú SKUÎ≥Ñ Î∂ÑÎ∞∞ ÏàòÌñâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb147a1-927e-4301-8b31-0594494d3756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKU1 ['c_Cell1_SKU1']\n",
      "SKU2 ['c_Cell1_SKU2', 'c_Cell2_SKU2', 'c_Cell3_SKU2']\n",
      "SKU3 ['c_Cell3_SKU3', 'c_Cell4_SKU3']\n",
      "SKU4 ['c_Cell1_SKU4', 'c_Cell2_SKU4', 'c_Cell4_SKU4']\n"
     ]
    }
   ],
   "source": [
    "for sku in [\"SKU1\",\"SKU2\",\"SKU3\",\"SKU4\"]:\n",
    "    related_cols = [c for c in df.columns if f\"_{sku}\" in c and \"c_Cell\" in c]\n",
    "    print(sku, related_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf64e3f8-c547-4ba7-b3ff-41ba37e33253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SKUÎ≥ÑÎ°ú Î∂ÑÎ∞∞Îêú Cell Queue (ÏïûÎ∂ÄÎ∂Ñ 10Ìñâ) ===\n",
      "   Cell_SKU1_Queue  Cell_SKU2_Queue  Cell_SKU3_Queue  Cell_SKU4_Queue\n",
      "0     1.370939e+06     1.192535e+06     1.247366e+06     8.856453e+05\n",
      "1     2.451033e+06     1.958747e+06     9.126624e+05     1.182048e+06\n",
      "2     5.568672e+06     3.817909e+06     9.283182e+05     1.242360e+06\n",
      "3     1.647598e+06     1.114051e+06     1.090078e+06     1.048065e+06\n",
      "4     1.553549e+06     1.232362e+06     1.476219e+06     1.102118e+06\n",
      "5     2.101007e+06     1.931448e+06     1.167199e+06     1.028449e+06\n",
      "6     1.851074e+06     1.886183e+06     6.287604e+05     8.966812e+05\n",
      "7     2.972045e+06     2.248654e+06     1.170633e+06     1.487739e+06\n",
      "8     5.720726e+06     4.591313e+06     9.949638e+05     1.545606e+06\n",
      "9     5.471222e+06     3.388148e+06     7.908985e+05     1.160693e+06\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 2. SKU Í≤ΩÎ°ú Ï†ïÏùò\n",
    "# ================================\n",
    "sku_paths = {\n",
    "    \"SKU1\": {\"blanking\": \"Blanking_SKU1_Queue\",\"press\": \"Press1_Queue\"},\n",
    "    \"SKU2\": {\"blanking\": \"Blanking_SKU2_Queue\",\"press\": \"Press2_Queue\"},\n",
    "    \"SKU3\": {\"blanking\": \"Blanking_SKU3_Queue\",\"press\": \"Press3_Queue\"},\n",
    "    \"SKU4\": {\"blanking\": \"Blanking_SKU4_Queue\",\"press\": \"Press4_Queue\"},\n",
    "}\n",
    "\n",
    "# ================================\n",
    "# 3. Cell ‚Üí SKU ÎπÑÏú® Í∏∞Î∞ò Î∂ÑÎ∞∞\n",
    "# ================================\n",
    "sku_cell_vals = {sku: pd.Series(0, index=df.index) for sku in sku_paths}\n",
    "\n",
    "for cell_num in range(1, 5):  # Cell1 ~ Cell4\n",
    "    cell_col = f\"Cell{cell_num}_Queue\"\n",
    "    \n",
    "    if cell_col not in df.columns:\n",
    "        continue\n",
    "    \n",
    "    # Ìï¥Îãπ Cell Queue Í∞í\n",
    "    cell_vals = df[cell_col]\n",
    "    \n",
    "    for sku in sku_paths.keys():\n",
    "        ratio_col = f\"c_Cell{cell_num}_{sku}\"\n",
    "        if ratio_col in df.columns:\n",
    "            # SKUÎ≥Ñ Cell Queue = Cell Queue √ó ÎπÑÏú®\n",
    "            sku_cell_vals[sku] += cell_vals * df[ratio_col]\n",
    "\n",
    "# ================================\n",
    "# 4. Í≤∞Í≥º DataFrame Íµ¨ÏÑ± (Ïª¨ÎüºÎ™Ö Î≥ÄÍ≤Ω)\n",
    "# ================================\n",
    "sku_cell_df = pd.DataFrame({\n",
    "    f\"Cell_{sku}_Queue\": vals for sku, vals in sku_cell_vals.items()\n",
    "})\n",
    "\n",
    "print(\"=== SKUÎ≥ÑÎ°ú Î∂ÑÎ∞∞Îêú Cell Queue (ÏïûÎ∂ÄÎ∂Ñ 10Ìñâ) ===\")\n",
    "print(sku_cell_df.head(10))\n",
    "\n",
    "# ÏõêÎûò dfÏóê Î∂ôÏù¥Í≥† Ïã∂Îã§Î©¥:\n",
    "df = pd.concat([df, sku_cell_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a574f272-8b18-42a1-b34e-693b09b2a537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Bottleneck_actual_Blanking Bottleneck_actual_Press Bottleneck_actual_Cell  \\\n",
      "0        Blanking_SKU2_Queue            Press2_Queue            Cell1_Queue   \n",
      "1        Blanking_SKU2_Queue            Press1_Queue            Cell1_Queue   \n",
      "2        Blanking_SKU1_Queue            Press2_Queue            Cell1_Queue   \n",
      "3        Blanking_SKU4_Queue            Press1_Queue            Cell1_Queue   \n",
      "4        Blanking_SKU4_Queue            Press1_Queue            Cell1_Queue   \n",
      "\n",
      "  Bottleneck_actual_SKU1 Bottleneck_actual_SKU2 Bottleneck_actual_SKU3  \\\n",
      "0                   Cell                   Cell                   Cell   \n",
      "1                   Cell                   Cell                   Cell   \n",
      "2                   Cell                   Cell                   Cell   \n",
      "3                   Cell                   Cell                   Cell   \n",
      "4                   Cell                   Cell                   Cell   \n",
      "\n",
      "  Bottleneck_actual_SKU4  \n",
      "0                   Cell  \n",
      "1                   Cell  \n",
      "2                   Cell  \n",
      "3                   Cell  \n",
      "4                   Cell  \n",
      "   Bottleneck_val_Blanking  Bottleneck_val_Press  Bottleneck_val_Cell  \\\n",
      "0                 0.056373             65.273786            98.155568   \n",
      "1                 0.052934             74.772823           162.632374   \n",
      "2                 0.052210             72.901066           335.401556   \n",
      "3                 0.052362             65.091192           112.173074   \n",
      "4                 0.057210             65.075312           107.982827   \n",
      "\n",
      "   Bottleneck_val_SKU1  Bottleneck_val_SKU2  Bottleneck_val_SKU3  \\\n",
      "0         1.370939e+06         1.192535e+06         1.247366e+06   \n",
      "1         2.451033e+06         1.958747e+06         9.126624e+05   \n",
      "2         5.568672e+06         3.817909e+06         9.283182e+05   \n",
      "3         1.647598e+06         1.114051e+06         1.090078e+06   \n",
      "4         1.553549e+06         1.232362e+06         1.476219e+06   \n",
      "\n",
      "   Bottleneck_val_SKU4  \n",
      "0         8.856453e+05  \n",
      "1         1.182048e+06  \n",
      "2         1.242360e+06  \n",
      "3         1.048065e+06  \n",
      "4         1.102118e+06  \n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 7. SKUÎ≥Ñ Î≥ëÎ™© Í≥µÏ†ï ÏòàÏ∏°\n",
    "# ================================\n",
    "sku_paths = {\n",
    "    \"SKU1\": {\"blanking\": \"Blanking_SKU1_Queue\",\"press\": \"Press1_Queue\", \"cell\": \"Cell_SKU1_Queue\"},\n",
    "    \"SKU2\": {\"blanking\": \"Blanking_SKU2_Queue\",\"press\": \"Press2_Queue\", \"cell\": \"Cell_SKU2_Queue\"},\n",
    "    \"SKU3\": {\"blanking\": \"Blanking_SKU3_Queue\",\"press\": \"Press3_Queue\", \"cell\": \"Cell_SKU3_Queue\"},\n",
    "    \"SKU4\": {\"blanking\": \"Blanking_SKU4_Queue\",\"press\": \"Press4_Queue\", \"cell\": \"Cell_SKU4_Queue\"},\n",
    "}\n",
    "\n",
    "for sku, paths in sku_paths.items():\n",
    "    # Í∞Å SKUÎ≥Ñ Î≥ëÎ™© ÌõÑÎ≥¥ Stage Í∞í Î™®ÏúºÍ∏∞\n",
    "    stage_df = df[[paths[\"blanking\"], paths[\"press\"], paths[\"cell\"]]].copy()\n",
    "    stage_df.columns = [\"Blanking\", \"Press\", \"Cell\"]  # Ï∂ï Ïù¥Î¶Ñ Îã®ÏàúÌôî\n",
    "    \n",
    "    # Í∞Å ÏãúÏ†êÎ≥Ñ ÏµúÎåÄÍ∞í Ïª¨ÎüºÎ™Ö ‚Üí Î≥ëÎ™© Í≥µÏ†ï\n",
    "    df[f\"Bottleneck_actual_{sku}\"] = stage_df.idxmax(axis=1)\n",
    "\n",
    "    # Í∞Å ÏãúÏ†êÎ≥Ñ Î≥ëÎ™© ÏàòÏπò (ÏµúÎåÄÍ∞í)\n",
    "    df[f\"Bottleneck_val_{sku}\"] = stage_df.max(axis=1)\n",
    "\n",
    "# ================================\n",
    "# 8. Í≤∞Í≥º ÌôïÏù∏\n",
    "# ================================\n",
    "print(df[[c for c in df.columns if c.startswith(\"Bottleneck_actual_\")]].head())\n",
    "print(df[[c for c in df.columns if c.startswith(\"Bottleneck_val_\")]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c8c63-485d-45d1-b9c2-21b20184f680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cb5e3-28dd-4699-9535-c430564bb08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf0d42b4-fdb4-4259-829d-1c65132e0999",
   "metadata": {},
   "source": [
    "# ÎûúÎç§ Î∂ÑÌï† - Train 70 : Val 15 : Test 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff1c5fe1-a1eb-4351-be5c-6eac9832e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42, shuffle=True)\n",
    "# train_df, val_df = train_test_split(train_val_df, test_size=0.1765, random_state=42, shuffle=True)\n",
    "# # 0.1765 ‚âà 15% / 85%\n",
    "\n",
    "# print(f\"Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b8de1fc-f4c7-408b-abe3-368a93af523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ï†ÄÏû• Í≤ΩÎ°ú ÏßÄÏ†ï (ÏõêÌïòÎäî Ìè¥ÎçîÎ°ú Î∞îÍæ∏ÏÑ∏Ïöî)\n",
    "# train_path = \"./bottleneck_train.csv\"\n",
    "# val_path   = \"./bottleneck_val.csv\"\n",
    "# test_path  = \"./bottleneck_test.csv\"\n",
    "\n",
    "# # CSV Ï†ÄÏû• (Ïù∏Îç±Ïä§ Ï†úÏô∏)\n",
    "# train_df.to_csv(train_path, index=False, encoding=\"utf-8-sig\")\n",
    "# val_df.to_csv(val_path, index=False, encoding=\"utf-8-sig\")\n",
    "# test_df.to_csv(test_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# print(\"‚úÖ CSV Ï†ÄÏû• ÏôÑÎ£å\")\n",
    "# print(f\"Train ‚Üí {train_path} ({train_df.shape})\")\n",
    "# print(f\"Val   ‚Üí {val_path} ({val_df.shape})\")\n",
    "# print(f\"Test  ‚Üí {test_path} ({test_df.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b88f8771-f8c9-419b-ba7a-2fd0fefde14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Î∂àÎü¨Ïò§Í∏∞ ÏôÑÎ£å\n",
      "Train: (92867, 76) Val: (19905, 76) Test: (19901, 76)\n",
      "Ï†ÑÏ≤¥ df: (132673, 76)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Í≤ΩÎ°ú ÏßÄÏ†ï\n",
    "train_path = \"./bottleneck_train.csv\"\n",
    "val_path   = \"./bottleneck_val.csv\"\n",
    "test_path  = \"./bottleneck_test.csv\"\n",
    "\n",
    "# Î∂àÎü¨Ïò§Í∏∞\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df   = pd.read_csv(val_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "# ÌïòÎÇòÎ°ú Ìï©ÏπòÍ≥† Ïã∂ÏúºÎ©¥\n",
    "df = pd.concat([train_df, val_df, test_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "print(\"‚úÖ Î∂àÎü¨Ïò§Í∏∞ ÏôÑÎ£å\")\n",
    "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape, \"Test:\", test_df.shape)\n",
    "print(\"Ï†ÑÏ≤¥ df:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8719fc-b556-42f7-baee-57b4058729c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f229ea7-345e-442e-9402-df353732501b",
   "metadata": {},
   "source": [
    "# ÎèÖÎ¶ΩÎ≥ÄÏàò Î∂ÑÎ¶¨\n",
    "- Ï†ÑÏ≤¥ Í∏∞Ï§Ä Î≥ëÎ™© ÏòàÏ∏°\n",
    "    - Î∂ÑÎ•ò : Bottleneck_actual\n",
    "    - ÌöåÍ∑Ä : Bottleneck_actual_val \n",
    "- Í≥µÏ†ï Îã®Í≥Ñ Í∏∞Ï§Ä Î≥ëÎ™© ÏòàÏ∏°\n",
    "    - Î∂ÑÎ•ò : Bottleneck_actual_Blanking , Bottleneck_actual_Press , Bottleneck_actual_Cell\n",
    "    - ÌöåÍ∑Ä : Bottleneck_val_Blanking , Bottleneck_val_Press , Bottleneck_val_Cell \n",
    "- Ï†úÌíàÍµ∞(SKU) Í∏∞Ï§Ä Î≥ëÎ™© ÏòàÏ∏°\n",
    "    - Î∂ÑÎ•ò : Bottleneck_actual_SKU1 , Bottleneck_actual_SKU2 , Bottleneck_actual_SKU3 , Bottleneck_actual_SKU4\n",
    "    - ÌöåÍ∑Ä : Bottleneck_val_SKU1 , Bottleneck_val_SKU2 , Bottleneck_val_SKU3, Bottleneck_val_SKU4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e003e859-53b4-4b57-9e05-d0ecf253a2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÎèÖÎ¶ΩÎ≥ÄÏàò Ïª¨Îüº Ïàò: 60\n",
      "ÏòàÏãú Ïª¨Îüº: ['Blanking_Util', 'Blanking_SKU1_Queue', 'Blanking_SKU2_Queue', 'Blanking_SKU3_Queue', 'Blanking_SKU4_Queue', 'Press1_Util', 'Press2_Util', 'Press3_Util', 'Press4_Util', 'Press1_Queue']\n"
     ]
    }
   ],
   "source": [
    "# ÌÉÄÍπÉ ÌõÑÎ≥¥ Ïª¨Îüº Ï†ÑÎ∂Ä Ï†ïÎ¶¨\n",
    "target_cols = [\n",
    "    # Ï†ÑÏ≤¥ Í∏∞Ï§Ä\n",
    "    \"Bottleneck_actual\", \"Bottleneck_val\",\n",
    "    # Í≥µÏ†ï Îã®Í≥Ñ Í∏∞Ï§Ä\n",
    "    \"Bottleneck_actual_Blanking\", \"Bottleneck_actual_Press\", \"Bottleneck_actual_Cell\",\n",
    "    \"Bottleneck_val_Blanking\", \"Bottleneck_val_Press\", \"Bottleneck_val_Cell\",\n",
    "    # SKU Í∏∞Ï§Ä\n",
    "    \"Bottleneck_actual_SKU1\", \"Bottleneck_actual_SKU2\", \"Bottleneck_actual_SKU3\", \"Bottleneck_actual_SKU4\",\n",
    "    \"Bottleneck_val_SKU1\", \"Bottleneck_val_SKU2\", \"Bottleneck_val_SKU3\", \"Bottleneck_val_SKU4\"\n",
    "]\n",
    "\n",
    "# ÎèÖÎ¶ΩÎ≥ÄÏàò(X)Îäî Ïù¥ ÌÉÄÍπÉ ÌõÑÎ≥¥Îì§ÏùÑ Ï†úÏô∏Ìïú Í≤ÉÎì§Îßå\n",
    "X_train = train_df.drop(columns=[c for c in target_cols if c in train_df.columns])\n",
    "X_val   = val_df.drop(columns=[c for c in target_cols if c in val_df.columns])\n",
    "X_test  = test_df.drop(columns=[c for c in target_cols if c in test_df.columns])\n",
    "\n",
    "print(\"‚úÖ ÎèÖÎ¶ΩÎ≥ÄÏàò Ïª¨Îüº Ïàò:\", X_train.shape[1])\n",
    "print(\"ÏòàÏãú Ïª¨Îüº:\", X_train.columns[:10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04073411-c48c-490e-b3ed-6ff5d87340c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d40dcb-1926-488e-acae-90067c6e07f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfad498-c8c8-4d50-ada2-b63c1bf2027a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd5c128e-c802-4daf-9564-dbb70aefa138",
   "metadata": {},
   "source": [
    "# Ï†ÑÏ≤¥ Í∏∞Ï§Ä Î≥ëÎ™© ÏòàÏ∏° Î™®Îç∏ÎßÅ\n",
    "- Î∂ÑÎ•ò : Bottleneck_actual\n",
    "- ÌöåÍ∑Ä : Bottleneck_actual_val "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58eca6d-e29e-41af-87db-9c0b7fe4832c",
   "metadata": {},
   "source": [
    "### Ï∂îÍ∞Ä Ï≤òÎ¶¨\n",
    "- Ìä∏Î¶¨ Í∏∞Î∞ò Î™®Îç∏(RandomForest, XGB) ‚Üí Í∑∏ÎåÄÎ°ú Îë† (Ïä§ÏºÄÏùºÎßÅ Î∂àÌïÑÏöî)\n",
    "- Logistic / Ridge / MLP ‚Üí StandardScaler Ï†ÅÏö©\n",
    "- MLP ‚Üí PyTorch Í∏∞Î∞ò GPU ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54802d30-20bc-4897-993b-e869c2fdc9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "‚úÖ Best Logistic Params: {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__penalty': 'l1'}\n",
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Project\\Python_Source\\Test01\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:49:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Best XGBoost Params: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'scale_pos_weight': 1, 'subsample': 1.0}\n",
      "\n",
      "=== TorchMLP trial: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001} ===\n",
      "[Epoch 1] Train=0.2735, Val=0.0883\n",
      "[Epoch 2] Train=0.0878, Val=0.0585\n",
      "[Epoch 3] Train=0.0652, Val=0.0512\n",
      "[Epoch 4] Train=0.0566, Val=0.0425\n",
      "[Epoch 5] Train=0.0469, Val=0.0384\n",
      "[Epoch 6] Train=0.0434, Val=0.0363\n",
      "[Epoch 7] Train=0.0414, Val=0.0338\n",
      "[Epoch 8] Train=0.0373, Val=0.0427\n",
      "[Epoch 9] Train=0.0355, Val=0.0279\n",
      "[Epoch 10] Train=0.0344, Val=0.0272\n",
      "[Epoch 11] Train=0.0321, Val=0.0274\n",
      "[Epoch 12] Train=0.0301, Val=0.0280\n",
      "[Epoch 13] Train=0.0288, Val=0.0240\n",
      "[Epoch 14] Train=0.0273, Val=0.0287\n",
      "[Epoch 15] Train=0.0271, Val=0.0254\n",
      "[Epoch 16] Train=0.0268, Val=0.0251\n",
      "[Epoch 17] Train=0.0258, Val=0.0256\n",
      "[Epoch 18] Train=0.0257, Val=0.0215\n",
      "[Epoch 19] Train=0.0251, Val=0.0255\n",
      "[Epoch 20] Train=0.0247, Val=0.0214\n",
      "[Epoch 21] Train=0.0238, Val=0.0195\n",
      "[Epoch 22] Train=0.0230, Val=0.0255\n",
      "[Epoch 23] Train=0.0240, Val=0.0206\n",
      "[Epoch 24] Train=0.0221, Val=0.0201\n",
      "[Epoch 25] Train=0.0221, Val=0.0176\n",
      "[Epoch 26] Train=0.0221, Val=0.0219\n",
      "[Epoch 27] Train=0.0209, Val=0.0226\n",
      "[Epoch 28] Train=0.0208, Val=0.0243\n",
      "[Epoch 29] Train=0.0214, Val=0.0204\n",
      "[Epoch 30] Train=0.0218, Val=0.0217\n",
      "‚èπ Early stopping triggered\n",
      "Validation F1=0.489\n",
      "\n",
      "=== TorchMLP trial: {'hidden_dim': 256, 'dropout': 0.4, 'lr': 0.0005} ===\n",
      "[Epoch 1] Train=0.3100, Val=0.1090\n",
      "[Epoch 2] Train=0.1091, Val=0.0733\n",
      "[Epoch 3] Train=0.0807, Val=0.0591\n",
      "[Epoch 4] Train=0.0687, Val=0.0518\n",
      "[Epoch 5] Train=0.0590, Val=0.0448\n",
      "[Epoch 6] Train=0.0533, Val=0.0450\n",
      "[Epoch 7] Train=0.0484, Val=0.0414\n",
      "[Epoch 8] Train=0.0446, Val=0.0366\n",
      "[Epoch 9] Train=0.0430, Val=0.0357\n",
      "[Epoch 10] Train=0.0382, Val=0.0309\n",
      "[Epoch 11] Train=0.0364, Val=0.0320\n",
      "[Epoch 12] Train=0.0350, Val=0.0281\n",
      "[Epoch 13] Train=0.0333, Val=0.0313\n",
      "[Epoch 14] Train=0.0312, Val=0.0260\n",
      "[Epoch 15] Train=0.0298, Val=0.0262\n",
      "[Epoch 16] Train=0.0280, Val=0.0253\n",
      "[Epoch 17] Train=0.0273, Val=0.0248\n",
      "[Epoch 18] Train=0.0265, Val=0.0247\n",
      "[Epoch 19] Train=0.0260, Val=0.0234\n",
      "[Epoch 20] Train=0.0257, Val=0.0225\n",
      "[Epoch 21] Train=0.0252, Val=0.0220\n",
      "[Epoch 22] Train=0.0239, Val=0.0223\n",
      "[Epoch 23] Train=0.0243, Val=0.0208\n",
      "[Epoch 24] Train=0.0226, Val=0.0205\n",
      "[Epoch 25] Train=0.0221, Val=0.0212\n",
      "[Epoch 26] Train=0.0226, Val=0.0213\n",
      "[Epoch 27] Train=0.0218, Val=0.0240\n",
      "[Epoch 28] Train=0.0211, Val=0.0217\n",
      "[Epoch 29] Train=0.0205, Val=0.0216\n",
      "‚èπ Early stopping triggered\n",
      "Validation F1=0.487\n",
      "\n",
      "=== TorchMLP trial: {'hidden_dim': 256, 'dropout': 0.5, 'lr': 0.0001} ===\n",
      "[Epoch 1] Train=0.6742, Val=0.3079\n",
      "[Epoch 2] Train=0.2859, Val=0.2008\n",
      "[Epoch 3] Train=0.2096, Val=0.1489\n",
      "[Epoch 4] Train=0.1664, Val=0.1213\n",
      "[Epoch 5] Train=0.1420, Val=0.1045\n",
      "[Epoch 6] Train=0.1287, Val=0.0943\n",
      "[Epoch 7] Train=0.1154, Val=0.0861\n",
      "[Epoch 8] Train=0.1086, Val=0.0803\n",
      "[Epoch 9] Train=0.1006, Val=0.0752\n",
      "[Epoch 10] Train=0.0932, Val=0.0707\n",
      "[Epoch 11] Train=0.0895, Val=0.0672\n",
      "[Epoch 12] Train=0.0847, Val=0.0644\n",
      "[Epoch 13] Train=0.0824, Val=0.0622\n",
      "[Epoch 14] Train=0.0776, Val=0.0593\n",
      "[Epoch 15] Train=0.0745, Val=0.0576\n",
      "[Epoch 16] Train=0.0705, Val=0.0545\n",
      "[Epoch 17] Train=0.0680, Val=0.0532\n",
      "[Epoch 18] Train=0.0663, Val=0.0507\n",
      "[Epoch 19] Train=0.0641, Val=0.0504\n",
      "[Epoch 20] Train=0.0630, Val=0.0485\n",
      "[Epoch 21] Train=0.0604, Val=0.0468\n",
      "[Epoch 22] Train=0.0595, Val=0.0457\n",
      "[Epoch 23] Train=0.0574, Val=0.0446\n",
      "[Epoch 24] Train=0.0562, Val=0.0431\n",
      "[Epoch 25] Train=0.0543, Val=0.0422\n",
      "[Epoch 26] Train=0.0525, Val=0.0407\n",
      "[Epoch 27] Train=0.0499, Val=0.0400\n",
      "[Epoch 28] Train=0.0497, Val=0.0388\n",
      "[Epoch 29] Train=0.0489, Val=0.0389\n",
      "[Epoch 30] Train=0.0476, Val=0.0372\n",
      "[Epoch 31] Train=0.0461, Val=0.0359\n",
      "[Epoch 32] Train=0.0462, Val=0.0356\n",
      "[Epoch 33] Train=0.0438, Val=0.0347\n",
      "[Epoch 34] Train=0.0432, Val=0.0350\n",
      "[Epoch 35] Train=0.0422, Val=0.0334\n",
      "[Epoch 36] Train=0.0412, Val=0.0339\n",
      "[Epoch 37] Train=0.0404, Val=0.0329\n",
      "[Epoch 38] Train=0.0391, Val=0.0319\n",
      "[Epoch 39] Train=0.0388, Val=0.0312\n",
      "[Epoch 40] Train=0.0365, Val=0.0312\n",
      "[Epoch 41] Train=0.0375, Val=0.0309\n",
      "[Epoch 42] Train=0.0365, Val=0.0303\n",
      "[Epoch 43] Train=0.0358, Val=0.0294\n",
      "[Epoch 44] Train=0.0354, Val=0.0292\n",
      "[Epoch 45] Train=0.0347, Val=0.0284\n",
      "[Epoch 46] Train=0.0344, Val=0.0291\n",
      "[Epoch 47] Train=0.0331, Val=0.0286\n",
      "[Epoch 48] Train=0.0332, Val=0.0275\n",
      "[Epoch 49] Train=0.0327, Val=0.0272\n",
      "[Epoch 50] Train=0.0321, Val=0.0266\n",
      "Validation F1=0.441\n",
      "‚úÖ Best TorchMLP Params: {'hidden_dim': 128, 'dropout': 0.3, 'lr': 0.001}\n",
      "Logistic | Acc=0.995, F1=0.868, BalAcc=0.887\n",
      "XGBoost | Acc=0.997, F1=0.615, BalAcc=0.590\n",
      "TorchMLP | Acc=0.992, F1=0.567, BalAcc=0.543\n",
      "‚úÖ Tuned results saved to classification_tuned_results.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ----- ÌÉÄÍπÉ Ï§ÄÎπÑ -----\n",
    "y_train_cls = train_df[\"Bottleneck_actual\"]\n",
    "y_val_cls   = val_df[\"Bottleneck_actual\"]\n",
    "y_test_cls  = test_df[\"Bottleneck_actual\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_cls = le.fit_transform(y_train_cls)\n",
    "y_val_cls   = le.transform(y_val_cls)\n",
    "y_test_cls  = le.transform(y_test_cls)\n",
    "\n",
    "# ==================================================\n",
    "# 1) Logistic Regression ÌäúÎãù\n",
    "# ==================================================\n",
    "log_reg = LogisticRegression(max_iter=5000, solver=\"saga\")\n",
    "\n",
    "log_params = {\n",
    "    \"logisticregression__C\": [0.01, 0.1, 1, 10],\n",
    "    \"logisticregression__penalty\": [\"l1\", \"l2\"],\n",
    "    \"logisticregression__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "grid_log = GridSearchCV(\n",
    "    make_pipeline(StandardScaler(), log_reg),\n",
    "    param_grid=log_params,\n",
    "    cv=3,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_log.fit(X_train, y_train_cls)\n",
    "\n",
    "best_log_model = grid_log.best_estimator_\n",
    "print(\"‚úÖ Best Logistic Params:\", grid_log.best_params_)\n",
    "\n",
    "# ==================================================\n",
    "# 2) XGBoost ÌäúÎãù\n",
    "# ==================================================\n",
    "xgb = XGBClassifier(tree_method=\"hist\", random_state=42, use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [200, 500],\n",
    "    \"max_depth\": [3, 6, 10],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"scale_pos_weight\": [1, 2, 5]  # Î∂àÍ∑†Ìòï ÎåÄÏùë\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    xgb,\n",
    "    param_grid=xgb_params,\n",
    "    cv=3,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_xgb.fit(X_train, y_train_cls)\n",
    "\n",
    "best_xgb_model = grid_xgb.best_estimator_\n",
    "print(\"‚úÖ Best XGBoost Params:\", grid_xgb.best_params_)\n",
    "\n",
    "# ==================================================\n",
    "# 3) TorchMLP ÌäúÎãù (ÏàòÎèô Î£®ÌîÑ Í∏∞Î∞ò)\n",
    "# ==================================================\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# Dataset & DataLoader\n",
    "class NumpyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(NumpyDataset(X_train_scaled, y_train_cls), batch_size=256, shuffle=True)\n",
    "val_loader   = torch.utils.data.DataLoader(NumpyDataset(X_val_scaled, y_val_cls), batch_size=256, shuffle=False)\n",
    "test_tensor  = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# Î™®Îç∏ Ï†ïÏùò\n",
    "class TorchMLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, hidden_dim=128, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "def train_mlp(train_loader, val_loader, input_dim, num_classes, hidden_dim=128, dropout=0.3, lr=1e-3, epochs=50, patience=5):\n",
    "    model = TorchMLPClassifier(input_dim, num_classes, hidden_dim, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    patience_cnt = 0\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * len(xb)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                out = model(xb)\n",
    "                loss = criterion(out, yb)\n",
    "                val_loss += loss.item() * len(xb)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f\"[Epoch {epoch}] Train={train_loss:.4f}, Val={val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_state = model.state_dict()\n",
    "            patience_cnt = 0\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt >= patience:\n",
    "                print(\"‚èπ Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "# Í∞ÑÎã®Ìïú ÌäúÎãù Î£®ÌîÑ\n",
    "mlp_param_grid = [\n",
    "    {\"hidden_dim\": 128, \"dropout\": 0.3, \"lr\": 1e-3},\n",
    "    {\"hidden_dim\": 256, \"dropout\": 0.4, \"lr\": 5e-4},\n",
    "    {\"hidden_dim\": 256, \"dropout\": 0.5, \"lr\": 1e-4}\n",
    "]\n",
    "\n",
    "best_score = -np.inf\n",
    "best_mlp_params = None\n",
    "best_mlp_model = None\n",
    "\n",
    "for params in mlp_param_grid:\n",
    "    print(f\"\\n=== TorchMLP trial: {params} ===\")\n",
    "    model = train_mlp(train_loader, val_loader, X_train.shape[1], len(le.classes_),\n",
    "                      hidden_dim=params[\"hidden_dim\"], dropout=params[\"dropout\"], lr=params[\"lr\"],\n",
    "                      epochs=50)\n",
    "    # Í≤ÄÏ¶ù ÏÑ±Îä• Ï∏°Ï†ï\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.tensor(X_val_scaled, dtype=torch.float32).to(device))\n",
    "        y_val_pred = torch.argmax(logits, axis=1).cpu().numpy()\n",
    "    f1_val = f1_score(y_val_cls, y_val_pred, average=\"macro\")\n",
    "    print(f\"Validation F1={f1_val:.3f}\")\n",
    "\n",
    "    if f1_val > best_score:\n",
    "        best_score = f1_val\n",
    "        best_mlp_model = model\n",
    "        best_mlp_params = params\n",
    "\n",
    "print(\"‚úÖ Best TorchMLP Params:\", best_mlp_params)\n",
    "\n",
    "# ==================================================\n",
    "# ÏµúÏ¢Ö ÌÖåÏä§Ìä∏ ÏÑ±Îä• ÎπÑÍµê\n",
    "# ==================================================\n",
    "models = {\n",
    "    \"Logistic\": best_log_model,\n",
    "    \"XGBoost\": best_xgb_model,\n",
    "    \"TorchMLP\": best_mlp_model\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    if name == \"TorchMLP\":\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(test_tensor)\n",
    "            y_pred = torch.argmax(logits, axis=1).cpu().numpy()\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test_cls, y_pred)\n",
    "    f1 = f1_score(y_test_cls, y_pred, average=\"macro\")\n",
    "    bal_acc = balanced_accuracy_score(y_test_cls, y_pred)\n",
    "    results.append({\"name\": name, \"Acc\": acc, \"F1\": f1, \"BalAcc\": bal_acc})\n",
    "    print(f\"{name} | Acc={acc:.3f}, F1={f1:.3f}, BalAcc={bal_acc:.3f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"classification_tuned_results.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"‚úÖ Tuned results saved to classification_tuned_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d51cd2-a3eb-4af3-8d15-b54e0b19ace6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1de757-309a-4647-9838-31afe807285e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a8f252-a01d-41c6-80d0-29c28df82a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç RandomForest Hyperparameter Tuning...\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# ----- ÌÉÄÍπÉ Ï§ÄÎπÑ -----\n",
    "y_train_reg = train_df[\"Bottleneck_val\"]\n",
    "y_val_reg   = val_df[\"Bottleneck_val\"]\n",
    "y_test_reg  = test_df[\"Bottleneck_val\"]\n",
    "\n",
    "# ----- ÌïôÏäµ/Í≤ÄÏ¶ù Ìï©Ï≥êÏÑú ÌäúÎãù Îç∞Ïù¥ÌÑ∞Î°ú ÏÇ¨Ïö© -----\n",
    "X_train_full = pd.concat([X_train, X_val])\n",
    "y_train_full = np.concatenate([y_train_reg.values, y_val_reg.values])\n",
    "\n",
    "# ----- ÎûúÎç§Ìè¨Î†àÏä§Ìä∏ + Í∑∏Î¶¨ÎìúÏÑúÏπò -----\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 500, 1000],\n",
    "    \"max_depth\": [None, 10, 20, 50],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"üîç RandomForest Hyperparameter Tuning...\")\n",
    "grid.fit(X_train_full, y_train_full)\n",
    "\n",
    "print(\"‚úÖ Best Params:\", grid.best_params_)\n",
    "print(\"‚úÖ Best CV R2:\", grid.best_score_)\n",
    "\n",
    "# ----- ÏµúÏ†Å Î™®Îç∏Î°ú ÌÖåÏä§Ìä∏ -----\n",
    "best_rf = grid.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred))\n",
    "r2 = r2_score(y_test_reg, y_pred)\n",
    "\n",
    "print(f\"üéØ RandomForest Tuned | MAE={mae:.3f} | RMSE={rmse:.3f} | R2={r2:.3f}\")\n",
    "\n",
    "# ----- Î™®Îç∏ Ï†ÄÏû• -----\n",
    "joblib.dump(best_rf, \"best_model_reg_RandomForest.pkl\")\n",
    "print(\"üíæ Saved tuned RandomForest model: best_model_reg_RandomForest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9526ce-bc06-4b1c-96c6-dc55123ea56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab7297-8c50-408f-a358-6f588165ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b10ef-3d01-48e8-a3b5-4c99bbeed5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
