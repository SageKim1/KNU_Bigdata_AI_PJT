{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df168bf-ff56-48a0-b7e2-64238a986d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 0) ÎìúÎ°≠Ïù∏ Ìå®Ïπò ÏÖÄ (Í≤ΩÎüâ Î™®Îìú)\n",
    "# ============================================\n",
    "# Î≥∏ ÏÖÄÏùÄ 1Î≤à ÏÖÄ ÏïÑÎûòÏóê ÎëêÍ≥† Ïã§Ìñâ. Ïù¥ÌõÑ ÏΩîÎìúÎäî Í∑∏ÎåÄÎ°ú Îë¨ÎèÑ Í≤ΩÎüâ Î™®ÎìúÎ°ú ÎèôÏûë.\n",
    "import os, re, gc, json, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Í∏ÄÎ°úÎ≤å Ïä§ÏúÑÏπò ----\n",
    "SPEED_MODE         = True\n",
    "ENABLE_PLOTS       = False\n",
    "ROW_SAMPLE_MAX     = 250_000\n",
    "COL_KEEP_PAT       = r\"(?:_Queue|_Util|^c_Cell|^c_TotalProducts$|^SKU\\d+_(?:VA|Wait|Transport|LeadTime|Total))\"\n",
    "TOP_SKU_K          = 3\n",
    "MAX_BNECK_ONEHOT   = 20\n",
    "ELAS_FEATURES_TOPK = 8\n",
    "ELAS_SAMPLE_N      = 5000\n",
    "USE_PDP            = False\n",
    "USE_FAST_FD        = True\n",
    "SKIP_PERM_IMPORT   = True\n",
    "RIDGE_TEST_SIZE    = 0.25\n",
    "RF_ESTIMATORS      = 60\n",
    "RF_MAX_DEPTH       = 12\n",
    "RF_NJOBS           = -1\n",
    "USE_HGBR_FIRST     = True\n",
    "SKIP_DEFECT_BLOCK  = True\n",
    "INCLUDE_MUSD_IN_LT = False\n",
    "INCLUDE_MUSD_IN_PR = False\n",
    "WHATIF_SCENARIOS   = {\"Blanking_Queue\": -50.0, \"Warehouse1_Queue\": -50.0, \"Quality_Util\": +5.0}\n",
    "\n",
    "def _speed_log(*a):\n",
    "    if SPEED_MODE: print(*a)\n",
    "\n",
    "def savefig(path: str):\n",
    "    # Í≤ΩÎüâ Ï†ÄÏû•: show ÏóÜÏù¥ Ï†ÄÏû•Îßå, Îã´Í≥† GC\n",
    "    if not ENABLE_PLOTS:\n",
    "        return\n",
    "    import matplotlib.pyplot as plt\n",
    "    try:\n",
    "        plt.tight_layout()\n",
    "    except Exception:\n",
    "        pass\n",
    "    plt.savefig(path, bbox_inches=\"tight\", dpi=140)\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "\n",
    "def to_numeric_df(d: pd.DataFrame) -> pd.DataFrame:\n",
    "    # float32 ÏùºÍ¥Ñ Î≥ÄÌôò + NA Ï±ÑÏõÄ(Í≤ΩÎüâ)\n",
    "    for c in d.columns:\n",
    "        d.loc[:, c] = pd.to_numeric(d[c], errors=\"coerce\", downcast=\"float\")\n",
    "    d = d.fillna(0.0)\n",
    "    d = d.infer_objects(copy=False)\n",
    "    return d\n",
    "\n",
    "def _apply_df_speed_filters(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not SPEED_MODE: return df\n",
    "    # Ïó¥ ÌïÑÌÑ∞\n",
    "    if COL_KEEP_PAT:\n",
    "        keep_re = re.compile(COL_KEEP_PAT, re.IGNORECASE)\n",
    "        keep_cols = [c for c in df.columns if keep_re.search(c)]\n",
    "        for must in [\"Time_Now\"]:\n",
    "            if must in df.columns and must not in keep_cols:\n",
    "                keep_cols.append(must)\n",
    "        df = df[keep_cols]\n",
    "        _speed_log(f\"[SPEED] kept {len(keep_cols)} columns by pattern.\")\n",
    "    # Ìñâ ÏÉòÌîåÎßÅ\n",
    "    if ROW_SAMPLE_MAX and len(df) > ROW_SAMPLE_MAX:\n",
    "        df = df.sample(ROW_SAMPLE_MAX, random_state=42).sort_index()\n",
    "        _speed_log(f\"[SPEED] row-sampled to {ROW_SAMPLE_MAX} rows.\")\n",
    "    # dtype\n",
    "    df = to_numeric_df(df)\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# ---- Î™®Îç∏ Í≥µÌÜµ ----\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "def metrics_dict(y_true, y_pred) -> dict:\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    r2   = float(r2_score(y_true, y_pred))\n",
    "    return {\"MAE\": round(mae,3), \"RMSE\": round(rmse,3), \"R2\": round(r2,4)}\n",
    "\n",
    "def train_ridge(X, y, alpha=1.0, random_state=42, test_size=None):\n",
    "    from sklearn.linear_model import Ridge\n",
    "    if test_size is None:\n",
    "        test_size = RIDGE_TEST_SIZE if SPEED_MODE else 0.3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    reg = Ridge(alpha=alpha, random_state=random_state)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    m = metrics_dict(y_test, y_pred)\n",
    "    coef = pd.Series(reg.coef_, index=X.columns).sort_values(ascending=False)\n",
    "    std_x = X_test.std(axis=0).replace(0, np.nan)\n",
    "    std_y = np.std(y_test) if np.std(y_test) > 0 else np.nan\n",
    "    beta_std = (coef * (std_x / std_y)).sort_values(ascending=False)\n",
    "    return reg, (X_train, X_test, y_train, y_test), m, coef, beta_std\n",
    "\n",
    "def train_fast_tree(X, y, random_state=42):\n",
    "    \"\"\"HistGradientBoostingRegressor Ïö∞ÏÑ†, Ïã§Ìå® Ïãú Í≤ΩÎüâ RF Ìè¥Î∞±.\"\"\"\n",
    "    try:\n",
    "        if USE_HGBR_FIRST:\n",
    "            from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "            from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "            model = HistGradientBoostingRegressor(\n",
    "                max_depth=8, learning_rate=0.1, max_iter=150, random_state=random_state\n",
    "            )\n",
    "            model.fit(X, y)\n",
    "            score = model.score(X, y)\n",
    "            _speed_log(\"[SPEED] Using HistGradientBoostingRegressor.\")\n",
    "            return model, None, score, None, None\n",
    "    except Exception as e:\n",
    "        _speed_log(\"[SPEED] HGBR unavailable ‚Üí fallback to RF.\", e)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=RF_ESTIMATORS, max_depth=RF_MAX_DEPTH,\n",
    "        n_jobs=RF_NJOBS, random_state=random_state\n",
    "    )\n",
    "    rf.fit(X, y)\n",
    "    fi = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "    pi = None\n",
    "    if not SKIP_PERM_IMPORT:\n",
    "        from sklearn.inspection import permutation_importance\n",
    "        pi_ = permutation_importance(rf, X, y, n_repeats=3, random_state=random_state, n_jobs=RF_NJOBS)\n",
    "        pi = pd.Series(pi_.importances_mean, index=X.columns)\n",
    "    score = rf.score(X, y)\n",
    "    return rf, None, score, fi, pi\n",
    "\n",
    "# Í∏∞Ï°¥ train_rf ÎçÆÏñ¥Ïì∞Í∏∞\n",
    "def train_rf(X, y, n_repeats=0, random_state=42):\n",
    "    return train_fast_tree(X, y, random_state=random_state)\n",
    "\n",
    "# ---- ÌîºÏ≤ò/Î≥ëÎ™© One-Hot Ï†úÌïú ----\n",
    "#time_like_regex = re.compile(r\"(?:_Time|_sec|_LeadTime|_Total)\", re.IGNORECASE)\n",
    "time_like_regex = re.compile(r'(?:_Time|_sec|_LeadTime|_Total|_VA_(?:dev|z))', re.IGNORECASE)\n",
    "\n",
    "def build_features_for_leadtime(df_, exclude_cols, add_bneck_onehot=True, top_bneck_list=None, max_bneck=None):\n",
    "    if max_bneck is None:\n",
    "        max_bneck = MAX_BNECK_ONEHOT\n",
    "    cols = [c for c in df_.columns if c not in exclude_cols and c != \"Time_Now\" and not time_like_regex.search(c)]\n",
    "    X = to_numeric_df(df_[cols]) if cols else pd.DataFrame(index=df_.index)\n",
    "    if add_bneck_onehot and \"_bneck\" in df_.columns:\n",
    "        b_series = df_[\"_bneck\"].astype(str)\n",
    "        if top_bneck_list is not None:\n",
    "            b_series = b_series.where(b_series.isin(top_bneck_list), \"Other\")\n",
    "        topN = b_series.value_counts().nlargest(max_bneck).index\n",
    "        b_series = b_series.where(b_series.isin(topN), \"Other\")\n",
    "        D = pd.get_dummies(b_series, prefix=\"BNECK\", dtype=\"float32\")\n",
    "        X = pd.concat([X, D], axis=1)\n",
    "    return X\n",
    "\n",
    "def build_features_for_production(df_, exclude_cols):\n",
    "    cols = [c for c in df_.columns if c not in exclude_cols and c != \"Time_Now\" and not c.startswith(\"c_Cell\") and c != \"c_TotalProducts\"]\n",
    "    return to_numeric_df(df_[cols]) if cols else pd.DataFrame(index=df_.index)\n",
    "\n",
    "# ---- ÌÉÑÎ†•ÎèÑ(FD) ÌååÎùºÎØ∏ÌÑ∞ ----\n",
    "FEATURES_TOP_K = ELAS_FEATURES_TOPK\n",
    "ONLY_QUEUE_UTIL = True\n",
    "SAMPLE_N = ELAS_SAMPLE_N\n",
    "USE_FDP_FAST = USE_FAST_FD\n",
    "\n",
    "def limit_top_k_skus(sku_ids, sku_targets, k=TOP_SKU_K):\n",
    "    if not SPEED_MODE or not k or k >= len(sku_ids):\n",
    "        return sku_ids\n",
    "    sums = []\n",
    "    for sid in sku_ids:\n",
    "        pr = sku_targets[sid][\"production\"]\n",
    "        sums.append((sid, float(np.nansum(pr.values)) if hasattr(pr, \"values\") else float(np.nansum(pr))))\n",
    "    sums = sorted(sums, key=lambda x: x[1], reverse=True)\n",
    "    top = [sid for sid, _ in sums[:k]]\n",
    "    _speed_log(f\"[SPEED] limit SKUs ‚Üí top {k}: {top}\")\n",
    "    return top\n",
    "\n",
    "def get_scenarios(X_cols):\n",
    "    sc = {}\n",
    "    for k, v in WHATIF_SCENARIOS.items():\n",
    "        if k in X_cols:\n",
    "            sc[k] = v\n",
    "    return sc\n",
    "\n",
    "def should_skip_defect_block(): return SPEED_MODE and SKIP_DEFECT_BLOCK\n",
    "def musd_flags():\n",
    "    return (INCLUDE_MUSD_IN_LT if not SPEED_MODE else False), (INCLUDE_MUSD_IN_PR if not SPEED_MODE else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89235282-6db7-4749-81b5-35e4f80490a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPEED] kept 66 columns by pattern.\n",
      "=== Dataset shape === (132676, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blanking_Util</th>\n",
       "      <th>Blanking_SKU1_Queue</th>\n",
       "      <th>Blanking_SKU2_Queue</th>\n",
       "      <th>Blanking_SKU3_Queue</th>\n",
       "      <th>Blanking_SKU4_Queue</th>\n",
       "      <th>Press1_Util</th>\n",
       "      <th>Press2_Util</th>\n",
       "      <th>Press3_Util</th>\n",
       "      <th>Press4_Util</th>\n",
       "      <th>Press1_Queue</th>\n",
       "      <th>Press2_Queue</th>\n",
       "      <th>Press3_Queue</th>\n",
       "      <th>Press4_Queue</th>\n",
       "      <th>Cell1_Util</th>\n",
       "      <th>Cell2_Util</th>\n",
       "      <th>Cell3_Util</th>\n",
       "      <th>Cell4_Util</th>\n",
       "      <th>Cell1_Queue</th>\n",
       "      <th>Cell2_Queue</th>\n",
       "      <th>Cell3_Queue</th>\n",
       "      <th>Cell4_Queue</th>\n",
       "      <th>Warehouse1_Queue</th>\n",
       "      <th>Warehouse_2_Queue</th>\n",
       "      <th>Warehouse_3_Queue</th>\n",
       "      <th>Warehouse_4_Queue</th>\n",
       "      <th>c_Cell1_SKU1</th>\n",
       "      <th>c_Cell1__SKU2</th>\n",
       "      <th>c_Cell1__SKU3</th>\n",
       "      <th>c_Cell1__SKU4</th>\n",
       "      <th>c_Cell2__SKU1</th>\n",
       "      <th>c_Cell2__SKU2</th>\n",
       "      <th>c_Cell2__SKU3</th>\n",
       "      <th>c_Cell2__SKU4</th>\n",
       "      <th>c_Cell3__SKU1</th>\n",
       "      <th>c_Cell3__SKU2</th>\n",
       "      <th>c_Cell3__SKU3</th>\n",
       "      <th>c_Cell3__SKU4</th>\n",
       "      <th>c_Cell4__SKU1</th>\n",
       "      <th>c_Cell4__SKU2</th>\n",
       "      <th>c_Cell4__SKU3</th>\n",
       "      <th>c_Cell4__SKU4</th>\n",
       "      <th>Paint1_Util</th>\n",
       "      <th>Paint2_Util</th>\n",
       "      <th>Quality_Util</th>\n",
       "      <th>Paint1_Queue</th>\n",
       "      <th>Paint2_Queue</th>\n",
       "      <th>Quality_Queue</th>\n",
       "      <th>Forklift_Util</th>\n",
       "      <th>Forklift_Blanking_Queue</th>\n",
       "      <th>Forklift_Press_Queue</th>\n",
       "      <th>Forklift_Assembly_Queue</th>\n",
       "      <th>c_TotalProducts</th>\n",
       "      <th>SKU1_VA_Time</th>\n",
       "      <th>SKU1_Transport_Time</th>\n",
       "      <th>SKU1_Wait_Time</th>\n",
       "      <th>SKU2_VA_Time</th>\n",
       "      <th>SKU2_Transport_Time</th>\n",
       "      <th>SKU2_Wait_Time</th>\n",
       "      <th>SKU3_VA_Time</th>\n",
       "      <th>SKU3_Transport_Time</th>\n",
       "      <th>SKU3_Wait_Time</th>\n",
       "      <th>SKU4_VA_Time</th>\n",
       "      <th>SKU4_Transport_Time</th>\n",
       "      <th>SKU4_Wait_Time</th>\n",
       "      <th>Blanking_Queue</th>\n",
       "      <th>Time_Now</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846367</td>\n",
       "      <td>0.045715</td>\n",
       "      <td>0.056373</td>\n",
       "      <td>0.055737</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.410297</td>\n",
       "      <td>0.434561</td>\n",
       "      <td>0.481388</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>56.540291</td>\n",
       "      <td>65.273788</td>\n",
       "      <td>52.970764</td>\n",
       "      <td>47.964825</td>\n",
       "      <td>0.848870</td>\n",
       "      <td>0.673814</td>\n",
       "      <td>0.705012</td>\n",
       "      <td>0.819405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.155571</td>\n",
       "      <td>19.580276</td>\n",
       "      <td>77.580864</td>\n",
       "      <td>75.124985</td>\n",
       "      <td>13967.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2851.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>4707.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11743.0</td>\n",
       "      <td>4934.0</td>\n",
       "      <td>0.472565</td>\n",
       "      <td>0.504126</td>\n",
       "      <td>0.432738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.361618</td>\n",
       "      <td>0.606002</td>\n",
       "      <td>157.256744</td>\n",
       "      <td>142.123962</td>\n",
       "      <td>137.454849</td>\n",
       "      <td>54377.0</td>\n",
       "      <td>1.525651</td>\n",
       "      <td>0.536810</td>\n",
       "      <td>0.587305</td>\n",
       "      <td>1.522853</td>\n",
       "      <td>0.532394</td>\n",
       "      <td>0.441645</td>\n",
       "      <td>1.525071</td>\n",
       "      <td>0.537617</td>\n",
       "      <td>0.453650</td>\n",
       "      <td>1.523338</td>\n",
       "      <td>0.536243</td>\n",
       "      <td>0.473453</td>\n",
       "      <td>58.361450</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851097</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>0.052934</td>\n",
       "      <td>0.038512</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>0.455471</td>\n",
       "      <td>0.454445</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.442986</td>\n",
       "      <td>74.772820</td>\n",
       "      <td>52.530064</td>\n",
       "      <td>49.303143</td>\n",
       "      <td>59.119987</td>\n",
       "      <td>0.876750</td>\n",
       "      <td>0.660415</td>\n",
       "      <td>0.629526</td>\n",
       "      <td>0.803448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.632370</td>\n",
       "      <td>18.164795</td>\n",
       "      <td>64.827576</td>\n",
       "      <td>69.374908</td>\n",
       "      <td>15071.0</td>\n",
       "      <td>11180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3615.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>3852.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9556.0</td>\n",
       "      <td>7484.0</td>\n",
       "      <td>0.482683</td>\n",
       "      <td>0.501912</td>\n",
       "      <td>0.436583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.266911</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>166.488724</td>\n",
       "      <td>142.113663</td>\n",
       "      <td>140.757584</td>\n",
       "      <td>54857.0</td>\n",
       "      <td>1.525665</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.684177</td>\n",
       "      <td>1.522836</td>\n",
       "      <td>0.535767</td>\n",
       "      <td>0.401993</td>\n",
       "      <td>1.524986</td>\n",
       "      <td>0.536764</td>\n",
       "      <td>0.473677</td>\n",
       "      <td>1.523344</td>\n",
       "      <td>0.534992</td>\n",
       "      <td>0.464380</td>\n",
       "      <td>62.830601</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846115</td>\n",
       "      <td>0.052210</td>\n",
       "      <td>0.047499</td>\n",
       "      <td>0.043181</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.496717</td>\n",
       "      <td>0.450816</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.352829</td>\n",
       "      <td>67.283035</td>\n",
       "      <td>72.901070</td>\n",
       "      <td>39.198517</td>\n",
       "      <td>33.994083</td>\n",
       "      <td>0.895845</td>\n",
       "      <td>0.660288</td>\n",
       "      <td>0.654895</td>\n",
       "      <td>0.766823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.401550</td>\n",
       "      <td>20.369415</td>\n",
       "      <td>46.120110</td>\n",
       "      <td>71.720192</td>\n",
       "      <td>16603.0</td>\n",
       "      <td>11042.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>4139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10282.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>0.476897</td>\n",
       "      <td>0.492906</td>\n",
       "      <td>0.429997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.906418</td>\n",
       "      <td>0.576669</td>\n",
       "      <td>159.188507</td>\n",
       "      <td>148.427689</td>\n",
       "      <td>142.653366</td>\n",
       "      <td>54052.0</td>\n",
       "      <td>1.525644</td>\n",
       "      <td>0.535403</td>\n",
       "      <td>0.898331</td>\n",
       "      <td>1.522821</td>\n",
       "      <td>0.535631</td>\n",
       "      <td>0.427815</td>\n",
       "      <td>1.525064</td>\n",
       "      <td>0.535925</td>\n",
       "      <td>0.424090</td>\n",
       "      <td>1.523403</td>\n",
       "      <td>0.535077</td>\n",
       "      <td>0.475330</td>\n",
       "      <td>59.365868</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blanking_Util  Blanking_SKU1_Queue  Blanking_SKU2_Queue  Blanking_SKU3_Queue  Blanking_SKU4_Queue  Press1_Util  Press2_Util  Press3_Util  Press4_Util  \\\n",
       "0       0.846367             0.045715             0.056373             0.055737             0.035849     0.410297     0.434561     0.481388     0.399992   \n",
       "1       0.851097             0.051937             0.052934             0.038512             0.042248     0.455471     0.454445     0.387975     0.442986   \n",
       "2       0.846115             0.052210             0.047499             0.043181             0.040979     0.496717     0.450816     0.417308     0.352829   \n",
       "\n",
       "   Press1_Queue  Press2_Queue  Press3_Queue  Press4_Queue  Cell1_Util  Cell2_Util  Cell3_Util  Cell4_Util  Cell1_Queue  Cell2_Queue  Cell3_Queue  Cell4_Queue  \\\n",
       "0     56.540291     65.273788     52.970764     47.964825    0.848870    0.673814    0.705012    0.819405          0.0          0.0          0.0          0.0   \n",
       "1     74.772820     52.530064     49.303143     59.119987    0.876750    0.660415    0.629526    0.803448          0.0          0.0          0.0          0.0   \n",
       "2     67.283035     72.901070     39.198517     33.994083    0.895845    0.660288    0.654895    0.766823          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   Warehouse1_Queue  Warehouse_2_Queue  Warehouse_3_Queue  Warehouse_4_Queue  c_Cell1_SKU1  c_Cell1__SKU2  c_Cell1__SKU3  c_Cell1__SKU4  c_Cell2__SKU1  \\\n",
       "0         98.155571          19.580276          77.580864          75.124985       13967.0        10867.0            0.0         4382.0            0.0   \n",
       "1        162.632370          18.164795          64.827576          69.374908       15071.0        11180.0            0.0         3615.0            0.0   \n",
       "2        335.401550          20.369415          46.120110          71.720192       16603.0        11042.0            0.0         2260.0            0.0   \n",
       "\n",
       "   c_Cell2__SKU2  c_Cell2__SKU3  c_Cell2__SKU4  c_Cell3__SKU1  c_Cell3__SKU2  c_Cell3__SKU3  c_Cell3__SKU4  c_Cell4__SKU1  c_Cell4__SKU2  c_Cell4__SKU3  \\\n",
       "0         2851.0            0.0         4334.0            0.0          903.0         4707.0            0.0            0.0            0.0        11743.0   \n",
       "1         2932.0            0.0         4125.0            0.0         1346.0         3852.0            0.0            0.0            0.0         9556.0   \n",
       "2         2904.0            0.0         4149.0            0.0         1198.0         4139.0            0.0            0.0            0.0        10282.0   \n",
       "\n",
       "   c_Cell4__SKU4  Paint1_Util  Paint2_Util  Quality_Util  Paint1_Queue  Paint2_Queue  Quality_Queue  Forklift_Util  Forklift_Blanking_Queue  \\\n",
       "0         4934.0     0.472565     0.504126      0.432738           0.0           0.0      47.361618       0.606002               157.256744   \n",
       "1         7484.0     0.482683     0.501912      0.436583           0.0           0.0      48.266911       0.599976               166.488724   \n",
       "2         5575.0     0.476897     0.492906      0.429997           0.0           0.0      48.906418       0.576669               159.188507   \n",
       "\n",
       "   Forklift_Press_Queue  Forklift_Assembly_Queue  c_TotalProducts  SKU1_VA_Time  SKU1_Transport_Time  SKU1_Wait_Time  SKU2_VA_Time  SKU2_Transport_Time  \\\n",
       "0            142.123962               137.454849          54377.0      1.525651             0.536810        0.587305      1.522853             0.532394   \n",
       "1            142.113663               140.757584          54857.0      1.525665             0.534195        0.684177      1.522836             0.535767   \n",
       "2            148.427689               142.653366          54052.0      1.525644             0.535403        0.898331      1.522821             0.535631   \n",
       "\n",
       "   SKU2_Wait_Time  SKU3_VA_Time  SKU3_Transport_Time  SKU3_Wait_Time  SKU4_VA_Time  SKU4_Transport_Time  SKU4_Wait_Time  Blanking_Queue  Time_Now  \n",
       "0        0.441645      1.525071             0.537617        0.453650      1.523338             0.536243        0.473453       58.361450        24  \n",
       "1        0.401993      1.524986             0.536764        0.473677      1.523344             0.534992        0.464380       62.830601        24  \n",
       "2        0.427815      1.525064             0.535925        0.424090      1.523403             0.535077        0.475330       59.365868        24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1) ÏÑ§Ï†ï ¬∑ Î°úÎìú ¬∑ Í≥µÌÜµ Ïú†Ìã∏\n",
    "# ============================================\n",
    "# -*- coding: utf-8 -*-\n",
    "import os, re, json, math, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "CSV_PATH = \"./Final Results Extended.csv\"   # ÌïÑÏöîÏãú Î≥ÄÍ≤Ω\n",
    "OUT_DIR  = \"./outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 160)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "# ---- Îç∞Ïù¥ÌÑ∞ Î°úÎìú ----\n",
    "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
    "df = _apply_df_speed_filters(df)  # ‚¨ÖÔ∏è Í≤ΩÎüâ ÌïÑÌÑ∞ Ï†ÅÏö©\n",
    "print(\"=== Dataset shape ===\", df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "def topk(s: pd.Series, k=20):\n",
    "    return s.head(k) if len(s) > k else s\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ece73fe-f7b5-4655-83fc-02d70ccccd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Column groups ===\n",
      "Queue cols  (23): ['Blanking_SKU1_Queue', 'Blanking_SKU2_Queue', 'Blanking_SKU3_Queue', 'Blanking_SKU4_Queue', 'Press1_Queue', 'Press2_Queue', 'Press3_Queue', 'Press4_Queue', 'Cell1_Queue', 'Cell2_Queue'] ...\n",
      "Util cols   (13):  ['Blanking_Util', 'Press1_Util', 'Press2_Util', 'Press3_Util', 'Press4_Util', 'Cell1_Util', 'Cell2_Util', 'Cell3_Util', 'Cell4_Util', 'Paint1_Util'] ...\n",
      "Cycle cols  (0): []\n",
      "Cell cols   (16):  ['c_Cell1_SKU1', 'c_Cell1__SKU2', 'c_Cell1__SKU3', 'c_Cell1__SKU4', 'c_Cell2__SKU1', 'c_Cell2__SKU2', 'c_Cell2__SKU3', 'c_Cell2__SKU4', 'c_Cell3__SKU1', 'c_Cell3__SKU2'] ...\n",
      "\n",
      "=== Detected SKUs === ['1', '2', '3', '4']\n",
      "\n",
      "=== SKU targets overview (first 2) ===\n",
      "SKU1 LT: SKU1_LeadTime_composed (VA+WAIT+LIFT), PROD: Total_SKU1 | #cell_cols=3\n",
      "SKU2 LT: SKU2_LeadTime_composed (VA+WAIT+LIFT), PROD: Total_SKU2 | #cell_cols=4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 2) Ïª¨Îüº Ïù∏Ïãù ¬∑ SKU ÌÉÄÍπÉ ¬∑ ÌÜµÌï© Î¶¨ÎìúÌÉÄÏûÑ(Î©îÎ™®Î¶¨ ÏïàÏ†Ñ)\n",
    "# ============================================\n",
    "queue_cols = [c for c in df.columns if c.endswith(\"_Queue\")]\n",
    "util_cols  = [c for c in df.columns if c.endswith(\"_Util\")]\n",
    "cycle_cols = [c for c in df.columns if c.startswith(\"c_Cycle\")]\n",
    "cell_cols  = [c for c in df.columns if c.startswith(\"c_Cell\")]\n",
    "\n",
    "print(\"\\n=== Column groups ===\")\n",
    "print(f\"Queue cols  ({len(queue_cols)}): {queue_cols[:10]}{' ...' if len(queue_cols)>10 else ''}\")\n",
    "print(f\"Util cols   ({len(util_cols)}):  {util_cols[:10]}{' ...' if len(util_cols)>10 else ''}\")\n",
    "print(f\"Cycle cols  ({len(cycle_cols)}): {cycle_cols[:10]}\")\n",
    "print(f\"Cell cols   ({len(cell_cols)}):  {cell_cols[:10]}{' ...' if len(cell_cols)>10 else ''}\")\n",
    "\n",
    "# === SKU ÏûêÎèô ÌÉêÏßÄ ===\n",
    "sku_ids = sorted({re.findall(r\"SKU(\\d+)_\", c)[0] for c in df.columns if re.findall(r\"SKU(\\d+)_\", c)})\n",
    "print(\"\\n=== Detected SKUs ===\", sku_ids)\n",
    "\n",
    "# Î¶¨ÎìúÌÉÄÏûÑ Ïª¨Îüº ÌõÑÎ≥¥\n",
    "LT_PATTERNS = dict(\n",
    "    VA=[\"_VA_Time_sec\", \"_VA_Time\", \"_VA\"],\n",
    "    WAIT=[\"_Wait_Time_sec\", \"_Wait_Time\", \"_Wait\"],\n",
    "    LIFT=[\"_Transport_Time_sec\", \"_Transport_Time\", \"_Transport\", \"_Lift\"],\n",
    "    TOTAL=[\"_Total_sec\", \"_LeadTime_sec\", \"_LeadTime\"]\n",
    ")\n",
    "def find_first_existing(base: str, suffixes: List[str]) -> Optional[str]:\n",
    "    for s in suffixes:\n",
    "        col = base + s\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "# === SKUÎ≥Ñ Î¶¨ÎìúÌÉÄÏûÑ/ÏÉùÏÇ∞Îüâ ÌÉÄÍπÉ ===\n",
    "sku_targets = {}\n",
    "for sid in sku_ids:\n",
    "    base = f\"SKU{sid}\"\n",
    "    col_VA   = find_first_existing(base, LT_PATTERNS[\"VA\"])\n",
    "    col_WAIT = find_first_existing(base, LT_PATTERNS[\"WAIT\"])\n",
    "    col_LIFT = find_first_existing(base, LT_PATTERNS[\"LIFT\"])\n",
    "    col_TOT  = find_first_existing(base, LT_PATTERNS[\"TOTAL\"])\n",
    "\n",
    "    # Î¶¨ÎìúÌÉÄÏûÑ ÌÉÄÍπÉ\n",
    "    if col_TOT:\n",
    "        lt_series = pd.to_numeric(df[col_TOT], errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "        lt_name, lt_method = col_TOT, \"TOTAL_col\"\n",
    "    else:\n",
    "        VA   = pd.to_numeric(df[col_VA],   errors=\"coerce\").fillna(0.0).astype(\"float32\") if col_VA   else 0.0\n",
    "        WAIT = pd.to_numeric(df[col_WAIT], errors=\"coerce\").fillna(0.0).astype(\"float32\") if col_WAIT else 0.0\n",
    "        LIFT = pd.to_numeric(df[col_LIFT], errors=\"coerce\").fillna(0.0).astype(\"float32\") if col_LIFT else 0.0\n",
    "        lt_series = pd.Series(VA, index=df.index) + pd.Series(WAIT, index=df.index) + pd.Series(LIFT, index=df.index)\n",
    "        lt_series = lt_series.astype(\"float32\")\n",
    "        lt_name, lt_method = f\"{base}_LeadTime_composed\", \"VA+WAIT+LIFT\"\n",
    "\n",
    "    # ÏÉùÏÇ∞Îüâ ÌÉÄÍπÉ: Ìï¥Îãπ SKUÏùò ÏÖÄ Ï∂úÎ†• Ìï©\n",
    "    cell_cols_sku = [c for c in cell_cols if re.search(fr\"__SKU{sid}\\b\", c)]\n",
    "    if cell_cols_sku:\n",
    "        prod_series = to_numeric_df(df[cell_cols_sku]).sum(axis=1).astype(\"float32\")\n",
    "        prod_name   = f\"Total_SKU{sid}\"\n",
    "    else:\n",
    "        prod_series = pd.Series(0.0, index=df.index, dtype=\"float32\")\n",
    "        prod_name   = f\"Total_SKU{sid}_zeros\"\n",
    "\n",
    "    sku_targets[sid] = dict(\n",
    "        lead_time=lt_series, lead_time_name=lt_name, lead_time_method=lt_method,\n",
    "        production=prod_series, production_name=prod_name, cell_cols=cell_cols_sku\n",
    "    )\n",
    "\n",
    "print(\"\\n=== SKU targets overview (first 2) ===\")\n",
    "for sid in sku_ids[:2]:\n",
    "    print(f\"SKU{sid} LT: {sku_targets[sid]['lead_time_name']} ({sku_targets[sid]['lead_time_method']}), \"\n",
    "          f\"PROD: {sku_targets[sid]['production_name']} | #cell_cols={len(sku_targets[sid]['cell_cols'])}\")\n",
    "\n",
    "# === ÌÜµÌï© ÌÉÄÍπÉ ===\n",
    "# ÏÉùÏÇ∞Îüâ(ÌÜµÌï©)\n",
    "if \"c_TotalProducts\" in df.columns:\n",
    "    total_prod = pd.to_numeric(df[\"c_TotalProducts\"], errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "else:\n",
    "    total_prod = to_numeric_df(df[cell_cols]).sum(axis=1).astype(\"float32\")\n",
    "\n",
    "# Î¶¨ÎìúÌÉÄÏûÑ(ÏÉùÏÇ∞Îüâ Í∞ÄÏ§ëÌèâÍ∑†, Î©îÎ™®Î¶¨ ÏïàÏ†Ñ)\n",
    "N = len(df)\n",
    "numerator = np.zeros(N, dtype=np.float32)  # Œ£(lt_k * prod_k)\n",
    "weights   = np.zeros(N, dtype=np.float32)  # Œ£(prod_k)\n",
    "sum_lt    = np.zeros(N, dtype=np.float32)  # fallback ÌèâÍ∑† Î∂ÑÏûê\n",
    "k_count   = 0\n",
    "\n",
    "for sid in sku_ids:\n",
    "    lt = sku_targets[sid][\"lead_time\"].values\n",
    "    pr = sku_targets[sid][\"production\"].values\n",
    "    numerator += lt * pr\n",
    "    weights   += pr\n",
    "    sum_lt    += lt\n",
    "    k_count   += 1\n",
    "\n",
    "fallback_mean = (sum_lt / max(k_count, 1)).astype(\"float32\")\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    weighted_lt = np.where(weights > 0.0, numerator / weights, fallback_mean)\n",
    "agg_lead_time = pd.Series(weighted_lt, index=df.index, name=\"Agg_LeadTime_weighted\").astype(\"float32\")\n",
    "\n",
    "del numerator, weights, sum_lt; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a55911-3d1c-4998-ab1f-7b203b761003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ÏÉùÏÇ∞Îüâ Í∏∞Ï§Ä Î≥ëÎ™© ÎπàÎèÑ ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>top1_count</th>\n",
       "      <th>mean_target</th>\n",
       "      <th>std_target</th>\n",
       "      <th>target_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warehouse1_Queue</td>\n",
       "      <td>77631</td>\n",
       "      <td>54858.582031</td>\n",
       "      <td>1095.462769</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forklift_Blanking_Queue</td>\n",
       "      <td>53681</td>\n",
       "      <td>54578.960938</td>\n",
       "      <td>1087.814575</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warehouse_3_Queue</td>\n",
       "      <td>1307</td>\n",
       "      <td>55135.089844</td>\n",
       "      <td>1061.024292</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warehouse_4_Queue</td>\n",
       "      <td>36</td>\n",
       "      <td>56690.417969</td>\n",
       "      <td>646.384399</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forklift_Press_Queue</td>\n",
       "      <td>9</td>\n",
       "      <td>54510.332031</td>\n",
       "      <td>932.098145</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Press4_Queue</td>\n",
       "      <td>6</td>\n",
       "      <td>55440.832031</td>\n",
       "      <td>665.971619</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press2_Queue</td>\n",
       "      <td>5</td>\n",
       "      <td>55408.398438</td>\n",
       "      <td>477.534607</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bneck  top1_count   mean_target   std_target      target_name\n",
       "0         Warehouse1_Queue       77631  54858.582031  1095.462769  TotalProduction\n",
       "1  Forklift_Blanking_Queue       53681  54578.960938  1087.814575  TotalProduction\n",
       "2        Warehouse_3_Queue        1307  55135.089844  1061.024292  TotalProduction\n",
       "3        Warehouse_4_Queue          36  56690.417969   646.384399  TotalProduction\n",
       "4     Forklift_Press_Queue           9  54510.332031   932.098145  TotalProduction\n",
       "5             Press4_Queue           6  55440.832031   665.971619  TotalProduction\n",
       "6             Press2_Queue           5  55408.398438   477.534607  TotalProduction\n",
       "7      Blanking_SKU3_Queue           1      0.000000          NaN  TotalProduction"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Î¶¨ÎìúÌÉÄÏûÑ Í∏∞Ï§Ä Î≥ëÎ™© ÎπàÎèÑ ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>top1_count</th>\n",
       "      <th>mean_target</th>\n",
       "      <th>std_target</th>\n",
       "      <th>target_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warehouse1_Queue</td>\n",
       "      <td>77631</td>\n",
       "      <td>2.513333</td>\n",
       "      <td>0.023924</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forklift_Blanking_Queue</td>\n",
       "      <td>53681</td>\n",
       "      <td>2.505023</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warehouse_3_Queue</td>\n",
       "      <td>1307</td>\n",
       "      <td>2.577764</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warehouse_4_Queue</td>\n",
       "      <td>36</td>\n",
       "      <td>2.568670</td>\n",
       "      <td>0.025048</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forklift_Press_Queue</td>\n",
       "      <td>9</td>\n",
       "      <td>2.501076</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Press4_Queue</td>\n",
       "      <td>6</td>\n",
       "      <td>2.546885</td>\n",
       "      <td>0.043715</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press2_Queue</td>\n",
       "      <td>5</td>\n",
       "      <td>2.540109</td>\n",
       "      <td>0.018334</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bneck  top1_count  mean_target  std_target  target_name\n",
       "0         Warehouse1_Queue       77631     2.513333    0.023924  AggLeadTime\n",
       "1  Forklift_Blanking_Queue       53681     2.505023    0.017277  AggLeadTime\n",
       "2        Warehouse_3_Queue        1307     2.577764    0.035883  AggLeadTime\n",
       "3        Warehouse_4_Queue          36     2.568670    0.025048  AggLeadTime\n",
       "4     Forklift_Press_Queue           9     2.501076    0.016981  AggLeadTime\n",
       "5             Press4_Queue           6     2.546885    0.043715  AggLeadTime\n",
       "6             Press2_Queue           5     2.540109    0.018334  AggLeadTime\n",
       "7      Blanking_SKU3_Queue           1     0.000000         NaN  AggLeadTime"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3) Î≥ëÎ™© ÎùºÎ≤®ÎßÅ ¬∑ ÏöîÏïΩÌëú(Ï†ÑÏ≤¥/ÌÜµÌï©) ¬∑ SKU√óÎ≥ëÎ™© Ïó∞Í≥ÑÌëú\n",
    "# ============================================\n",
    "Q = to_numeric_df(df[[c for c in df.columns if c.endswith(\"_Queue\")]])\n",
    "if Q.shape[1] == 0:\n",
    "    raise ValueError(\"Queue Í≥ÑÏó¥ Ïª¨ÎüºÏù¥ ÏóÜÏäµÎãàÎã§.\")\n",
    "df[\"_bneck\"] = Q.idxmax(axis=1)  # Í∞Å Ìñâ ÏµúÎåÄ QueueÏùò Ïª¨ÎüºÎ™Ö\n",
    "\n",
    "def compute_bneck_stats(target: pd.Series, name: str, out_csv: str):\n",
    "    tmp = pd.DataFrame({\"bneck\": df[\"_bneck\"].astype(\"category\"), \"val\": target.astype(\"float32\")})\n",
    "    stats = tmp.groupby(\"bneck\", observed=False).agg(\n",
    "        top1_count=(\"bneck\", \"count\"),\n",
    "        mean_target=(\"val\", \"mean\"),\n",
    "        std_target=(\"val\", \"std\")\n",
    "    ).sort_values(\"top1_count\", ascending=False).reset_index()\n",
    "    stats[\"target_name\"] = name\n",
    "    stats.to_csv(ensure_dir(os.path.join(OUT_DIR, out_csv)), index=False)\n",
    "    return stats\n",
    "\n",
    "bneck_total_prod = compute_bneck_stats(total_prod, \"TotalProduction\", \"bottleneck_totalProduction.csv\")\n",
    "bneck_agg_lt     = compute_bneck_stats(agg_lead_time, \"AggLeadTime\", \"bottleneck_aggLeadTime.csv\")\n",
    "\n",
    "print(\"\\n=== ÏÉùÏÇ∞Îüâ Í∏∞Ï§Ä Î≥ëÎ™© ÎπàÎèÑ ===\")\n",
    "display(bneck_total_prod.head(10))\n",
    "\n",
    "print(\"\\n=== Î¶¨ÎìúÌÉÄÏûÑ Í∏∞Ï§Ä Î≥ëÎ™© ÎπàÎèÑ ===\")\n",
    "display(bneck_agg_lt.head(10))\n",
    "\n",
    "TOP_BNECKS = list(bneck_total_prod[\"bneck\"].head(8).values)  # ÎπàÎèÑ ÏÉÅÏúÑ N\n",
    "for sid in sku_ids:\n",
    "    lt = sku_targets[sid][\"lead_time\"].astype(\"float32\")\n",
    "    tmp = pd.DataFrame({\"bneck\": df[\"_bneck\"], \"lt\": lt})\n",
    "    tmp[\"bneck_top\"] = np.where(tmp[\"bneck\"].isin(TOP_BNECKS), tmp[\"bneck\"], \"Other\")\n",
    "    grp = tmp.groupby(\"bneck_top\")[\"lt\"].agg([\"count\",\"mean\",\"std\"]).sort_values(\"count\", ascending=False)\n",
    "    grp.to_csv(ensure_dir(os.path.join(OUT_DIR, f\"sku_bneck_effect_SKU{sid}.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1412673-e3a7-4347-be78-3924d1a957d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc28a374-ad40-444b-9361-135715171073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPEED] limit SKUs ‚Üí top 3: ['2', '3', '4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Project\\Python_Source\\Test01\\.venv\\Lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:19: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "\n",
      "=== AGG Metrics ===\n",
      "{'RF_LT': 0.8874460359017269, 'RG_LT': {'MAE': 0.005, 'RMSE': 0.016, 'R2': 0.5805}, 'RF_PR': 0.9880771185836398, 'RG_PR': {'MAE': 120.036, 'RMSE': 167.721, 'R2': 0.9785}}\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4) ÌîºÏ≤ò Íµ¨ÏÑ±(ÎàÑÏàò Î∞©ÏßÄ + Î≥ëÎ™© One-Hot) ¬∑ Î™®Îç∏ ÌïôÏäµ(RF & Ridge)\n",
    "# ============================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (Ï§ëÏöî) SKU Î£®ÌîÑ Ï†úÌïú: ÏÉùÏÇ∞Îüâ ÏÉÅÏúÑ KÍ∞úÎßå\n",
    "sku_ids = limit_top_k_skus(sku_ids, sku_targets, k=TOP_SKU_K)\n",
    "\n",
    "# === ÌÜµÌï©(AGG) Î™®Îç∏ ===\n",
    "# LeadTime(AGG)\n",
    "X_lt_agg = build_features_for_leadtime(df, exclude_cols=[], add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "y_lt_agg = agg_lead_time.values\n",
    "rf_lt_agg, splits_lt_agg, m_rf_lt_agg, fi_lt_agg, pi_lt_agg = train_rf(X_lt_agg, y_lt_agg)\n",
    "rg_lt_agg, splits_rg_lt_agg, m_rg_lt_agg, coef_lt_agg, beta_std_lt_agg = train_ridge(X_lt_agg, y_lt_agg)\n",
    "\n",
    "# üëç ÌÉÑÎ†•ÎèÑ 5Î≤à ÏÖÄÏóêÏÑú Ïì∞Í∏∞ ÏúÑÌïú 'ÌïôÏäµ Ïãú ÌîºÏ≤ò Î¶¨Ïä§Ìä∏' Ï†ÄÏû• (ÏÇ≠Ï†ú Ï†ÑÏóê!)\n",
    "FEATS_AG_LT = X_lt_agg.columns.tolist()\n",
    "\n",
    "if fi_lt_agg is not None:\n",
    "    fi_lt_agg.to_csv(ensure_dir(os.path.join(OUT_DIR, \"fi_leadtime_AGG.csv\")))\n",
    "if pi_lt_agg is not None:\n",
    "    pi_lt_agg.to_csv(ensure_dir(os.path.join(OUT_DIR, \"pi_leadtime_AGG.csv\")))\n",
    "coef_lt_agg.to_csv(ensure_dir(os.path.join(OUT_DIR, \"ridge_coef_leadtime_AGG.csv\")))\n",
    "beta_std_lt_agg.to_csv(ensure_dir(os.path.join(OUT_DIR, \"ridge_betaStd_leadtime_AGG.csv\")))\n",
    "if ENABLE_PLOTS and fi_lt_agg is not None:\n",
    "    plt.figure(figsize=(8,6)); topk(fi_lt_agg,20).iloc[::-1].plot(kind=\"barh\")\n",
    "    plt.title(\"RF FI (LeadTime) - AGG\"); savefig(os.path.join(OUT_DIR,\"fi_leadtime_AGG_top20.png\"))\n",
    "\n",
    "del X_lt_agg; gc.collect()\n",
    "\n",
    "# Production(AGG)\n",
    "X_pr_agg = build_features_for_production(df, exclude_cols=[])\n",
    "y_pr_agg = total_prod.values\n",
    "rf_pr_agg, splits_pr_agg, m_rf_pr_agg, fi_pr_agg, pi_pr_agg = train_rf(X_pr_agg, y_pr_agg)\n",
    "rg_pr_agg, splits_rg_pr_agg, m_rg_pr_agg, coef_pr_agg, beta_std_pr_agg = train_ridge(X_pr_agg, y_pr_agg)\n",
    "\n",
    "# üëç ÌÉÑÎ†•ÎèÑ 5Î≤à ÏÖÄÏóêÏÑú Ïì∞Í∏∞ ÏúÑÌïú 'ÌïôÏäµ Ïãú ÌîºÏ≤ò Î¶¨Ïä§Ìä∏' Ï†ÄÏû• (ÏÇ≠Ï†ú Ï†ÑÏóê!)\n",
    "FEATS_AG_PR = X_pr_agg.columns.tolist()\n",
    "\n",
    "if fi_pr_agg is not None:\n",
    "    fi_pr_agg.to_csv(ensure_dir(os.path.join(OUT_DIR, \"fi_production_AGG.csv\")))\n",
    "if pi_pr_agg is not None:\n",
    "    pi_pr_agg.to_csv(ensure_dir(os.path.join(OUT_DIR, \"pi_production_AGG.csv\")))\n",
    "coef_pr_agg.to_csv(ensure_dir(os.path.join(OUT_DIR, \"ridge_coef_production_AGG.csv\")))\n",
    "beta_std_pr_agg.to_csv(ensure_dir(os.path.join(OUT_DIR, \"ridge_betaStd_production_AGG.csv\")))\n",
    "if ENABLE_PLOTS and fi_pr_agg is not None:\n",
    "    plt.figure(figsize=(8,6)); topk(fi_pr_agg,20).iloc[::-1].plot(kind=\"barh\")\n",
    "    plt.title(\"RF FI (Production) - AGG\"); savefig(os.path.join(OUT_DIR, \"fi_production_AGG_top20.png\"))\n",
    "\n",
    "del X_pr_agg; gc.collect()\n",
    "\n",
    "print(\"\\n=== AGG Metrics ===\")\n",
    "print({\"RF_LT\": m_rf_lt_agg, \"RG_LT\": m_rg_lt_agg, \"RF_PR\": m_rf_pr_agg, \"RG_PR\": m_rg_pr_agg})\n",
    "\n",
    "# === SKUÎ≥Ñ Î™®Îç∏ ===\n",
    "per_sku_results = {}\n",
    "for sid in sku_ids:\n",
    "    # LeadTime\n",
    "    y_lt = sku_targets[sid][\"lead_time\"].values\n",
    "    exclude_lt = set(sku_targets[sid][\"cell_cols\"])\n",
    "    exclude_lt |= {c for c in df.columns if c.startswith(f\"SKU{sid}_\") and time_like_regex.search(c)}\n",
    "    X_lt = build_features_for_leadtime(df, list(exclude_lt), add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "\n",
    "    lead_pack = None\n",
    "    if X_lt.shape[1] > 0:\n",
    "        rf_lt, spl_lt, m_rf_lt, fi_lt, pi_lt = train_rf(X_lt, y_lt)\n",
    "        rg_lt, spl_rg_lt, m_rg_lt, coef_lt, beta_std_lt = train_ridge(X_lt, y_lt)\n",
    "\n",
    "        if fi_lt is not None:\n",
    "            fi_lt.to_csv(ensure_dir(os.path.join(OUT_DIR, f\"fi_leadtime_SKU{sid}.csv\")))\n",
    "        if pi_lt is not None:\n",
    "            pi_lt.to_csv(ensure_dir(os.path.join(OUT_DIR, f\"pi_leadtime_SKU{sid}.csv\")))\n",
    "        coef_lt.to_csv(ensure_dir(os.path.join(OUT_DIR, f\"ridge_coef_leadtime_SKU{sid}.csv\")))\n",
    "        beta_std_lt.to_csv(ensure_dir(os.path.join(OUT_DIR, f\"ridge_betaStd_leadtime_SKU{sid}.csv\")))\n",
    "\n",
    "        if ENABLE_PLOTS and fi_lt is not None:\n",
    "            plt.figure(figsize=(8,6)); topk(fi_lt,20).iloc[::-1].plot(kind=\"barh\")\n",
    "            plt.title(f\"RF FI (LeadTime) - SKU{sid}\"); savefig(os.path.join(OUT_DIR, f\"fi_leadtime_SKU{sid}_top20.png\"))\n",
    "\n",
    "        lead_pack = {\n",
    "            \"rf\": (rf_lt, spl_lt, m_rf_lt),\n",
    "            \"rg\": (rg_lt, spl_rg_lt, m_rg_lt),\n",
    "            \"feats\": X_lt.columns.tolist()\n",
    "        }\n",
    "\n",
    "        del X_lt; gc.collect()\n",
    "    else:\n",
    "        print(f\"[WARN] SKU{sid}: LeadTime features empty ‚Üí skip\")\n",
    "\n",
    "    # Production\n",
    "    y_pr = sku_targets[sid][\"production\"].values\n",
    "    exclude_pr = set(sku_targets[sid][\"cell_cols\"])\n",
    "    X_pr = build_features_for_production(df, list(exclude_pr))\n",
    "\n",
    "    prod_pack = None\n",
    "    if X_pr.shape[1] > 0:\n",
    "        rf_pr, spl_pr, m_rf_pr, fi_pr, pi_pr = train_rf(X_pr, y_pr)\n",
    "        rg_pr, spl_rg_pr, m_rg_pr, coef_pr, beta_std_pr = train_ridge(X_pr, y_pr)\n",
    "\n",
    "        if fi_pr is not None:\n",
    "            fi_pr.to_csv(ensure_dir(os.path.join(OUT_DIR, f\"fi_production_SKU{sid}.csv\")))\n",
    "        if pi_pr is not None:\n",
    "            pi_pr.to_csv(ensure_dir(os.path.join(OUT_DIR, f\"pi_production_SKU{sid}.csv\")))\n",
    "        coef_pr.to_csv(ensure_dir(os.path.join(OUT_DIR, f\"ridge_coef_production_SKU{sid}.csv\")))\n",
    "        beta_std_pr.to_csv(ensure_dir(os.path.join(OUT_DIR, f\"ridge_betaStd_production_SKU{sid}.csv\")))\n",
    "\n",
    "        if ENABLE_PLOTS and fi_pr is not None:\n",
    "            plt.figure(figsize=(8,6)); topk(fi_pr,20).iloc[::-1].plot(kind=\"barh\")\n",
    "            plt.title(f\"RF FI (Production) - SKU{sid}\"); savefig(os.path.join(OUT_DIR, f\"fi_production_SKU{sid}_top20.png\"))\n",
    "\n",
    "        prod_pack = {\n",
    "            \"rf\": (rf_pr, spl_pr, m_rf_pr),\n",
    "            \"rg\": (rg_pr, spl_rg_pr, m_rg_pr),\n",
    "            \"feats\": X_pr.columns.tolist()\n",
    "        }\n",
    "\n",
    "        del X_pr; gc.collect()\n",
    "\n",
    "    per_sku_results[sid] = {\"lead_time\": lead_pack, \"production\": prod_pack}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a72d217-6575-4348-b657-81479a5c1dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AGG Î¶¨ÎìúÌÉÄÏûÑ ÌÉÑÎ†•ÎèÑ (ÏÉÅÏúÑ NÍ∞ú ÌîºÏ≤ò) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blanking_SKU1_Queue</td>\n",
       "      <td>0.008873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Press1_Util</td>\n",
       "      <td>0.004446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blanking_SKU4_Queue</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>-0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blanking_SKU2_Queue</td>\n",
       "      <td>-0.002123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press2_Util</td>\n",
       "      <td>-0.040837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Press3_Util</td>\n",
       "      <td>-0.040982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blanking_Util</td>\n",
       "      <td>-0.672543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature     slope\n",
       "1  Blanking_SKU1_Queue  0.008873\n",
       "5          Press1_Util  0.004446\n",
       "4  Blanking_SKU4_Queue  0.000852\n",
       "3  Blanking_SKU3_Queue -0.001244\n",
       "2  Blanking_SKU2_Queue -0.002123\n",
       "6          Press2_Util -0.040837\n",
       "7          Press3_Util -0.040982\n",
       "0        Blanking_Util -0.672543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AGG ÏÉùÏÇ∞Îüâ ÌÉÑÎ†•ÎèÑ (ÏÉÅÏúÑ NÍ∞ú ÌîºÏ≤ò) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blanking_Util</td>\n",
       "      <td>225.401591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Press1_Util</td>\n",
       "      <td>3.245672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blanking_SKU2_Queue</td>\n",
       "      <td>1.616548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1.166340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blanking_SKU1_Queue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blanking_SKU4_Queue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press2_Util</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Press3_Util</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature       slope\n",
       "0        Blanking_Util  225.401591\n",
       "5          Press1_Util    3.245672\n",
       "2  Blanking_SKU2_Queue    1.616548\n",
       "3  Blanking_SKU3_Queue    1.166340\n",
       "1  Blanking_SKU1_Queue    0.000000\n",
       "4  Blanking_SKU4_Queue    0.000000\n",
       "6          Press2_Util    0.000000\n",
       "7          Press3_Util    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticity (lite) CSVs saved to: ./outputs\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 5) Í∞ÑÏù¥ ÌÉÑÎ†•ÎèÑ(ÎØºÍ∞êÎèÑ): splits ÎØ∏ÏÇ¨Ïö©, Ï†ÑÏ≤¥ X Ï†ïÎ†¨ ÌõÑ Top-NÎßå Î≥ÄÎèô\n",
    "# ============================================\n",
    "from numpy.random import default_rng\n",
    "RANDOM_STATE = 42\n",
    "_rng = default_rng(RANDOM_STATE)\n",
    "\n",
    "def pick_topN_features_from_X(X: pd.DataFrame, topk: int = ELAS_FEATURES_TOPK,\n",
    "                              only_queue_util: bool = ONLY_QUEUE_UTIL) -> List[str]:\n",
    "    cols = list(X.columns)\n",
    "    if only_queue_util:\n",
    "        base = [c for c in cols if c.endswith(\"_Queue\") or c.endswith(\"_Util\")]\n",
    "        if base: return base[:topk]\n",
    "    # fallback: Ìï¥ÏÑù Ìé∏ÏùòÏÉÅ BNECK Ïõê-Ìï´ÏùÄ Ï†úÏô∏\n",
    "    return [c for c in cols if not c.startswith(\"BNECK_\")][:topk]\n",
    "\n",
    "def align_X_for_model(X_built: pd.DataFrame, trained_feats: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"ÌïôÏäµ Ïãú ÌîºÏ≤ò Ïù¥Î¶Ñ/ÏàúÏÑúÏôÄ Ï†ïÌôïÌûà ÏùºÏπòÌïòÎèÑÎ°ù reindex.\"\"\"\n",
    "    return X_built.reindex(columns=trained_feats, fill_value=0.0)\n",
    "\n",
    "def _suggest_h(x: np.ndarray) -> float:\n",
    "    if x.size == 0: return 1.0\n",
    "    q25, q75 = np.percentile(x, [25, 75]); iqr = q75 - q25\n",
    "    if iqr > 0: return float(iqr * 0.05)\n",
    "    std = np.std(x); return float(std * 0.1 if std > 0 else 1.0)\n",
    "\n",
    "def fd_slope_mean(model, X_full: pd.DataFrame, feature: str, h: Optional[float]=None,\n",
    "                  sample_n: int=ELAS_SAMPLE_N) -> Optional[float]:\n",
    "    \"\"\"X_fullÏùÄ ÌïôÏäµ ÌîºÏ≤ò Ï†ÑÎ∂Ä Ìè¨Ìï®(ÏàúÏÑú ÎèôÏùº). featureÎßå ¬±hÎ°ú Î≥ÄÍ≤Ω.\"\"\"\n",
    "    if feature not in X_full.columns: return None\n",
    "    n = len(X_full);  Xs = X_full\n",
    "    if n == 0: return None\n",
    "    if sample_n and sample_n < n:\n",
    "        idx = _rng.choice(n, size=sample_n, replace=False)\n",
    "        Xs = X_full.iloc[idx].copy()\n",
    "    else:\n",
    "        Xs = X_full.copy()\n",
    "    x = Xs[feature].to_numpy()\n",
    "    h = _suggest_h(x) if h is None else h\n",
    "    if h == 0: return 0.0\n",
    "    X_minus = Xs.copy(); X_plus = Xs.copy()\n",
    "    X_minus[feature] = x - h\n",
    "    X_plus[feature]  = x + h\n",
    "    y_m = model.predict(X_minus).mean()\n",
    "    y_p = model.predict(X_plus).mean()\n",
    "    return float((y_p - y_m) / (2.0 * h))\n",
    "\n",
    "def run_elasticity_block(tag: str, model, X_full: pd.DataFrame, features: List[str],\n",
    "                         sample_n: int=ELAS_SAMPLE_N) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for f in features:\n",
    "        s = fd_slope_mean(model, X_full, f, h=None, sample_n=sample_n)\n",
    "        rows.append({\"feature\": f, \"slope\": s})\n",
    "    out = pd.DataFrame(rows).dropna().sort_values(\"slope\", ascending=False)\n",
    "    out.to_csv(os.path.join(OUT_DIR, f\"elasticity_{tag}.csv\"), index=False)\n",
    "    return out\n",
    "\n",
    "elasticity_outputs = {}\n",
    "\n",
    "# ---------- AGG (ÌÜµÌï©) ----------\n",
    "# ÌïôÏäµ ÎãπÏãú ÌîºÏ≤ò Î™©Î°ùÏúºÎ°ú Ï†ïÎ†¨\n",
    "X_base_lt_built = build_features_for_leadtime(df, exclude_cols=[], add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "X_full_lt = align_X_for_model(X_base_lt_built, FEATS_AG_LT)\n",
    "feats_lt = pick_topN_features_from_X(X_full_lt, ELAS_FEATURES_TOPK, ONLY_QUEUE_UTIL)\n",
    "\n",
    "X_base_pr_built = build_features_for_production(df, exclude_cols=[])\n",
    "X_full_pr = align_X_for_model(X_base_pr_built, FEATS_AG_PR)\n",
    "feats_pr = pick_topN_features_from_X(X_full_pr, ELAS_FEATURES_TOPK, ONLY_QUEUE_UTIL)\n",
    "\n",
    "if feats_lt:\n",
    "    el_lt = run_elasticity_block(\"leadtime_AGG_fast_lite\", rf_lt_agg, X_full_lt, feats_lt, ELAS_SAMPLE_N)\n",
    "    elasticity_outputs[\"leadtime_AGG\"] = el_lt\n",
    "    print(\"\\n=== AGG Î¶¨ÎìúÌÉÄÏûÑ ÌÉÑÎ†•ÎèÑ (ÏÉÅÏúÑ NÍ∞ú ÌîºÏ≤ò) ===\")\n",
    "    display(el_lt.head(15))\n",
    "else:\n",
    "    print(\"[Elasticity] AGG Î¶¨ÎìúÌÉÄÏûÑ: ÌõÑÎ≥¥ ÌîºÏ≤ò ÏóÜÏùå ‚Üí Í±¥ÎÑàÎúÄ\")\n",
    "\n",
    "if feats_pr:\n",
    "    el_pr = run_elasticity_block(\"production_AGG_fast_lite\", rf_pr_agg, X_full_pr, feats_pr, ELAS_SAMPLE_N)\n",
    "    elasticity_outputs[\"production_AGG\"] = el_pr\n",
    "    print(\"\\n=== AGG ÏÉùÏÇ∞Îüâ ÌÉÑÎ†•ÎèÑ (ÏÉÅÏúÑ NÍ∞ú ÌîºÏ≤ò) ===\")\n",
    "    display(el_pr.head(15))\n",
    "else:\n",
    "    print(\"[Elasticity] AGG ÏÉùÏÇ∞Îüâ: ÌõÑÎ≥¥ ÌîºÏ≤ò ÏóÜÏùå ‚Üí Í±¥ÎÑàÎúÄ\")\n",
    "\n",
    "# ---------- SKUÎ≥Ñ ----------\n",
    "per_sku_elasticity = {}\n",
    "for sid, packs in per_sku_results.items():\n",
    "    per_sku_elasticity[sid] = {}\n",
    "\n",
    "    # LeadTime\n",
    "    if packs.get(\"lead_time\") is not None:\n",
    "        exclude_lt = set(sku_targets[sid][\"cell_cols\"])\n",
    "        exclude_lt |= {c for c in df.columns if c.startswith(f\"SKU{sid}_\") and time_like_regex.search(c)}\n",
    "        X_lt_sku_built = build_features_for_leadtime(df, list(exclude_lt), add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "\n",
    "        trained_feats_lt = packs[\"lead_time\"][\"feats\"]\n",
    "        X_lt_full = align_X_for_model(X_lt_sku_built, trained_feats_lt)\n",
    "        cand_lt = pick_topN_features_from_X(X_lt_full, ELAS_FEATURES_TOPK, ONLY_QUEUE_UTIL)\n",
    "        # ÌïôÏäµ ÎãπÏãú ÏûàÏóàÎçò Ïó¥Îßå ÎÇ®ÍπÄ\n",
    "        cand_lt = [c for c in cand_lt if c in trained_feats_lt]\n",
    "        if cand_lt:\n",
    "            rf = packs[\"lead_time\"][\"rf\"][0]\n",
    "            out = run_elasticity_block(f\"leadtime_SKU{sid}_fast_lite\", rf, X_lt_full, cand_lt, ELAS_SAMPLE_N)\n",
    "            per_sku_elasticity[sid][\"lead_time\"] = out\n",
    "\n",
    "    # Production\n",
    "    if packs.get(\"production\") is not None:\n",
    "        exclude_pr = set(sku_targets[sid][\"cell_cols\"])\n",
    "        X_pr_sku_built = build_features_for_production(df, list(exclude_pr))\n",
    "\n",
    "        trained_feats_pr = packs[\"production\"][\"feats\"]\n",
    "        X_pr_full = align_X_for_model(X_pr_sku_built, trained_feats_pr)\n",
    "        cand_pr = pick_topN_features_from_X(X_pr_full, ELAS_FEATURES_TOPK, ONLY_QUEUE_UTIL)\n",
    "        cand_pr = [c for c in cand_pr if c in trained_feats_pr]\n",
    "        if cand_pr:\n",
    "            rf = packs[\"production\"][\"rf\"][0]\n",
    "            out = run_elasticity_block(f\"production_SKU{sid}_fast_lite\", rf, X_pr_full, cand_pr, ELAS_SAMPLE_N)\n",
    "            per_sku_elasticity[sid][\"production\"] = out\n",
    "\n",
    "print(\"Elasticity (lite) CSVs saved to:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b13bea-032a-462b-a7d2-ff75787e4ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[What-if ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏÑ§Î™Ö]\n",
      "ÌäπÏ†ï Î≥ÄÏàò(Queue, Util Îì±)Î•º Ïù∏ÏúÑÏ†ÅÏúºÎ°ú ¬± Î≥ÄÌôîÏãúÏº∞ÏùÑ Îïå,\n",
      "Î¶¨ÎìúÌÉÄÏûÑÍ≥º ÏÉùÏÇ∞Îüâ ÌèâÍ∑†Ïù¥ ÏñºÎßàÎÇò Îã¨ÎùºÏßÄÎäîÏßÄÎ•º Í≥ÑÏÇ∞Ìïú Í≤∞Í≥ºÏûÖÎãàÎã§.\n",
      "‚Üí base_mean: ÏõêÎûò ÌèâÍ∑†Í∞í, new_mean: Î≥ÄÌôî ÌõÑ ÌèâÍ∑†Í∞í, delta_mean: Ï∞®Ïù¥\n",
      "\n",
      "=== What-if (AGG) ===\n",
      "{\n",
      "  \"lead_time\": {\n",
      "    \"Blanking_Queue_-50\": {\n",
      "      \"base_mean\": 2.510594421587846,\n",
      "      \"new_mean\": 1.8318075097749484,\n",
      "      \"delta_mean\": -0.6787869118128977\n",
      "    },\n",
      "    \"Warehouse1_Queue_-50\": {\n",
      "      \"base_mean\": 2.510594421587846,\n",
      "      \"new_mean\": 2.5106675099329148,\n",
      "      \"delta_mean\": 7.308834506858375e-05\n",
      "    },\n",
      "    \"Quality_Util_+5\": {\n",
      "      \"base_mean\": 2.510594421587846,\n",
      "      \"new_mean\": 2.510832725805052,\n",
      "      \"delta_mean\": 0.00023830421720560935\n",
      "    }\n",
      "  },\n",
      "  \"production\": {\n",
      "    \"Blanking_Queue_-50\": {\n",
      "      \"base_mean\": 54748.176045612076,\n",
      "      \"new_mean\": 54746.31936813327,\n",
      "      \"delta_mean\": -1.856677478805068\n",
      "    },\n",
      "    \"Warehouse1_Queue_-50\": {\n",
      "      \"base_mean\": 54748.176045612076,\n",
      "      \"new_mean\": 54748.18151975673,\n",
      "      \"delta_mean\": 0.005474144651088864\n",
      "    },\n",
      "    \"Quality_Util_+5\": {\n",
      "      \"base_mean\": 54748.176045612076,\n",
      "      \"new_mean\": 57600.20967776429,\n",
      "      \"delta_mean\": 2852.033632152212\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 6) What‚Äëif ÏãúÎÆ¨Î†àÏù¥ÌÑ∞ (AGG & SKUÎ≥Ñ)\n",
    "# ============================================\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "def simulate_delta(model, X_base: pd.DataFrame, deltas: Dict[str, float]) -> Tuple[float, float, float]:\n",
    "    X_sim = X_base.copy()\n",
    "    for k, v in deltas.items():\n",
    "        if k in X_sim.columns:\n",
    "            X_sim[k] = X_sim[k] + v\n",
    "    base_mean = float(model.predict(X_base).mean())\n",
    "    new_mean  = float(model.predict(X_sim).mean())\n",
    "    return base_mean, new_mean, new_mean - base_mean\n",
    "\n",
    "# Í∞ÑÏù¥ ÌÉÑÎ†•ÎèÑ ÏÖÄÏóêÏÑú ÏçºÎçò Ï†ïÎ†¨ Ïú†Ìã∏Ïù¥ ÏóÜÏùÑ ÏàòÎèÑ ÏûàÏúºÎãà Í∞ÄÎìú\n",
    "def align_X_for_model(X_built: pd.DataFrame, trained_feats: List[str]) -> pd.DataFrame:\n",
    "    return X_built.reindex(columns=trained_feats, fill_value=0.0)\n",
    "\n",
    "whatif = {\"AGG\": {\"lead_time\": {}, \"production\": {}}, \"SKU\": {}}\n",
    "\n",
    "# ---------- AGG(ÌÜµÌï©)Ïö© Î≤†Ïù¥Ïä§ X Ïû¨Íµ¨ÏÑ± & Ï†ïÎ†¨ ----------\n",
    "# LeadTime\n",
    "X_lt_agg_built = build_features_for_leadtime(df, exclude_cols=[], add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "X_full_lt_agg  = align_X_for_model(X_lt_agg_built, FEATS_AG_LT)  # ÌïôÏäµ Ïãú ÌîºÏ≤ò ÏàúÏÑú/Ïù¥Î¶ÑÏóê ÎßûÏ∂§\n",
    "sc_lt = get_scenarios(X_full_lt_agg.columns)\n",
    "for name, v in sc_lt.items():\n",
    "    base_m, new_m, d_m = simulate_delta(rf_lt_agg, X_full_lt_agg, {name: v})\n",
    "    whatif[\"AGG\"][\"lead_time\"][f\"{name}_{v:+g}\"] = {\"base_mean\": base_m, \"new_mean\": new_m, \"delta_mean\": d_m}\n",
    "\n",
    "# Production\n",
    "X_pr_agg_built = build_features_for_production(df, exclude_cols=[])\n",
    "X_full_pr_agg  = align_X_for_model(X_pr_agg_built, FEATS_AG_PR)\n",
    "sc_pr = get_scenarios(X_full_pr_agg.columns)\n",
    "for name, v in sc_pr.items():\n",
    "    base_m, new_m, d_m = simulate_delta(rf_pr_agg, X_full_pr_agg, {name: v})\n",
    "    whatif[\"AGG\"][\"production\"][f\"{name}_{v:+g}\"] = {\"base_mean\": base_m, \"new_mean\": new_m, \"delta_mean\": d_m}\n",
    "\n",
    "# ---------- SKUÎ≥Ñ ----------\n",
    "for sid, packs in per_sku_results.items():\n",
    "    whatif[\"SKU\"][sid] = {}\n",
    "\n",
    "    # LeadTime\n",
    "    if packs[\"lead_time\"] is not None:\n",
    "        # Ìï¥Îãπ SKU Î¶¨ÎìúÌÉÄÏûÑ ÌîºÏ≤ò Ïû¨Íµ¨ÏÑ±\n",
    "        exclude_lt = set(sku_targets[sid][\"cell_cols\"])\n",
    "        exclude_lt |= {c for c in df.columns if c.startswith(f\"SKU{sid}_\") and time_like_regex.search(c)}\n",
    "        X_lt_sku_built = build_features_for_leadtime(df, list(exclude_lt), add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "\n",
    "        trained_feats_lt = packs[\"lead_time\"][\"feats\"]  # ÌïôÏäµ Ïãú ÏÇ¨Ïö©Ìïú Ï†ÑÏ≤¥ ÌîºÏ≤ò Î™©Î°ù\n",
    "        X_lt_full = align_X_for_model(X_lt_sku_built, trained_feats_lt)\n",
    "\n",
    "        lt_map = {}\n",
    "        for name, v in WHATIF_SCENARIOS.items():\n",
    "            if name in X_lt_full.columns:  # Ï°¥Ïû¨ÌïòÎäî ÌîºÏ≤òÎßå ÏãúÎÇòÎ¶¨Ïò§ Ï†ÅÏö©\n",
    "                base_m, new_m, d_m = simulate_delta(packs[\"lead_time\"][\"rf\"][0], X_lt_full, {name: v})\n",
    "                lt_map[f\"{name}_{v:+g}\"] = {\"base_mean\": base_m, \"new_mean\": new_m, \"delta_mean\": d_m}\n",
    "        whatif[\"SKU\"][sid][\"lead_time\"] = lt_map\n",
    "\n",
    "    # Production\n",
    "    if packs[\"production\"] is not None:\n",
    "        exclude_pr = set(sku_targets[sid][\"cell_cols\"])\n",
    "        X_pr_sku_built = build_features_for_production(df, list(exclude_pr))\n",
    "\n",
    "        trained_feats_pr = packs[\"production\"][\"feats\"]\n",
    "        X_pr_full = align_X_for_model(X_pr_sku_built, trained_feats_pr)\n",
    "\n",
    "        pr_map = {}\n",
    "        for name, v in WHATIF_SCENARIOS.items():\n",
    "            if name in X_pr_full.columns:\n",
    "                base_m, new_m, d_m = simulate_delta(packs[\"production\"][\"rf\"][0], X_pr_full, {name: v})\n",
    "                pr_map[f\"{name}_{v:+g}\"] = {\"base_mean\": base_m, \"new_mean\": new_m, \"delta_mean\": d_m}\n",
    "        whatif[\"SKU\"][sid][\"production\"] = pr_map\n",
    "\n",
    "# Ï†ÄÏû• Î∞è Ï∂úÎ†•\n",
    "with open(ensure_dir(os.path.join(OUT_DIR, \"whatif_results.json\")), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(whatif, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# --- ÏÑ§Î™Ö Ï∂úÎ†• ---\n",
    "print(\"\\n[What-if ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏÑ§Î™Ö]\")\n",
    "print(\"ÌäπÏ†ï Î≥ÄÏàò(Queue, Util Îì±)Î•º Ïù∏ÏúÑÏ†ÅÏúºÎ°ú ¬± Î≥ÄÌôîÏãúÏº∞ÏùÑ Îïå,\")\n",
    "print(\"Î¶¨ÎìúÌÉÄÏûÑÍ≥º ÏÉùÏÇ∞Îüâ ÌèâÍ∑†Ïù¥ ÏñºÎßàÎÇò Îã¨ÎùºÏßÄÎäîÏßÄÎ•º Í≥ÑÏÇ∞Ìïú Í≤∞Í≥ºÏûÖÎãàÎã§.\")\n",
    "print(\"‚Üí base_mean: ÏõêÎûò ÌèâÍ∑†Í∞í, new_mean: Î≥ÄÌôî ÌõÑ ÌèâÍ∑†Í∞í, delta_mean: Ï∞®Ïù¥\")\n",
    "\n",
    "print(\"\\n=== What-if (AGG) ===\")\n",
    "print(json.dumps(whatif[\"AGG\"], ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328770e8-c141-4e87-acb7-d3fad51fc300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38501f51-01d8-4256-a758-b7b525a044d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "014618f1-e82e-4956-af97-3323eae48203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEFECT PROXY] '_quality_reject_proxy' ÏÉùÏÑ± ÏôÑÎ£å. ÏòàÏãú ÌÜµÍ≥Ñ: {'min': 0.0, 'median': 0.5141528248786926, 'max': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 7a) ÌíàÏßà Îã®Í≥Ñ ÌÉàÎùΩ(Î∂àÎüâ) ÌîÑÎ°ùÏãú ÏÉùÏÑ±\n",
    "#  - Paint1~2 Util, Quality Util/Queue, ÏµúÏ¢Ö ÏÉùÏÇ∞Îüâ Ï¶ùÍ∞ÄÎ∂Ñ(Œî)Î°ú Í∞ÑÏù¥ ÏßÄÌëú Íµ¨ÏÑ±\n",
    "#  - ÌîÑÎ°ùÏãú: ÌÉàÎùΩÏù¥ Ïª§ Î≥¥ÏùºÏàòÎ°ù Í∞í Ï¶ùÍ∞Ä (0~1 Ï†ïÍ∑úÌôî)\n",
    "# ============================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _safe_col(df, name, default=0.0):\n",
    "    return pd.to_numeric(df[name], errors=\"coerce\").fillna(default).astype(\"float32\") if name in df.columns else pd.Series(default, index=df.index, dtype=\"float32\")\n",
    "\n",
    "# 1) ÌïÑÏöîÌïú ÏõêÏ≤ú ÏãúÍ≥ÑÏó¥\n",
    "u_p1   = _safe_col(df, \"Paint1_Util\")\n",
    "u_p2   = _safe_col(df, \"Paint2_Util\")\n",
    "u_q    = _safe_col(df, \"Quality_Util\")\n",
    "q_q    = _safe_col(df, \"Quality_Queue\")\n",
    "tot    = _safe_col(df, \"c_TotalProducts\")\n",
    "\n",
    "# 2) ÏµúÏ¢Ö ÏÇ∞Ï∂ú Ï¶ùÍ∞ÄÎ∂Ñ(Œî) = ÏÉùÏÇ∞ÎüâÏùò 1Ïä§ÌÖù Ï∞®Î∂Ñ (ÏùåÏàòÎäî 0ÏúºÎ°ú ÌÅ¥Î¶Ω)\n",
    "#    ÌÅ∞ Îç∞Ïù¥ÌÑ∞Ïóî ÏïΩÍ∞ÑÏùò ÎÖ∏Ïù¥Ï¶àÍ∞Ä ÏûàÏñ¥ Ïù¥ÎèôÌèâÍ∑†ÏúºÎ°ú Î∂ÄÎìúÎüΩÍ≤å\n",
    "delta_final_raw = tot.diff().fillna(0.0).clip(lower=0).astype(\"float32\")\n",
    "delta_final     = delta_final_raw.rolling(window=5, min_periods=1).mean().astype(\"float32\")\n",
    "\n",
    "# 3) ÏÉÅ¬∑ÌïòÎ•ò \"ÌôúÎèô ÏßÄÏàò\" Íµ¨ÏÑ± (Ïä§ÏºÄÏùº ÌîÑÎ¶¨)\n",
    "#    - ÏÉÅÎ•ò ÌôúÎèô: Paint Í∞ÄÎèô (Î≥ëÎ†¨ Ìï©) & Quality Í∞ÄÎèô\n",
    "#    - ÌïòÎ•ò ÏÇ∞Ï∂ú: ÏµúÏ¢Ö ÏÇ∞Ï∂ú Ï¶ùÍ∞ÄÎ∂Ñ\n",
    "upstream_idx = (u_p1 + u_p2 + u_q).astype(\"float32\")                   # ÏÉÅÎ•ò Í∞ÄÎèô Í∞ïÎèÑ\n",
    "quality_load = (q_q).astype(\"float32\")                                 # ÌíàÏßà ÎåÄÍ∏∞Ïó¥(Ï†ÅÏ≤¥)\n",
    "downstream_y = (delta_final).astype(\"float32\")                          # Ïã§Ï†ú ÏÇ∞Ï∂ú\n",
    "\n",
    "# 4) z-Ï†ïÍ∑úÌôî (Î∂ÑÏÇ∞ 0 Î∞©ÏßÄ)\n",
    "def _z(x):\n",
    "    mu, sd = float(np.nanmean(x)), float(np.nanstd(x))\n",
    "    if not np.isfinite(sd) or sd == 0:\n",
    "        return pd.Series(0.0, index=df.index, dtype=\"float32\")\n",
    "    return ((x - mu) / sd).astype(\"float32\")\n",
    "\n",
    "zu   = _z(upstream_idx)\n",
    "zq   = _z(quality_load)\n",
    "zy   = _z(downstream_y)\n",
    "\n",
    "# 5) Í∞ÑÏù¥ ÌÉàÎùΩ ÌîÑÎ°ùÏãú: ÏÉÅÎ•òÌôúÎèô‚Üë + ÌíàÏßàÏ†ÅÏ≤¥‚Üë ÎåÄÎπÑ ÏÇ∞Ï∂ú‚Üì\n",
    "#    ‚Üí Í∞íÏù¥ ÌÅ¥ÏàòÎ°ù \"ÌÉàÎùΩ/Ïû¨ÏûëÏóÖ/ÌÜµÍ≥ºÏú® Ï†ÄÌïò\" ÏùòÏã¨\n",
    "raw_defect_proxy = (zu + zq - zy).astype(\"float32\")\n",
    "\n",
    "# 6) 0~1 Î≤îÏúÑÎ°ú ÌÅ¥Î¶¨Ìïë & Ï†ïÍ∑úÌôî (Ïù¥ÎèôÏ∞ΩÏúºÎ°ú ÏôÑÎßåÌôî)\n",
    "win = 25\n",
    "proxy_smooth = raw_defect_proxy.rolling(window=win, min_periods=1).mean()\n",
    "mn, mx = float(proxy_smooth.quantile(0.01)), float(proxy_smooth.quantile(0.99))\n",
    "den = (mx - mn) if (mx - mn) > 1e-6 else 1.0\n",
    "quality_reject_proxy = ((proxy_smooth - mn) / den).clip(0, 1).astype(\"float32\")\n",
    "\n",
    "# 7) ÌÉÄÍπÉ ÏãúÎ¶¨Ï¶àÎ°ú dfÏóê Î∂ÄÏ∞©\n",
    "df[\"_quality_reject_proxy\"] = quality_reject_proxy\n",
    "print(\"[DEFECT PROXY] '_quality_reject_proxy' ÏÉùÏÑ± ÏôÑÎ£å. ÏòàÏãú ÌÜµÍ≥Ñ:\",\n",
    "      {\"min\": float(quality_reject_proxy.min()),\n",
    "       \"median\": float(quality_reject_proxy.median()),\n",
    "       \"max\": float(quality_reject_proxy.max())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fbd5b9a-6eb8-47ad-98b5-8124a5c666ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy Í¥ÄÍ≥Ñ ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>count</th>\n",
       "      <th>mean_defect</th>\n",
       "      <th>std_defect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warehouse_4_Queue</td>\n",
       "      <td>36</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.187337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Press2_Queue</td>\n",
       "      <td>5</td>\n",
       "      <td>0.528022</td>\n",
       "      <td>0.216524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warehouse1_Queue</td>\n",
       "      <td>77631</td>\n",
       "      <td>0.521246</td>\n",
       "      <td>0.210814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warehouse_3_Queue</td>\n",
       "      <td>1307</td>\n",
       "      <td>0.504420</td>\n",
       "      <td>0.216034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forklift_Blanking_Queue</td>\n",
       "      <td>53681</td>\n",
       "      <td>0.497501</td>\n",
       "      <td>0.211187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forklift_Press_Queue</td>\n",
       "      <td>9</td>\n",
       "      <td>0.479962</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press4_Queue</td>\n",
       "      <td>6</td>\n",
       "      <td>0.447602</td>\n",
       "      <td>0.117323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bneck  count  mean_defect  std_defect\n",
       "0        Warehouse_4_Queue     36     0.553382    0.187337\n",
       "1             Press2_Queue      5     0.528022    0.216524\n",
       "2         Warehouse1_Queue  77631     0.521246    0.210814\n",
       "3        Warehouse_3_Queue   1307     0.504420    0.216034\n",
       "4  Forklift_Blanking_Queue  53681     0.497501    0.211187\n",
       "5     Forklift_Press_Queue      9     0.479962    0.117338\n",
       "6             Press4_Queue      6     0.447602    0.117323\n",
       "7      Blanking_SKU3_Queue      1     0.000000         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Î≥ëÎ™© ‚Üî Î∂àÎüâ proxy Í¥ÄÍ≥Ñ ÏßëÍ≥Ñ\n",
    "if \"_bneck\" in df.columns and \"_quality_reject_proxy\" in df.columns:\n",
    "    tmp = pd.DataFrame({\n",
    "        \"bneck\": df[\"_bneck\"],\n",
    "        \"defect_proxy\": df[\"_quality_reject_proxy\"].astype(\"float32\")\n",
    "    })\n",
    "    stats = tmp.groupby(\"bneck\").agg(\n",
    "        count=(\"defect_proxy\", \"count\"),\n",
    "        mean_defect=(\"defect_proxy\", \"mean\"),\n",
    "        std_defect=(\"defect_proxy\", \"std\")\n",
    "    ).sort_values(\"mean_defect\", ascending=False).reset_index()\n",
    "\n",
    "    print(\"\\n=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy Í¥ÄÍ≥Ñ ===\")\n",
    "    display(stats.head(15))  # ÏÉÅÏúÑ 15Í∞úÎßå Î≥¥Í∏∞\n",
    "else:\n",
    "    print(\"bneck ÎòêÎäî defect proxy Ïª¨ÎüºÏù¥ ÏóÜÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "370521ca-2909-488c-931e-d9adbf7effc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[Proxy Defect - no leakage] RF score on train: 0.02340521780170579\n",
      "[Proxy Defect - no leakage] Ridge metrics: {'MAE': 0.169, 'RMSE': 0.21, 'R2': 0.0129}\n",
      "\n",
      "=== Defect Proxy - Ridge ÌëúÏ§ÄÌôî Í≥ÑÏàò ÏÉÅÏúÑ (ÎàÑÏàò Ï†úÍ±∞) ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "c_Cell4__SKU3                    0.146085\n",
       "c_Cell3__SKU3                   -0.096936\n",
       "c_Cell1__SKU2                    0.073247\n",
       "Quality_Queue                    0.072795\n",
       "c_Cell1_SKU1                     0.071760\n",
       "c_Cell1__SKU4                    0.060462\n",
       "c_Cell4__SKU4                    0.046548\n",
       "Press2_Util                     -0.029907\n",
       "c_Cell2__SKU2                    0.027182\n",
       "BNECK_Forklift_Blanking_Queue   -0.021411\n",
       "Press2_Queue                     0.020604\n",
       "BNECK_Warehouse1_Queue          -0.020366\n",
       "Warehouse_2_Queue               -0.019236\n",
       "Press3_Util                      0.018836\n",
       "c_Cell2__SKU4                    0.012542\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No proxy target found. Î®ºÏ†Ä 7a ÏÖÄÏùÑ Ïã§ÌñâÌïòÏó¨ '_quality_reject_proxy'Î•º ÎßåÎìúÏÑ∏Ïöî.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 7) Í≤∞Ìï®/Î∂àÎüâ ÌÉÄÍπÉ ÏûêÎèô ÌÉêÏßÄ (ÌîÑÎ°ùÏãú Í∏∞Î∞ò) ¬∑ ÎèôÏùº ÌååÏù¥ÌîÑÎùºÏù∏\n",
    "#  - '_quality_reject_proxy'Î•º ÌÉÄÍπÉÏúºÎ°ú Î™®Îç∏ ÌïôÏäµ/Ìï¥ÏÑù\n",
    "# ============================================\n",
    "\n",
    "# ÌÉÄÍπÉ Ïù¥Î¶Ñ\n",
    "tgt_name = \"_quality_reject_proxy\"\n",
    "\n",
    "# ÌîºÏ≤ò Íµ¨ÏÑ± Ïãú ÌÉÄÍπÉÏùÑ Î™ÖÏãúÏ†ÅÏúºÎ°ú Ï†úÏô∏ (Î≥ëÎ™© one-hot Ìè¨Ìï®)\n",
    "X_df = build_features_for_leadtime(\n",
    "    df,\n",
    "    exclude_cols=[tgt_name],            # ‚òÖ ÎàÑÏàò Ï∞®Îã® Ìè¨Ïù∏Ìä∏\n",
    "    add_bneck_onehot=True,\n",
    "    top_bneck_list=TOP_BNECKS\n",
    ")\n",
    "\n",
    "y_df = df[tgt_name].astype(\"float32\").values\n",
    "\n",
    "# Î™®Îç∏ Ïû¨ÌïôÏäµ\n",
    "rf, spl, m_rf, fi, pi = train_rf(X_df, y_df)\n",
    "rg, spl2, m_rg, coef, beta_std = train_ridge(X_df, y_df)\n",
    "\n",
    "print(\"[Proxy Defect - no leakage] RF score on train:\", m_rf)\n",
    "print(\"[Proxy Defect - no leakage] Ridge metrics:\", m_rg)\n",
    "\n",
    "print(\"\\n=== Defect Proxy - Ridge ÌëúÏ§ÄÌôî Í≥ÑÏàò ÏÉÅÏúÑ (ÎàÑÏàò Ï†úÍ±∞) ===\")\n",
    "top_beta = beta_std.sort_values(key=lambda s: s.abs(), ascending=False).head(15)\n",
    "display(top_beta)\n",
    "\n",
    "if fi is not None:\n",
    "    print(\"\\n=== Defect Proxy - Ìä∏Î¶¨ Ï§ëÏöîÎèÑ ÏÉÅÏúÑ (ÎàÑÏàò Ï†úÍ±∞) ===\")\n",
    "    display(fi.sort_values(ascending=False).head(15))\n",
    "else:\n",
    "    print(\"No proxy target found. Î®ºÏ†Ä 7a ÏÖÄÏùÑ Ïã§ÌñâÌïòÏó¨ '_quality_reject_proxy'Î•º ÎßåÎìúÏÑ∏Ïöî.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea3b224-7b2a-48aa-81fc-2b0d4c362640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy (ÌëúÎ≥∏Ïàò ‚â• 200) ‚Äî Ï†ÑÏ≤¥ ÌèâÍ∑†=0.511 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>count</th>\n",
       "      <th>mean_defect</th>\n",
       "      <th>std_defect</th>\n",
       "      <th>lift_vs_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Warehouse1_Queue</td>\n",
       "      <td>77631</td>\n",
       "      <td>0.521246</td>\n",
       "      <td>0.210814</td>\n",
       "      <td>0.009774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Warehouse_3_Queue</td>\n",
       "      <td>1307</td>\n",
       "      <td>0.504420</td>\n",
       "      <td>0.216034</td>\n",
       "      <td>-0.007052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forklift_Blanking_Queue</td>\n",
       "      <td>53681</td>\n",
       "      <td>0.497501</td>\n",
       "      <td>0.211187</td>\n",
       "      <td>-0.013971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bneck  count  mean_defect  std_defect  lift_vs_overall\n",
       "5         Warehouse1_Queue  77631     0.521246    0.210814         0.009774\n",
       "6        Warehouse_3_Queue   1307     0.504420    0.216034        -0.007052\n",
       "1  Forklift_Blanking_Queue  53681     0.497501    0.211187        -0.013971"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy (ÌëúÎ≥∏Ïàò < 200) ‚Äî Ï∞∏Í≥†Ïö© ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>count</th>\n",
       "      <th>mean_defect</th>\n",
       "      <th>std_defect</th>\n",
       "      <th>lift_vs_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Warehouse_4_Queue</td>\n",
       "      <td>36</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.187337</td>\n",
       "      <td>0.041910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Press2_Queue</td>\n",
       "      <td>5</td>\n",
       "      <td>0.528022</td>\n",
       "      <td>0.216524</td>\n",
       "      <td>0.016550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forklift_Press_Queue</td>\n",
       "      <td>9</td>\n",
       "      <td>0.479962</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>-0.031510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Press4_Queue</td>\n",
       "      <td>6</td>\n",
       "      <td>0.447602</td>\n",
       "      <td>0.117323</td>\n",
       "      <td>-0.063870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.511472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bneck  count  mean_defect  std_defect  lift_vs_overall\n",
       "7     Warehouse_4_Queue     36     0.553382    0.187337         0.041910\n",
       "3          Press2_Queue      5     0.528022    0.216524         0.016550\n",
       "2  Forklift_Press_Queue      9     0.479962    0.117338        -0.031510\n",
       "4          Press4_Queue      6     0.447602    0.117323        -0.063870\n",
       "0   Blanking_SKU3_Queue      1     0.000000         NaN        -0.511472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy: Ïã†Î¢∞ÎèÑ ÌïÑÌÑ∞ + Î¶¨ÌîÑÌä∏ Í≥ÑÏÇ∞ + ÌÉÄÏù¥ÌãÄ/Ï†ÄÏû• ===\n",
    "min_count = 200  # ÌëúÎ≥∏Ïàò ÌïòÌïú (ÏõêÌïòÎ©¥ 500/1000 Îì±ÏúºÎ°ú Ï°∞Ï†à)\n",
    "tgt_name = \"_quality_reject_proxy\"\n",
    "\n",
    "if \"_bneck\" in df.columns and tgt_name in df.columns:\n",
    "    overall_mean = float(df[tgt_name].mean())\n",
    "    tmp = pd.DataFrame({\"bneck\": df[\"_bneck\"], \"defect_proxy\": df[tgt_name].astype(\"float32\")})\n",
    "    stats = (\n",
    "        tmp.groupby(\"bneck\", observed=False)\n",
    "           .agg(count=(\"defect_proxy\",\"count\"),\n",
    "                mean_defect=(\"defect_proxy\",\"mean\"),\n",
    "                std_defect=(\"defect_proxy\",\"std\"))\n",
    "           .reset_index()\n",
    "    )\n",
    "    stats[\"lift_vs_overall\"] = stats[\"mean_defect\"] - overall_mean\n",
    "    stats = stats.sort_values([\"count\",\"mean_defect\"], ascending=[False,False])\n",
    "\n",
    "    # Ïã†Î¢∞ Íµ¨Í∞Ñ: ÌëúÎ≥∏Ïàò Í∏∞Ï§Ä ÌïÑÌÑ∞\n",
    "    stats_strong = stats[stats[\"count\"] >= min_count].copy()\n",
    "    stats_weak   = stats[stats[\"count\"] <  min_count].copy()\n",
    "\n",
    "    # Ï†ÄÏû•\n",
    "    out_main = ensure_dir(os.path.join(OUT_DIR, \"bneck_vs_defectProxy_main.csv\"))\n",
    "    out_weak = ensure_dir(os.path.join(OUT_DIR, \"bneck_vs_defectProxy_lowCount.csv\"))\n",
    "    stats_strong.to_csv(out_main, index=False)\n",
    "    stats_weak.to_csv(out_weak, index=False)\n",
    "\n",
    "    # Ï∂úÎ†• (Ï†úÎ™© Ìè¨Ìï®)\n",
    "    print(f\"\\n=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy (ÌëúÎ≥∏Ïàò ‚â• {min_count}) ‚Äî Ï†ÑÏ≤¥ ÌèâÍ∑†={overall_mean:.3f} ===\")\n",
    "    display(stats_strong.sort_values(\"lift_vs_overall\", ascending=False).head(15))\n",
    "\n",
    "    if len(stats_weak):\n",
    "        print(f\"\\n=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy (ÌëúÎ≥∏Ïàò < {min_count}) ‚Äî Ï∞∏Í≥†Ïö© ===\")\n",
    "        display(stats_weak.sort_values(\"lift_vs_overall\", ascending=False).head(15))\n",
    "\n",
    "else:\n",
    "    print(\"bneck ÎòêÎäî defect proxy Ïª¨ÎüºÏù¥ ÏóÜÏäµÎãàÎã§. Î®ºÏ†Ä 7a ÌîÑÎ°ùÏãú ÏÉùÏÑ±Í≥º Î≥ëÎ™© ÎùºÎ≤®ÎßÅÏùÑ ÌôïÏù∏ÌïòÏÑ∏Ïöî.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf67537-dde5-40cf-a45c-1457301d0863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy (ÌëúÎ≥∏‚â•200) ‚Äî Ï†ÑÏ≤¥ ÌèâÍ∑†=0.511 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>count</th>\n",
       "      <th>mean_defect</th>\n",
       "      <th>std_defect</th>\n",
       "      <th>lift_vs_overall</th>\n",
       "      <th>rel_lift_%</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>sig_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Warehouse1_Queue</td>\n",
       "      <td>77631</td>\n",
       "      <td>0.521246</td>\n",
       "      <td>0.210814</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>1.910962</td>\n",
       "      <td>0.519763</td>\n",
       "      <td>0.522729</td>\n",
       "      <td>‚òÖ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Warehouse_3_Queue</td>\n",
       "      <td>1307</td>\n",
       "      <td>0.504420</td>\n",
       "      <td>0.216034</td>\n",
       "      <td>-0.007052</td>\n",
       "      <td>-1.378685</td>\n",
       "      <td>0.492708</td>\n",
       "      <td>0.516132</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forklift_Blanking_Queue</td>\n",
       "      <td>53681</td>\n",
       "      <td>0.497501</td>\n",
       "      <td>0.211187</td>\n",
       "      <td>-0.013971</td>\n",
       "      <td>-2.731488</td>\n",
       "      <td>0.495714</td>\n",
       "      <td>0.499288</td>\n",
       "      <td>‚òÖ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bneck  count  mean_defect  std_defect  lift_vs_overall  rel_lift_%    ci_low   ci_high sig_95\n",
       "5         Warehouse1_Queue  77631     0.521246    0.210814         0.009774    1.910962  0.519763  0.522729      ‚òÖ\n",
       "6        Warehouse_3_Queue   1307     0.504420    0.216034        -0.007052   -1.378685  0.492708  0.516132       \n",
       "1  Forklift_Blanking_Queue  53681     0.497501    0.211187        -0.013971   -2.731488  0.495714  0.499288      ‚òÖ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy (ÌëúÎ≥∏<200) ‚Äî Ï∞∏Í≥†Ïö© ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>count</th>\n",
       "      <th>mean_defect</th>\n",
       "      <th>std_defect</th>\n",
       "      <th>lift_vs_overall</th>\n",
       "      <th>rel_lift_%</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>sig_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Warehouse_4_Queue</td>\n",
       "      <td>36</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.187337</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>8.194092</td>\n",
       "      <td>0.492186</td>\n",
       "      <td>0.614579</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Press2_Queue</td>\n",
       "      <td>5</td>\n",
       "      <td>0.528022</td>\n",
       "      <td>0.216524</td>\n",
       "      <td>0.016550</td>\n",
       "      <td>3.235831</td>\n",
       "      <td>0.338231</td>\n",
       "      <td>0.717814</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forklift_Press_Queue</td>\n",
       "      <td>9</td>\n",
       "      <td>0.479962</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>-0.031510</td>\n",
       "      <td>-6.160611</td>\n",
       "      <td>0.403301</td>\n",
       "      <td>0.556623</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Press4_Queue</td>\n",
       "      <td>6</td>\n",
       "      <td>0.447602</td>\n",
       "      <td>0.117323</td>\n",
       "      <td>-0.063870</td>\n",
       "      <td>-12.487465</td>\n",
       "      <td>0.353724</td>\n",
       "      <td>0.541480</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.511472</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bneck  count  mean_defect  std_defect  lift_vs_overall  rel_lift_%    ci_low   ci_high sig_95\n",
       "7     Warehouse_4_Queue     36     0.553382    0.187337         0.041910    8.194092  0.492186  0.614579       \n",
       "3          Press2_Queue      5     0.528022    0.216524         0.016550    3.235831  0.338231  0.717814       \n",
       "2  Forklift_Press_Queue      9     0.479962    0.117338        -0.031510   -6.160611  0.403301  0.556623       \n",
       "4          Press4_Queue      6     0.447602    0.117323        -0.063870  -12.487465  0.353724  0.541480       \n",
       "0   Blanking_SKU3_Queue      1     0.000000         NaN        -0.511472 -100.000000       NaN       NaN       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ÏöîÏïΩ] ÌëúÎ≥∏‚â•200 Ï§ë lift ÏµúÎåÄ: Warehouse1_Queue (lift=0.010, rel=1.9%, 95% CI [0.008, 0.011] ‚òÖ)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Í∏∞Î≥∏\n",
    "tgt_name = \"_quality_reject_proxy\"\n",
    "min_count = 200\n",
    "\n",
    "overall_mean = float(df[tgt_name].mean())\n",
    "\n",
    "tmp = pd.DataFrame({\"bneck\": df[\"_bneck\"], \"defect_proxy\": df[tgt_name].astype(\"float32\")})\n",
    "stats = (\n",
    "    tmp.groupby(\"bneck\", observed=False)\n",
    "       .agg(count=(\"defect_proxy\",\"count\"),\n",
    "            mean_defect=(\"defect_proxy\",\"mean\"),\n",
    "            std_defect=(\"defect_proxy\",\"std\"))\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "# ÌÜµÍ≥ÑÎüâ\n",
    "stats[\"se\"] = stats[\"std_defect\"]/np.sqrt(stats[\"count\"].clip(lower=1))\n",
    "stats[\"ci_low\"]  = stats[\"mean_defect\"] - 1.96*stats[\"se\"]\n",
    "stats[\"ci_high\"] = stats[\"mean_defect\"] + 1.96*stats[\"se\"]\n",
    "stats[\"lift_vs_overall\"] = stats[\"mean_defect\"] - overall_mean\n",
    "stats[\"lift_low\"]  = stats[\"ci_low\"]  - overall_mean\n",
    "stats[\"lift_high\"] = stats[\"ci_high\"] - overall_mean\n",
    "stats[\"rel_lift_%\"] = 100.0 * stats[\"lift_vs_overall\"] / overall_mean\n",
    "stats[\"z\"] = (stats[\"mean_defect\"] - overall_mean) / stats[\"se\"].replace(0, np.nan)\n",
    "stats[\"sig_95\"] = np.where(stats[\"z\"].abs() >= 1.96, \"‚òÖ\", \"\")\n",
    "\n",
    "# ÌëúÎ≥∏Ïàò ÌïÑÌÑ∞\n",
    "stats_strong = stats[stats[\"count\"] >= min_count].copy()\n",
    "stats_weak   = stats[stats[\"count\"] <  min_count].copy()\n",
    "\n",
    "# Ï†ïÎ†¨ Î∞è Ï†ÄÏû•\n",
    "stats_strong = stats_strong.sort_values([\"rel_lift_%\",\"count\"], ascending=[False,False])\n",
    "stats_weak   = stats_weak.sort_values([\"rel_lift_%\",\"count\"], ascending=[False,False])\n",
    "\n",
    "stats_strong.to_csv(ensure_dir(os.path.join(OUT_DIR, \"bneck_vs_defectProxy_main_CI.csv\")), index=False)\n",
    "stats_weak.to_csv(ensure_dir(os.path.join(OUT_DIR, \"bneck_vs_defectProxy_lowCount_CI.csv\")), index=False)\n",
    "\n",
    "# Ï†úÎ™© + Ï∂úÎ†•\n",
    "print(f\"\\n=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy (ÌëúÎ≥∏‚â•{min_count}) ‚Äî Ï†ÑÏ≤¥ ÌèâÍ∑†={overall_mean:.3f} ===\")\n",
    "cols_show = [\"bneck\",\"count\",\"mean_defect\",\"std_defect\",\"lift_vs_overall\",\"rel_lift_%\",\"ci_low\",\"ci_high\",\"sig_95\"]\n",
    "display(stats_strong[cols_show].head(15))\n",
    "\n",
    "if len(stats_weak):\n",
    "    print(f\"\\n=== Î≥ëÎ™© ‚Üî Î∂àÎüâ Proxy (ÌëúÎ≥∏<{min_count}) ‚Äî Ï∞∏Í≥†Ïö© ===\")\n",
    "    display(stats_weak[cols_show].head(15))\n",
    "\n",
    "# Ìïú Ï§Ñ ÏöîÏïΩ\n",
    "if len(stats_strong):\n",
    "    top = stats_strong.iloc[0]\n",
    "    print(f\"\\n[ÏöîÏïΩ] ÌëúÎ≥∏‚â•{min_count} Ï§ë lift ÏµúÎåÄ: {top['bneck']} \"\n",
    "          f\"(lift={top['lift_vs_overall']:.3f}, rel={top['rel_lift_%']:.1f}%, 95% CI [{top['lift_low']:.3f}, {top['lift_high']:.3f}] {top['sig_95']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f504149-9a13-43e1-b05e-cd03e8fc9edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Î≥ëÎ™© √ó SKU ÌèâÍ∑† Î∂àÎüâ Proxy ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sku</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bneck</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blanking_SKU3_Queue</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forklift_Blanking_Queue</th>\n",
       "      <td>0.497078</td>\n",
       "      <td>0.506164</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.494360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forklift_Press_Queue</th>\n",
       "      <td>0.407522</td>\n",
       "      <td>0.275847</td>\n",
       "      <td>0.516404</td>\n",
       "      <td>0.527135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Press2_Queue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Press4_Queue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warehouse1_Queue</th>\n",
       "      <td>0.524061</td>\n",
       "      <td>0.525224</td>\n",
       "      <td>0.517986</td>\n",
       "      <td>0.512809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warehouse_3_Queue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543214</td>\n",
       "      <td>0.502751</td>\n",
       "      <td>0.520273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warehouse_4_Queue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483111</td>\n",
       "      <td>0.498602</td>\n",
       "      <td>0.588946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sku                             1         2         3         4\n",
       "bneck                                                          \n",
       "Blanking_SKU3_Queue      0.000000       NaN       NaN       NaN\n",
       "Forklift_Blanking_Queue  0.497078  0.506164  0.494624  0.494360\n",
       "Forklift_Press_Queue     0.407522  0.275847  0.516404  0.527135\n",
       "Press2_Queue                  NaN  0.528022       NaN       NaN\n",
       "Press4_Queue                  NaN       NaN       NaN  0.447602\n",
       "Warehouse1_Queue         0.524061  0.525224  0.517986  0.512809\n",
       "Warehouse_3_Queue             NaN  0.543214  0.502751  0.520273\n",
       "Warehouse_4_Queue             NaN  0.483111  0.498602  0.588946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ÌñâÎ≥Ñ \"ÏßÄÎ∞∞ SKU\" Í∞ÑÏù¥ Ï∂îÏ†ï: Í∞Å ÌñâÏóêÏÑú SKUÎ≥Ñ ÏÉùÏÇ∞(Î™®Îì† ÏÖÄ Ìï©) Ï§ë ÏµúÎåìÍ∞íÏùò SKU\n",
    "cell_sku_cols = [c for c in df.columns if re.match(r\"^c_Cell\\d+__?SKU\\d+$\", c)]\n",
    "sku_ids = sorted(set(re.findall(r\"SKU(\\d+)\", \" \".join(cell_sku_cols))), key=lambda x:int(x))\n",
    "\n",
    "sku_by_row = pd.DataFrame({\n",
    "    s: df.filter(regex=fr\"^c_Cell\\d+__?SKU{s}$\").sum(axis=1).astype(\"float32\")\n",
    "    for s in sku_ids\n",
    "})\n",
    "df[\"_sku_dom\"] = sku_by_row.idxmax(axis=1).str.extract(r\"(\\d+)\")\n",
    "tmp2 = pd.DataFrame({\"bneck\": df[\"_bneck\"], \"sku\": df[\"_sku_dom\"], \"defect_proxy\": df[tgt_name]})\n",
    "mat = tmp2.pivot_table(index=\"bneck\", columns=\"sku\", values=\"defect_proxy\", aggfunc=\"mean\")\n",
    "print(\"\\n=== Î≥ëÎ™© √ó SKU ÌèâÍ∑† Î∂àÎüâ Proxy ===\")\n",
    "display(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "097f78b1-3277-4be0-97a9-98f59c6c65da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Warehouse1_Queue Î≥ëÎ™© vs ÎπÑ-Î≥ëÎ™© (SKUÎ≥Ñ, n‚â•200) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>n_focus</th>\n",
       "      <th>n_other</th>\n",
       "      <th>mean_focus</th>\n",
       "      <th>mean_other</th>\n",
       "      <th>lift</th>\n",
       "      <th>rel_lift_%</th>\n",
       "      <th>z_approx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27738</td>\n",
       "      <td>1633</td>\n",
       "      <td>0.524061</td>\n",
       "      <td>0.496719</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>5.232476</td>\n",
       "      <td>5.138274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14526</td>\n",
       "      <td>19623</td>\n",
       "      <td>0.517987</td>\n",
       "      <td>0.495140</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>4.525352</td>\n",
       "      <td>9.890108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21558</td>\n",
       "      <td>13539</td>\n",
       "      <td>0.525224</td>\n",
       "      <td>0.506246</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>3.664424</td>\n",
       "      <td>8.181109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13809</td>\n",
       "      <td>20250</td>\n",
       "      <td>0.512809</td>\n",
       "      <td>0.494511</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>3.645392</td>\n",
       "      <td>7.884097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SKU  n_focus  n_other  mean_focus  mean_other      lift  rel_lift_%  z_approx\n",
       "0   1    27738     1633    0.524061    0.496719  0.027342    5.232476  5.138274\n",
       "2   3    14526    19623    0.517987    0.495140  0.022847    4.525352  9.890108\n",
       "1   2    21558    13539    0.525224    0.506246  0.018978    3.664424  8.181109\n",
       "3   4    13809    20250    0.512809    0.494511  0.018297    3.645392  7.884097"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tgt = \"_quality_reject_proxy\"\n",
    "bnk = \"_bneck\"\n",
    "focus = \"Warehouse1_Queue\"\n",
    "min_count = 200  # ÌëúÎ≥∏ ÌïòÌïú\n",
    "\n",
    "# SKU ÎèÑÎ©îÏù∏ ÎùºÎ≤®(ÏïûÏÑú ÎßåÎì† _sku_domÏù¥ ÏóÜÏúºÎ©¥ Í∞ÑÏù¥ ÏßÄÎ∞∞ SKU Ïû¨Í≥ÑÏÇ∞)\n",
    "if \"_sku_dom\" not in df.columns:\n",
    "    import re\n",
    "    cell_sku_cols = [c for c in df.columns if re.match(r\"^c_Cell\\d+__?SKU\\d+$\", c)]\n",
    "    sku_ids = sorted(set(re.findall(r\"SKU(\\d+)\", \" \".join(cell_sku_cols))), key=lambda x:int(x))\n",
    "    sku_by_row = pd.DataFrame({s: df.filter(regex=fr\"^c_Cell\\d+__?SKU{s}$\").sum(axis=1).astype(\"float32\") for s in sku_ids})\n",
    "    df[\"_sku_dom\"] = sku_by_row.idxmax(axis=1).str.extract(r\"(\\d+)\")\n",
    "\n",
    "res = []\n",
    "for sku in sorted(df[\"_sku_dom\"].dropna().unique(), key=lambda x:int(x)):\n",
    "    sub = df[df[\"_sku_dom\"] == sku]\n",
    "    a = sub[sub[bnk] == focus][tgt].dropna()\n",
    "    b = sub[sub[bnk] != focus][tgt].dropna()\n",
    "    if len(a) >= min_count and len(b) >= min_count:\n",
    "        mean_a, mean_b = float(a.mean()), float(b.mean())\n",
    "        lift = mean_a - mean_b\n",
    "        rel = 100.0 * lift / (float(sub[tgt].mean()) + 1e-9)\n",
    "        se = np.sqrt(a.var(ddof=1)/len(a) + b.var(ddof=1)/len(b))\n",
    "        z = (lift / se) if se > 0 else np.nan\n",
    "        res.append({\"SKU\": sku, \"n_focus\": len(a), \"n_other\": len(b),\n",
    "                    \"mean_focus\": mean_a, \"mean_other\": mean_b,\n",
    "                    \"lift\": lift, \"rel_lift_%\": rel, \"z_approx\": z})\n",
    "\n",
    "sku_cmp = pd.DataFrame(res).sort_values([\"rel_lift_%\",\"n_focus\"], ascending=[False,False])\n",
    "print(f\"\\n=== {focus} Î≥ëÎ™© vs ÎπÑ-Î≥ëÎ™© (SKUÎ≥Ñ, n‚â•{min_count}) ===\")\n",
    "display(sku_cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52db4c95-8260-4c34-b091-a544e2b1eef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Warehouse1_Queue ‚Üî Defect Proxy ÏÉÅÍ¥Ä (ÎûòÍ∑∏) ===\n",
      "Lag -6: 0.0042\n",
      "Lag -5: 0.0041\n",
      "Lag -4: 0.0051\n",
      "Lag -3: 0.0056\n",
      "Lag -2: 0.0051\n",
      "Lag -1: 0.0053\n",
      "Lag +0: 0.0620\n",
      "Lag +1: 0.0625\n",
      "Lag +2: 0.0620\n",
      "Lag +3: 0.0614\n",
      "Lag +4: 0.0605\n",
      "Lag +5: 0.0636\n",
      "Lag +6: 0.0631\n"
     ]
    }
   ],
   "source": [
    "# -6~+6 Ïä§ÌÖùÏóêÏÑú ÏÉÅÍ¥ÄÍ≥ÑÏàò Í≥ÑÏÇ∞ (Îç∞Ïù¥ÌÑ∞ Í∞ÑÍ≤©Ïóê ÎßûÏ∂∞ Ìï¥ÏÑù)\n",
    "series_x = df[\"Warehouse1_Queue\"].astype(\"float32\")\n",
    "series_y = df[\"_quality_reject_proxy\"].astype(\"float32\")\n",
    "\n",
    "def corr_lag(x, y, lag):\n",
    "    if lag > 0:\n",
    "        return x.shift(lag).corr(y)\n",
    "    elif lag < 0:\n",
    "        return x.corr(y.shift(-lag))\n",
    "    else:\n",
    "        return x.corr(y)\n",
    "\n",
    "lags = range(-6, 7)\n",
    "corrs = {lag: corr_lag(series_x, series_y, lag) for lag in lags}\n",
    "print(\"\\n=== Warehouse1_Queue ‚Üî Defect Proxy ÏÉÅÍ¥Ä (ÎûòÍ∑∏) ===\")\n",
    "for lag in sorted(corrs):\n",
    "    print(f\"Lag {lag:+d}: {corrs[lag]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddcc901e-f062-4c4c-a307-b2a23996523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ï∞ΩÍ≥†1 Queue Î∂ÑÏúÑÏàòÎ≥Ñ Î∂àÎüâ Proxy ÌèâÍ∑† ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDT6\\AppData\\Local\\Temp\\ipykernel_36936\\3847015275.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  trend = pd.DataFrame({\"bin\": bins, \"proxy\": y}).groupby(\"bin\").agg(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>n</th>\n",
       "      <th>proxy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.001, 108.222]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.488169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(108.222, 124.823]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.497153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(124.823, 138.934]</td>\n",
       "      <td>13267</td>\n",
       "      <td>0.500140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(138.934, 153.135]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.501666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(153.135, 168.504]</td>\n",
       "      <td>13267</td>\n",
       "      <td>0.507277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(168.504, 186.166]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.514875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(186.166, 208.301]</td>\n",
       "      <td>13267</td>\n",
       "      <td>0.518185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(208.301, 240.038]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.522366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(240.038, 296.61]</td>\n",
       "      <td>13267</td>\n",
       "      <td>0.527139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(296.61, 1828.135]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.537749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bin      n  proxy_mean\n",
       "0   (-0.001, 108.222]  13268    0.488169\n",
       "1  (108.222, 124.823]  13268    0.497153\n",
       "2  (124.823, 138.934]  13267    0.500140\n",
       "3  (138.934, 153.135]  13268    0.501666\n",
       "4  (153.135, 168.504]  13267    0.507277\n",
       "5  (168.504, 186.166]  13268    0.514875\n",
       "6  (186.166, 208.301]  13267    0.518185\n",
       "7  (208.301, 240.038]  13268    0.522366\n",
       "8   (240.038, 296.61]  13267    0.527139\n",
       "9  (296.61, 1828.135]  13268    0.537749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df[\"Warehouse1_Queue\"].astype(\"float32\")\n",
    "y = df[\"_quality_reject_proxy\"].astype(\"float32\")\n",
    "bins = pd.qcut(x, 10, duplicates=\"drop\")  # Î∂ÑÏúÑÏàò 10Íµ¨Í∞Ñ\n",
    "trend = pd.DataFrame({\"bin\": bins, \"proxy\": y}).groupby(\"bin\").agg(\n",
    "    n=(\"proxy\",\"count\"), proxy_mean=(\"proxy\",\"mean\")).reset_index()\n",
    "print(\"\\n=== Ï∞ΩÍ≥†1 Queue Î∂ÑÏúÑÏàòÎ≥Ñ Î∂àÎüâ Proxy ÌèâÍ∑† ===\")\n",
    "display(trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5085c212-174b-483f-b62d-a9b081483bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ÏûÑÍ≥ÑÏπò] Warehouse1_Queue ‚â• 240.0 Î•º Í≥†ÏúÑÌóòÏúºÎ°ú Í∞ÑÏ£º\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_w1q_risk</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106140</td>\n",
       "      <td>0.506231</td>\n",
       "      <td>0.211275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26536</td>\n",
       "      <td>0.532436</td>\n",
       "      <td>0.210230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count      mean       std\n",
       "_w1q_risk                            \n",
       "0          106140  0.506231  0.211275\n",
       "1           26536  0.532436  0.210230"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thr = df[\"Warehouse1_Queue\"].quantile(0.80)\n",
    "df[\"_w1q_risk\"] = (df[\"Warehouse1_Queue\"] >= thr).astype(int)\n",
    "\n",
    "summary = df.groupby(\"_w1q_risk\")[\"_quality_reject_proxy\"].agg([\"count\",\"mean\",\"std\"])\n",
    "print(f\"[ÏûÑÍ≥ÑÏπò] Warehouse1_Queue ‚â• {thr:.1f} Î•º Í≥†ÏúÑÌóòÏúºÎ°ú Í∞ÑÏ£º\")\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f895cfab-4676-44e7-823a-9bc4485c3ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Ï∏µÌôî] Quality_Util Î†àÎ≤®Î≥Ñ Ï∞ΩÍ≥†1 Î≥ëÎ™© lift\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_a</th>\n",
       "      <th>n_b</th>\n",
       "      <th>mean_a</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22901.0</td>\n",
       "      <td>21326.0</td>\n",
       "      <td>0.500582</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>0.020487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26020.0</td>\n",
       "      <td>18205.0</td>\n",
       "      <td>0.520903</td>\n",
       "      <td>0.500898</td>\n",
       "      <td>0.020005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28710.0</td>\n",
       "      <td>15514.0</td>\n",
       "      <td>0.538039</td>\n",
       "      <td>0.518102</td>\n",
       "      <td>0.019937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_a      n_b    mean_a    mean_b      lift\n",
       "0  22901.0  21326.0  0.500582  0.480096  0.020487\n",
       "1  26020.0  18205.0  0.520903  0.500898  0.020005\n",
       "2  28710.0  15514.0  0.538039  0.518102  0.019937"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_bins = pd.qcut(df[\"Quality_Util\"], q=3, labels=[\"low\",\"mid\",\"high\"])\n",
    "def layer_lift(layer):\n",
    "    sub = df[q_bins == layer]\n",
    "    a = sub[sub[\"_bneck\"]==\"Warehouse1_Queue\"][\"_quality_reject_proxy\"]\n",
    "    b = sub[sub[\"_bneck\"]!=\"Warehouse1_Queue\"][\"_quality_reject_proxy\"]\n",
    "    return pd.Series({\n",
    "        \"n_a\": len(a), \"n_b\": len(b),\n",
    "        \"mean_a\": a.mean(), \"mean_b\": b.mean(),\n",
    "        \"lift\": a.mean()-b.mean()\n",
    "    })\n",
    "print(\"\\n[Ï∏µÌôî] Quality_Util Î†àÎ≤®Î≥Ñ Ï∞ΩÍ≥†1 Î≥ëÎ™© lift\")\n",
    "display(pd.concat([layer_lift(\"low\"), layer_lift(\"mid\"), layer_lift(\"high\")], axis=1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcb1197b-776c-4297-8758-648f387cba1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>n_a</th>\n",
       "      <th>n_b</th>\n",
       "      <th>lift</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27738</td>\n",
       "      <td>1633</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.037771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14526</td>\n",
       "      <td>19623</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>0.018319</td>\n",
       "      <td>0.027374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21558</td>\n",
       "      <td>13539</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>0.023525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13809</td>\n",
       "      <td>20250</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>0.022846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SKU    n_a    n_b      lift    ci_low   ci_high\n",
       "0   1  27738   1633  0.027342  0.016912  0.037771\n",
       "2   3  14526  19623  0.022847  0.018319  0.027374\n",
       "1   2  21558  13539  0.018978  0.014431  0.023525\n",
       "3   4  13809  20250  0.018297  0.013749  0.022846"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "rows=[]\n",
    "for sku in sorted(df[\"_sku_dom\"].dropna().unique(), key=lambda x:int(x)):\n",
    "    sub = df[df[\"_sku_dom\"]==sku]\n",
    "    a = sub[sub[\"_bneck\"]==\"Warehouse1_Queue\"][\"_quality_reject_proxy\"].dropna()\n",
    "    b = sub[sub[\"_bneck\"]!=\"Warehouse1_Queue\"][\"_quality_reject_proxy\"].dropna()\n",
    "    if len(a)>1 and len(b)>1:\n",
    "        lift = a.mean()-b.mean()\n",
    "        se = np.sqrt(a.var(ddof=1)/len(a) + b.var(ddof=1)/len(b))\n",
    "        ci = (lift-1.96*se, lift+1.96*se)\n",
    "        rows.append({\"SKU\":sku,\"n_a\":len(a),\"n_b\":len(b),\"lift\":lift,\"ci_low\":ci[0],\"ci_high\":ci[1]})\n",
    "display(pd.DataFrame(rows).sort_values(\"lift\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e31bd-9455-442d-9d71-cfddd6c200ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e955d-a8c8-4232-9041-3c44a496cc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62f6f95a-bd83-4d8c-888b-ea98c95dc194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 8) (ÏòµÏÖò) mu/sd Í∏∞Î∞ò Ìé∏Ï∞® ÌååÏÉùÌîºÏ≤ò (Í∏∞Î≥∏ OFF)\n",
    "# ============================================\n",
    "# ÌïÑÏöî Ïãú Ìå®ÌÑ¥Îßå ÎÇ®Í≤®Îë†. SPEED_MODE=TrueÎ©¥ Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ÏÇ¨Ïö© Ïïà Ìï®.\n",
    "MUSD: Dict[str, Dict[str, Dict[str, float]]] = {\n",
    "    \"SKU1\": {\n",
    "        \"mu\": {\"BL\":900.0, \"PR\":5.0, \"AS\":25.0, \"PA\":5400.0, \"QL\":55.0},\n",
    "        \"sd\": {\"BL\":30.0,  \"PR\":0.1, \"AS\":0.1,  \"PA\":0.0,    \"QL\":2.04},\n",
    "    }\n",
    "}\n",
    "REPLICATE_TO_OTHERS = True\n",
    "\n",
    "def add_musd_features(df_: pd.DataFrame, sku_ids_: List[str]) -> List[str]:\n",
    "    created = []\n",
    "    for sid in sku_ids_:\n",
    "        key = f\"SKU{sid}\"\n",
    "        if key not in MUSD and REPLICATE_TO_OTHERS and \"SKU1\" in MUSD:\n",
    "            MUSD[key] = MUSD[\"SKU1\"]\n",
    "        if key not in MUSD:\n",
    "            continue\n",
    "        mu = MUSD[key][\"mu\"]; sd = MUSD[key][\"sd\"]\n",
    "        mu_sum = mu[\"BL\"] + mu[\"PR\"] + mu[\"AS\"] + mu[\"PA\"] + mu[\"QL\"]\n",
    "        S_var  = sd[\"BL\"]**2 + sd[\"PR\"]**2 + sd[\"AS\"]**2 + sd[\"QL\"]**2\n",
    "        S_std  = math.sqrt(S_var) if S_var > 0 else 1.0\n",
    "        base = f\"SKU{sid}\"\n",
    "        va_col = next((base+s for s in LT_PATTERNS[\"VA\"] if (base+s) in df_.columns), None)\n",
    "        VA = pd.to_numeric(df_[va_col], errors=\"coerce\").fillna(0.0) if va_col else pd.Series(0.0, index=df_.index)\n",
    "        dev_col = f\"{base}_VA_dev\"; z_col = f\"{base}_VA_z\"\n",
    "        df_[dev_col] = (VA - mu_sum).astype(\"float32\")\n",
    "        df_[z_col]   = ((VA - mu_sum)/S_std).astype(\"float32\")\n",
    "        created += [dev_col, z_col]\n",
    "    return created\n",
    "\n",
    "# ÏÇ¨Ïö© Ïòà)\n",
    "# if not SPEED_MODE and INCLUDE_MUSD_IN_PR:\n",
    "#     musd_cols = add_musd_features(df, sku_ids)\n",
    "#     print(\"MUSD features created:\", musd_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "765e03f0-914c-4141-95b6-cfa765a06ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUSD features created: ['SKU1_VA_dev', 'SKU1_VA_z', 'SKU2_VA_dev', 'SKU2_VA_z', 'SKU3_VA_dev', 'SKU3_VA_z', 'SKU4_VA_dev', 'SKU4_VA_z']\n"
     ]
    }
   ],
   "source": [
    "# ÌïÑÏöîÌï† ÎïåÎßå ÏàòÎèô Ìò∏Ï∂ú\n",
    "musd_cols = add_musd_features(df, sku_ids)\n",
    "print(\"MUSD features created:\", musd_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b650409-a933-4db5-8ebe-d05d1c83fdc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79320d9a-44f3-46d6-999a-f8ab0f92e18f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Project\\Python_Source\\Test01\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'outputs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m n\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m names[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# ÏóÜÏúºÎ©¥ ÏõêÎûò Ïù¥Î¶Ñ Ïú†ÏßÄ\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43msummary\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutputs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33magg_fi_pi_lt\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfi_leadtime_AGG.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpi_leadtime_AGG.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfi_leadtime_AGG_top20.png\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mridge_coef_leadtime_AGG.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mridge_betaStd_leadtime_AGG.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     pick_existing(\u001b[33m\"\u001b[39m\u001b[33melasticity_leadtime_AGG_fast.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m                   \u001b[33m\"\u001b[39m\u001b[33melasticity_leadtime_AGG_fast_lite.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m ]\n\u001b[32m     17\u001b[39m summary[\u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33magg_fi_pi_pr\u001b[39m\u001b[33m\"\u001b[39m] = [\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfi_production_AGG.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpi_production_AGG.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m                   \u001b[33m\"\u001b[39m\u001b[33melasticity_production_AGG_fast_lite.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Project\\Python_Source\\Test01\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Project\\Python_Source\\Test01\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'outputs'"
     ]
    }
   ],
   "source": [
    "# SUMMARY ÏßÅÏ†ÑÏóê Ï∂îÍ∞Ä\n",
    "def pick_existing(*names):\n",
    "    for n in names:\n",
    "        if os.path.exists(os.path.join(OUT_DIR, n)):\n",
    "            return n\n",
    "    return names[0]  # ÏóÜÏúºÎ©¥ ÏõêÎûò Ïù¥Î¶Ñ Ïú†ÏßÄ\n",
    "\n",
    "summary[\"outputs\"][\"agg_fi_pi_lt\"] = [\n",
    "    \"fi_leadtime_AGG.csv\",\n",
    "    \"pi_leadtime_AGG.csv\",\n",
    "    \"fi_leadtime_AGG_top20.png\",\n",
    "    \"ridge_coef_leadtime_AGG.csv\",\n",
    "    \"ridge_betaStd_leadtime_AGG.csv\",\n",
    "    pick_existing(\"elasticity_leadtime_AGG_fast.csv\",\n",
    "                  \"elasticity_leadtime_AGG_fast_lite.csv\")\n",
    "]\n",
    "summary[\"outputs\"][\"agg_fi_pi_pr\"] = [\n",
    "    \"fi_production_AGG.csv\",\n",
    "    \"pi_production_AGG.csv\",\n",
    "    \"fi_production_AGG_top20.png\",\n",
    "    \"ridge_coef_production_AGG.csv\",\n",
    "    \"ridge_betaStd_production_AGG.csv\",\n",
    "    pick_existing(\"elasticity_production_AGG_fast.csv\",\n",
    "                  \"elasticity_production_AGG_fast_lite.csv\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82db9c0-08ea-46c1-8540-49626c0f473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 9) ÏöîÏïΩ Î¶¨Ìè¨Ìä∏ Ï†ÄÏû•\n",
    "# ============================================\n",
    "summary = {\n",
    "    \"cwd\": os.getcwd(),\n",
    "    \"dataset_shape\": tuple(df.shape),\n",
    "    \"detected_skus\": sku_ids,\n",
    "    \"top_bottlenecks_used\": TOP_BNECKS,\n",
    "    \"metrics\": {\n",
    "        \"AGG\": {\n",
    "            \"RF_LT\": m_rf_lt_agg, \"RG_LT\": m_rg_lt_agg,\n",
    "            \"RF_PR\": m_rf_pr_agg, \"RG_PR\": m_rg_pr_agg,\n",
    "        }\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"bottleneck_total\": os.path.join(OUT_DIR, \"bottleneck_totalProduction.csv\"),\n",
    "        \"bottleneck_aggLT\": os.path.join(OUT_DIR, \"bottleneck_aggLeadTime.csv\"),\n",
    "        \"sku_bneck_effect\": \"sku_bneck_effect_SKU*.csv\",\n",
    "        \"agg_fi_pi_lt\": [\n",
    "            \"fi_leadtime_AGG.csv\",\"pi_leadtime_AGG.csv\",\"fi_leadtime_AGG_top20.png\",\n",
    "            \"ridge_coef_leadtime_AGG.csv\",\"ridge_betaStd_leadtime_AGG.csv\",\n",
    "            \"elasticity_leadtime_AGG_fast.csv\"\n",
    "        ],\n",
    "        \"agg_fi_pi_pr\": [\n",
    "            \"fi_production_AGG.csv\",\"pi_production_AGG.csv\",\"fi_production_AGG_top20.png\",\n",
    "            \"ridge_coef_production_AGG.csv\",\"ridge_betaStd_production_AGG.csv\",\n",
    "            \"elasticity_production_AGG_fast.csv\"\n",
    "        ],\n",
    "        \"per_sku_elasticity\": \"elasticity_(leadtime|production)_SKU*_fast.csv\",\n",
    "        \"whatif\": os.path.join(OUT_DIR, \"whatif_results.json\")\n",
    "    },\n",
    "    \"notes\": [\n",
    "        \"ÏÉùÏÇ∞Îüâ Î™®Îç∏ÏóêÏÑú c_TotalProducts, c_Cell* ÌîºÏ≤ò Ï†úÏô∏ ‚Üí ÌÉÄÍπÉ ÎàÑÏàò Î∞©ÏßÄ.\",\n",
    "        \"Î¶¨ÎìúÌÉÄÏûÑ Î™®Îç∏ÏóêÏÑú *_Time/_sec/_LeadTime/_Total ÌîºÏ≤ò Ï†úÏô∏ ‚Üí ÎàÑÏàò Î∞©ÏßÄ.\",\n",
    "        \"Î≥ëÎ™© ÎùºÎ≤®(_bneck) Ïõê-Ìï´ Ï∂îÍ∞ÄÎ°ú Î≥ëÎ™© ÏÉÅÌÉúÏùò ÌèâÍ∑†Ï†Å ÏòÅÌñ• Î∞òÏòÅ.\",\n",
    "        \"ÌÉÑÎ†•ÎèÑ: FD(ÏÉòÌîåÎßÅ)ÏúºÎ°ú Îπ†Î•¥Í≤å ‚àÇ≈∑/‚àÇx Ï∂îÏ†ï.\",\n",
    "        \"SPEED_MODE=TrueÏùº Îïå HGBR Ïö∞ÏÑ†, fi/piÍ∞Ä NoneÏùº Ïàò ÏûàÏùå(Í∞ÄÎìú Ï†ÅÏö©).\",\n",
    "        f\"SKU ÏÉÅÏúÑ {TOP_SKU_K}Í∞úÎßå ÌïôÏäµÌï¥ Ï†ÑÏ≤¥ ÏãúÍ∞Ñ Îã®Ï∂ï.\"\n",
    "    ]\n",
    "}\n",
    "with open(ensure_dir(os.path.join(OUT_DIR, \"SUMMARY.json\")), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(json.dumps(summary, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12ae60-3bde-4445-9211-c7e9e35df231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323e53a-59f3-4557-830d-ff8178b1af65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
