{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daeaf88-22e7-4ef9-9594-c59e1eab5e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecc32bf2-c3e1-4c78-a485-9ab4bc5caa30",
   "metadata": {},
   "source": [
    "# 0) 드롭인 패치 셀 (경량 모드 & 파일 로깅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8067a66-14f0-4731-bc34-606dc91b6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 0) 드롭인 패치 셀 (경량 모드, 파일 로깅, 공통 유틸)\n",
    "# --------------------------------------------\n",
    "# ✔ 전역 스위치/경고 억제/파일 로깅 유틸/모델·피처 빌더/시나리오/탄력도 유틸을 정의합니다.\n",
    "# ✔ 타임스탬프 폴더 규칙: MMDDHH (exists 시 MMDDHHmm).\n",
    "# ✔ 모든 셀의 save_csv/save_json이 자동으로 경로를 수집하고,\n",
    "#   각 셀 끝에서 list_saved(\"cellN\")로 생성 파일을 출력합니다.\n",
    "# ✔ MUSD 파생피처를 '시작 시' 자동 생성할 수 있도록 스위치(MUSD_ON_START)도 포함했습니다.\n",
    "# ============================================\n",
    "import os, re, gc, json, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "# ---- 글로벌 스위치 ----\n",
    "SPEED_MODE         = True\n",
    "ENABLE_PLOTS       = False\n",
    "ROW_SAMPLE_MAX     = 250_000\n",
    "COL_KEEP_PAT       = r\"(?:_Queue|_Util|^c_Cell|^c_TotalProducts$|^SKU\\d+_(?:VA|Wait|Transport|LeadTime|Total))\"\n",
    "TOP_SKU_K          = 4\n",
    "MAX_BNECK_ONEHOT   = 20\n",
    "ELAS_FEATURES_TOPK = 8\n",
    "ELAS_SAMPLE_N      = 5000\n",
    "USE_PDP            = False\n",
    "USE_FAST_FD        = True\n",
    "SKIP_PERM_IMPORT   = True\n",
    "RIDGE_TEST_SIZE    = 0.25\n",
    "RF_ESTIMATORS      = 60\n",
    "RF_MAX_DEPTH       = 12\n",
    "RF_NJOBS           = -1\n",
    "USE_HGBR_FIRST     = True\n",
    "SKIP_DEFECT_BLOCK  = True  # (미사용; 프록시 블록은 항상 실행하도록 아래 셀에서 구현)\n",
    "INCLUDE_MUSD_IN_LT = False # 리드타임 피처에서는 누수 방지 위해 기본 제외됨(time_like_regex)\n",
    "INCLUDE_MUSD_IN_PR = False\n",
    "WHATIF_SCENARIOS   = {\"Blanking_Queue\": -50.0, \"Warehouse1_Queue\": -50.0, \"Quality_Util\": +5.0}\n",
    "\n",
    "# (NEW) MUSD 파생피처: 시작 시 자동 생성 여부\n",
    "MUSD_ON_START = True     # ← 처음부터 켜려면 True\n",
    "\n",
    "# (8번 셀의 정의를 여기로 모아옴)\n",
    "MUSD: Dict[str, Dict[str, Dict[str, float]]] = {\n",
    "    \"SKU1\": {\n",
    "        \"mu\": {\"BL\":900.0, \"PR\":5.0, \"AS\":25.0, \"PA\":5400.0, \"QL\":55.0},\n",
    "        \"sd\": {\"BL\":30.0,  \"PR\":0.1, \"AS\":0.1,  \"PA\":0.0,    \"QL\":2.04},\n",
    "    }\n",
    "}\n",
    "REPLICATE_TO_OTHERS = True\n",
    "\n",
    "def add_musd_features(df_: pd.DataFrame, sku_ids_: List[str]) -> List[str]:\n",
    "    created = []\n",
    "    for sid in sku_ids_:\n",
    "        key = f\"SKU{sid}\"\n",
    "        if key not in MUSD and REPLICATE_TO_OTHERS and \"SKU1\" in MUSD:\n",
    "            MUSD[key] = MUSD[\"SKU1\"]\n",
    "        if key not in MUSD:\n",
    "            continue\n",
    "        mu = MUSD[key][\"mu\"]; sd = MUSD[key][\"sd\"]\n",
    "        mu_sum = mu[\"BL\"] + mu[\"PR\"] + mu[\"AS\"] + mu[\"PA\"] + mu[\"QL\"]\n",
    "        S_var  = sd[\"BL\"]**2 + sd[\"PR\"]**2 + sd[\"AS\"]**2 + sd[\"QL\"]**2\n",
    "        S_std  = math.sqrt(S_var) if S_var > 0 else 1.0\n",
    "        base = f\"SKU{sid}\"\n",
    "        # LT_PATTERNS는 2번 셀에서 정의되므로, 여기서는 키만 맞춰 사용\n",
    "        va_col = next((base+s for s in [\"_VA_Time_sec\",\"_VA_Time\",\"_VA\"] if (base+s) in df_.columns), None)\n",
    "        VA = pd.to_numeric(df_[va_col], errors=\"coerce\").fillna(0.0) if va_col else pd.Series(0.0, index=df_.index)\n",
    "        dev_col = f\"{base}_VA_dev\"; z_col = f\"{base}_VA_z\"\n",
    "        df_[dev_col] = (VA - mu_sum).astype(\"float32\")\n",
    "        df_[z_col]   = ((VA - mu_sum)/S_std).astype(\"float32\")\n",
    "        created += [dev_col, z_col]\n",
    "    return created\n",
    "\n",
    "# pandas 미래 경고 억제 (fillna downcast 등)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# ---- 타임스탬프 기반 OUT_DIR 프리셋 ----\n",
    "def _compute_outdir():\n",
    "    now = datetime.now()\n",
    "    stamp = now.strftime(\"%m%d%H\")      # 예: 082416\n",
    "    base = os.path.join(\"./outputs\", stamp)\n",
    "    if os.path.exists(base):\n",
    "        # 충돌 시 분까지 추가\n",
    "        stamp = now.strftime(\"%m%d%H%M\")  # 예: 08241632\n",
    "        base = os.path.join(\"./outputs\", stamp)\n",
    "    os.makedirs(base, exist_ok=True)\n",
    "    return stamp, base\n",
    "\n",
    "RUN_STAMP, DEFAULT_OUT_DIR = _compute_outdir()\n",
    "\n",
    "# ---- 파일 로깅 유틸 ----\n",
    "SAVED_FILES = defaultdict(list)\n",
    "\n",
    "def _ensure_outdir(path):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    return path\n",
    "\n",
    "def register_output(path, cell_tag=None, note=None):\n",
    "    path = os.path.abspath(path)\n",
    "    rel = os.path.relpath(path, start='.')\n",
    "    if cell_tag is None:\n",
    "        cell_tag = \"_misc\"\n",
    "    SAVED_FILES[cell_tag].append(rel)\n",
    "    if note and SPEED_MODE:\n",
    "        print(f\"[SAVED] {rel} ({note})\")\n",
    "    return rel\n",
    "\n",
    "def save_csv(df, filename, cell_tag):\n",
    "    base = globals().get(\"OUT_DIR\", DEFAULT_OUT_DIR)\n",
    "    path = filename if os.path.isabs(filename) else os.path.join(base, filename)\n",
    "    _ensure_outdir(path)\n",
    "    df.to_csv(path, index=False)\n",
    "    return register_output(path, cell_tag, \"csv\")\n",
    "\n",
    "def save_json(obj, filename, cell_tag):\n",
    "    base = globals().get(\"OUT_DIR\", DEFAULT_OUT_DIR)\n",
    "    path = filename if os.path.isabs(filename) else os.path.join(base, filename)\n",
    "    _ensure_outdir(path)\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "    return register_output(path, cell_tag, \"json\")\n",
    "\n",
    "def list_saved(cell_tag=None):\n",
    "    if cell_tag:\n",
    "        files = SAVED_FILES.get(cell_tag, [])\n",
    "        print(f\"\\n[Saved files in {cell_tag}]\")\n",
    "        if files:\n",
    "            for p in files: print(\" -\", p)\n",
    "        else:\n",
    "            print(\" (none)\")\n",
    "    else:\n",
    "        print(\"\\n[All saved files]\")\n",
    "        for tag, files in SAVED_FILES.items():\n",
    "            print(f\" {tag}:\")\n",
    "            for p in files: print(\"   -\", p)\n",
    "\n",
    "def begin_cell(tag):\n",
    "    SAVED_FILES[tag].clear()\n",
    "\n",
    "def _speed_log(*a):\n",
    "    if SPEED_MODE: print(*a)\n",
    "\n",
    "def savefig(path: str, cell_tag=None):\n",
    "    if not ENABLE_PLOTS:\n",
    "        return\n",
    "    import matplotlib.pyplot as plt\n",
    "    try:\n",
    "        plt.tight_layout()\n",
    "    except Exception:\n",
    "        pass\n",
    "    _ensure_outdir(path)\n",
    "    plt.savefig(path, bbox_inches=\"tight\", dpi=140)\n",
    "    plt.close()\n",
    "    gc.collect()\n",
    "    register_output(path, cell_tag or \"_fig\", \"figure\")\n",
    "\n",
    "def to_numeric_df(d: pd.DataFrame) -> pd.DataFrame:\n",
    "    for c in d.columns:\n",
    "        d.loc[:, c] = pd.to_numeric(d[c], errors=\"coerce\", downcast=\"float\")\n",
    "    d = d.fillna(0.0).infer_objects(copy=False)\n",
    "    return d\n",
    "\n",
    "def _apply_df_speed_filters(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not SPEED_MODE: return df\n",
    "    if COL_KEEP_PAT:\n",
    "        keep_re = re.compile(COL_KEEP_PAT, re.IGNORECASE)\n",
    "        keep_cols = [c for c in df.columns if keep_re.search(c)]\n",
    "        for must in [\"Time_Now\"]:\n",
    "            if must in df.columns and must not in keep_cols:  # noqa: E713\n",
    "                keep_cols.append(must)\n",
    "        df = df[keep_cols]\n",
    "        _speed_log(f\"[SPEED] kept {len(keep_cols)} columns by pattern.\")\n",
    "    if ROW_SAMPLE_MAX and len(df) > ROW_SAMPLE_MAX:\n",
    "        df = df.sample(ROW_SAMPLE_MAX, random_state=42).sort_index()\n",
    "        _speed_log(f\"[SPEED] row-sampled to {ROW_SAMPLE_MAX} rows.\")\n",
    "    df = to_numeric_df(df)\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# ---- 모델 공통 ----\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "def metrics_dict(y_true, y_pred) -> dict:\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    r2   = float(r2_score(y_true, y_pred))\n",
    "    return {\"MAE\": round(mae,3), \"RMSE\": round(rmse,3), \"R2\": round(r2,4)}\n",
    "\n",
    "def train_ridge(X, y, alpha=1.0, random_state=42, test_size=None):\n",
    "    from sklearn.linear_model import Ridge\n",
    "    if test_size is None:\n",
    "        test_size = RIDGE_TEST_SIZE if SPEED_MODE else 0.3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    reg = Ridge(alpha=alpha, random_state=random_state)\n",
    "    reg.fit(X_train, y_train)\n",
    "    y_pred = reg.predict(X_test)\n",
    "    m = metrics_dict(y_test, y_pred)\n",
    "    coef = pd.Series(reg.coef_, index=X.columns).sort_values(ascending=False)\n",
    "    std_x = X_test.std(axis=0).replace(0, np.nan)\n",
    "    std_y = np.std(y_test) if np.std(y_test) > 0 else np.nan\n",
    "    beta_std = (coef * (std_x / std_y)).sort_values(ascending=False)\n",
    "    return reg, (X_train, X_test, y_train, y_test), m, coef, beta_std\n",
    "\n",
    "def train_fast_tree(X, y, random_state=42):\n",
    "    \"\"\"HistGradientBoostingRegressor 우선, 실패 시 경량 RF 폴백.\"\"\"\n",
    "    try:\n",
    "        if USE_HGBR_FIRST:\n",
    "            from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "            model = HistGradientBoostingRegressor(\n",
    "                max_depth=8, learning_rate=0.1, max_iter=150, random_state=random_state\n",
    "            )\n",
    "            model.fit(X, y)\n",
    "            score = model.score(X, y)\n",
    "            _speed_log(\"[SPEED] Using HistGradientBoostingRegressor.\")\n",
    "            return model, None, score, None, None\n",
    "    except Exception as e:\n",
    "        _speed_log(\"[SPEED] HGBR unavailable → fallback to RF.\", e)\n",
    "\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=RF_ESTIMATORS, max_depth=RF_MAX_DEPTH,\n",
    "        n_jobs=RF_NJOBS, random_state=random_state\n",
    "    )\n",
    "    rf.fit(X, y)\n",
    "    fi = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "    pi = None\n",
    "    if not SKIP_PERM_IMPORT:\n",
    "        from sklearn.inspection import permutation_importance\n",
    "        pi_ = permutation_importance(rf, X, y, n_repeats=3, random_state=random_state, n_jobs=RF_NJOBS)\n",
    "        pi = pd.Series(pi_.importances_mean, index=X.columns)\n",
    "    score = rf.score(X, y)\n",
    "    return rf, None, score, fi, pi\n",
    "\n",
    "def train_rf(X, y, n_repeats=0, random_state=42):\n",
    "    return train_fast_tree(X, y, random_state=random_state)\n",
    "\n",
    "# ---- 피처/병목 One-Hot 제한 ----\n",
    "time_like_regex = re.compile(r'(?:_Time|_sec|_LeadTime|_Total|_VA_(?:dev|z))', re.IGNORECASE)\n",
    "\n",
    "def build_features_for_leadtime(df_, exclude_cols, add_bneck_onehot=True, top_bneck_list=None, max_bneck=None):\n",
    "    if max_bneck is None:\n",
    "        max_bneck = MAX_BNECK_ONEHOT\n",
    "    cols = [c for c in df_.columns if c not in exclude_cols and c != \"Time_Now\" and not time_like_regex.search(c)]\n",
    "    X = to_numeric_df(df_[cols]) if cols else pd.DataFrame(index=df_.index)\n",
    "    if add_bneck_onehot and \"_bneck\" in df_.columns:\n",
    "        b_series = df_[\"_bneck\"].astype(str)\n",
    "        if top_bneck_list is not None:\n",
    "            b_series = b_series.where(b_series.isin(top_bneck_list), \"Other\")\n",
    "        topN = b_series.value_counts().nlargest(max_bneck).index\n",
    "        b_series = b_series.where(b_series.isin(topN), \"Other\")\n",
    "        D = pd.get_dummies(b_series, prefix=\"BNECK\", dtype=\"float32\")\n",
    "        X = pd.concat([X, D], axis=1)\n",
    "    return X\n",
    "\n",
    "def build_features_for_production(df_, exclude_cols):\n",
    "    cols = [c for c in df_.columns if c not in exclude_cols and c != \"Time_Now\" and not c.startswith(\"c_Cell\") and c != \"c_TotalProducts\"]\n",
    "    return to_numeric_df(df_[cols]) if cols else pd.DataFrame(index=df_.index)\n",
    "\n",
    "# ---- 탄력도/시나리오 유틸 ----\n",
    "FEATURES_TOP_K = ELAS_FEATURES_TOPK\n",
    "ONLY_QUEUE_UTIL = True\n",
    "SAMPLE_N = ELAS_SAMPLE_N\n",
    "USE_FDP_FAST = USE_FAST_FD\n",
    "\n",
    "def limit_top_k_skus(sku_ids, sku_targets, k=TOP_SKU_K):\n",
    "    if not SPEED_MODE or not k or k >= len(sku_ids):\n",
    "        return sku_ids\n",
    "    sums = []\n",
    "    for sid in sku_ids:\n",
    "        pr = sku_targets[sid][\"production\"]\n",
    "        sums.append((sid, float(np.nansum(pr.values)) if hasattr(pr, \"values\") else float(np.nansum(pr))))\n",
    "    sums = sorted(sums, key=lambda x: x[1], reverse=True)\n",
    "    top = [sid for sid, _ in sums[:k]]\n",
    "    _speed_log(f\"[SPEED] limit SKUs → top {k}: {top}\")\n",
    "    return top\n",
    "\n",
    "def get_scenarios(X_cols):\n",
    "    sc = {}\n",
    "    for k, v in WHATIF_SCENARIOS.items():\n",
    "        if k in X_cols:\n",
    "            sc[k] = v\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981ab5c-fe2c-460d-84ab-787758ebceeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d734aec-3ae9-4724-bfc0-769d8fb3ef50",
   "metadata": {},
   "source": [
    "# 1) 설정 · 로드 · 공통 유틸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59590ce6-8953-4133-9ac3-27d585d4f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN_STAMP] 082416\n",
      "[OUT_DIR]   ./outputs\\082416\n",
      "[SPEED] kept 66 columns by pattern.\n",
      "=== Dataset shape === (132676, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blanking_Util</th>\n",
       "      <th>Blanking_SKU1_Queue</th>\n",
       "      <th>Blanking_SKU2_Queue</th>\n",
       "      <th>Blanking_SKU3_Queue</th>\n",
       "      <th>Blanking_SKU4_Queue</th>\n",
       "      <th>Press1_Util</th>\n",
       "      <th>Press2_Util</th>\n",
       "      <th>Press3_Util</th>\n",
       "      <th>Press4_Util</th>\n",
       "      <th>Press1_Queue</th>\n",
       "      <th>Press2_Queue</th>\n",
       "      <th>Press3_Queue</th>\n",
       "      <th>Press4_Queue</th>\n",
       "      <th>Cell1_Util</th>\n",
       "      <th>Cell2_Util</th>\n",
       "      <th>Cell3_Util</th>\n",
       "      <th>Cell4_Util</th>\n",
       "      <th>Cell1_Queue</th>\n",
       "      <th>Cell2_Queue</th>\n",
       "      <th>Cell3_Queue</th>\n",
       "      <th>Cell4_Queue</th>\n",
       "      <th>Warehouse1_Queue</th>\n",
       "      <th>Warehouse_2_Queue</th>\n",
       "      <th>Warehouse_3_Queue</th>\n",
       "      <th>Warehouse_4_Queue</th>\n",
       "      <th>c_Cell1_SKU1</th>\n",
       "      <th>c_Cell1__SKU2</th>\n",
       "      <th>c_Cell1__SKU3</th>\n",
       "      <th>c_Cell1__SKU4</th>\n",
       "      <th>c_Cell2__SKU1</th>\n",
       "      <th>c_Cell2__SKU2</th>\n",
       "      <th>c_Cell2__SKU3</th>\n",
       "      <th>c_Cell2__SKU4</th>\n",
       "      <th>c_Cell3__SKU1</th>\n",
       "      <th>c_Cell3__SKU2</th>\n",
       "      <th>c_Cell3__SKU3</th>\n",
       "      <th>c_Cell3__SKU4</th>\n",
       "      <th>c_Cell4__SKU1</th>\n",
       "      <th>c_Cell4__SKU2</th>\n",
       "      <th>c_Cell4__SKU3</th>\n",
       "      <th>c_Cell4__SKU4</th>\n",
       "      <th>Paint1_Util</th>\n",
       "      <th>Paint2_Util</th>\n",
       "      <th>Quality_Util</th>\n",
       "      <th>Paint1_Queue</th>\n",
       "      <th>Paint2_Queue</th>\n",
       "      <th>Quality_Queue</th>\n",
       "      <th>Forklift_Util</th>\n",
       "      <th>Forklift_Blanking_Queue</th>\n",
       "      <th>Forklift_Press_Queue</th>\n",
       "      <th>Forklift_Assembly_Queue</th>\n",
       "      <th>c_TotalProducts</th>\n",
       "      <th>SKU1_VA_Time</th>\n",
       "      <th>SKU1_Transport_Time</th>\n",
       "      <th>SKU1_Wait_Time</th>\n",
       "      <th>SKU2_VA_Time</th>\n",
       "      <th>SKU2_Transport_Time</th>\n",
       "      <th>SKU2_Wait_Time</th>\n",
       "      <th>SKU3_VA_Time</th>\n",
       "      <th>SKU3_Transport_Time</th>\n",
       "      <th>SKU3_Wait_Time</th>\n",
       "      <th>SKU4_VA_Time</th>\n",
       "      <th>SKU4_Transport_Time</th>\n",
       "      <th>SKU4_Wait_Time</th>\n",
       "      <th>Blanking_Queue</th>\n",
       "      <th>Time_Now</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846367</td>\n",
       "      <td>0.045715</td>\n",
       "      <td>0.056373</td>\n",
       "      <td>0.055737</td>\n",
       "      <td>0.035849</td>\n",
       "      <td>0.410297</td>\n",
       "      <td>0.434561</td>\n",
       "      <td>0.481388</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>56.540291</td>\n",
       "      <td>65.273788</td>\n",
       "      <td>52.970764</td>\n",
       "      <td>47.964825</td>\n",
       "      <td>0.848870</td>\n",
       "      <td>0.673814</td>\n",
       "      <td>0.705012</td>\n",
       "      <td>0.819405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.155571</td>\n",
       "      <td>19.580276</td>\n",
       "      <td>77.580864</td>\n",
       "      <td>75.124985</td>\n",
       "      <td>13967.0</td>\n",
       "      <td>10867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4382.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2851.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4334.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>903.0</td>\n",
       "      <td>4707.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11743.0</td>\n",
       "      <td>4934.0</td>\n",
       "      <td>0.472565</td>\n",
       "      <td>0.504126</td>\n",
       "      <td>0.432738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.361618</td>\n",
       "      <td>0.606002</td>\n",
       "      <td>157.256744</td>\n",
       "      <td>142.123962</td>\n",
       "      <td>137.454849</td>\n",
       "      <td>54377.0</td>\n",
       "      <td>1.525651</td>\n",
       "      <td>0.536810</td>\n",
       "      <td>0.587305</td>\n",
       "      <td>1.522853</td>\n",
       "      <td>0.532394</td>\n",
       "      <td>0.441645</td>\n",
       "      <td>1.525071</td>\n",
       "      <td>0.537617</td>\n",
       "      <td>0.453650</td>\n",
       "      <td>1.523338</td>\n",
       "      <td>0.536243</td>\n",
       "      <td>0.473453</td>\n",
       "      <td>58.361450</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851097</td>\n",
       "      <td>0.051937</td>\n",
       "      <td>0.052934</td>\n",
       "      <td>0.038512</td>\n",
       "      <td>0.042248</td>\n",
       "      <td>0.455471</td>\n",
       "      <td>0.454445</td>\n",
       "      <td>0.387975</td>\n",
       "      <td>0.442986</td>\n",
       "      <td>74.772820</td>\n",
       "      <td>52.530064</td>\n",
       "      <td>49.303143</td>\n",
       "      <td>59.119987</td>\n",
       "      <td>0.876750</td>\n",
       "      <td>0.660415</td>\n",
       "      <td>0.629526</td>\n",
       "      <td>0.803448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.632370</td>\n",
       "      <td>18.164795</td>\n",
       "      <td>64.827576</td>\n",
       "      <td>69.374908</td>\n",
       "      <td>15071.0</td>\n",
       "      <td>11180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3615.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2932.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1346.0</td>\n",
       "      <td>3852.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9556.0</td>\n",
       "      <td>7484.0</td>\n",
       "      <td>0.482683</td>\n",
       "      <td>0.501912</td>\n",
       "      <td>0.436583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.266911</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>166.488724</td>\n",
       "      <td>142.113663</td>\n",
       "      <td>140.757584</td>\n",
       "      <td>54857.0</td>\n",
       "      <td>1.525665</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>0.684177</td>\n",
       "      <td>1.522836</td>\n",
       "      <td>0.535767</td>\n",
       "      <td>0.401993</td>\n",
       "      <td>1.524986</td>\n",
       "      <td>0.536764</td>\n",
       "      <td>0.473677</td>\n",
       "      <td>1.523344</td>\n",
       "      <td>0.534992</td>\n",
       "      <td>0.464380</td>\n",
       "      <td>62.830601</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.846115</td>\n",
       "      <td>0.052210</td>\n",
       "      <td>0.047499</td>\n",
       "      <td>0.043181</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>0.496717</td>\n",
       "      <td>0.450816</td>\n",
       "      <td>0.417308</td>\n",
       "      <td>0.352829</td>\n",
       "      <td>67.283035</td>\n",
       "      <td>72.901070</td>\n",
       "      <td>39.198517</td>\n",
       "      <td>33.994083</td>\n",
       "      <td>0.895845</td>\n",
       "      <td>0.660288</td>\n",
       "      <td>0.654895</td>\n",
       "      <td>0.766823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.401550</td>\n",
       "      <td>20.369415</td>\n",
       "      <td>46.120110</td>\n",
       "      <td>71.720192</td>\n",
       "      <td>16603.0</td>\n",
       "      <td>11042.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2904.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>4139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10282.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>0.476897</td>\n",
       "      <td>0.492906</td>\n",
       "      <td>0.429997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.906418</td>\n",
       "      <td>0.576669</td>\n",
       "      <td>159.188507</td>\n",
       "      <td>148.427689</td>\n",
       "      <td>142.653366</td>\n",
       "      <td>54052.0</td>\n",
       "      <td>1.525644</td>\n",
       "      <td>0.535403</td>\n",
       "      <td>0.898331</td>\n",
       "      <td>1.522821</td>\n",
       "      <td>0.535631</td>\n",
       "      <td>0.427815</td>\n",
       "      <td>1.525064</td>\n",
       "      <td>0.535925</td>\n",
       "      <td>0.424090</td>\n",
       "      <td>1.523403</td>\n",
       "      <td>0.535077</td>\n",
       "      <td>0.475330</td>\n",
       "      <td>59.365868</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blanking_Util  Blanking_SKU1_Queue  Blanking_SKU2_Queue  Blanking_SKU3_Queue  Blanking_SKU4_Queue  Press1_Util  Press2_Util  Press3_Util  Press4_Util  \\\n",
       "0       0.846367             0.045715             0.056373             0.055737             0.035849     0.410297     0.434561     0.481388     0.399992   \n",
       "1       0.851097             0.051937             0.052934             0.038512             0.042248     0.455471     0.454445     0.387975     0.442986   \n",
       "2       0.846115             0.052210             0.047499             0.043181             0.040979     0.496717     0.450816     0.417308     0.352829   \n",
       "\n",
       "   Press1_Queue  Press2_Queue  Press3_Queue  Press4_Queue  Cell1_Util  Cell2_Util  Cell3_Util  Cell4_Util  Cell1_Queue  Cell2_Queue  Cell3_Queue  Cell4_Queue  \\\n",
       "0     56.540291     65.273788     52.970764     47.964825    0.848870    0.673814    0.705012    0.819405          0.0          0.0          0.0          0.0   \n",
       "1     74.772820     52.530064     49.303143     59.119987    0.876750    0.660415    0.629526    0.803448          0.0          0.0          0.0          0.0   \n",
       "2     67.283035     72.901070     39.198517     33.994083    0.895845    0.660288    0.654895    0.766823          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   Warehouse1_Queue  Warehouse_2_Queue  Warehouse_3_Queue  Warehouse_4_Queue  c_Cell1_SKU1  c_Cell1__SKU2  c_Cell1__SKU3  c_Cell1__SKU4  c_Cell2__SKU1  \\\n",
       "0         98.155571          19.580276          77.580864          75.124985       13967.0        10867.0            0.0         4382.0            0.0   \n",
       "1        162.632370          18.164795          64.827576          69.374908       15071.0        11180.0            0.0         3615.0            0.0   \n",
       "2        335.401550          20.369415          46.120110          71.720192       16603.0        11042.0            0.0         2260.0            0.0   \n",
       "\n",
       "   c_Cell2__SKU2  c_Cell2__SKU3  c_Cell2__SKU4  c_Cell3__SKU1  c_Cell3__SKU2  c_Cell3__SKU3  c_Cell3__SKU4  c_Cell4__SKU1  c_Cell4__SKU2  c_Cell4__SKU3  \\\n",
       "0         2851.0            0.0         4334.0            0.0          903.0         4707.0            0.0            0.0            0.0        11743.0   \n",
       "1         2932.0            0.0         4125.0            0.0         1346.0         3852.0            0.0            0.0            0.0         9556.0   \n",
       "2         2904.0            0.0         4149.0            0.0         1198.0         4139.0            0.0            0.0            0.0        10282.0   \n",
       "\n",
       "   c_Cell4__SKU4  Paint1_Util  Paint2_Util  Quality_Util  Paint1_Queue  Paint2_Queue  Quality_Queue  Forklift_Util  Forklift_Blanking_Queue  \\\n",
       "0         4934.0     0.472565     0.504126      0.432738           0.0           0.0      47.361618       0.606002               157.256744   \n",
       "1         7484.0     0.482683     0.501912      0.436583           0.0           0.0      48.266911       0.599976               166.488724   \n",
       "2         5575.0     0.476897     0.492906      0.429997           0.0           0.0      48.906418       0.576669               159.188507   \n",
       "\n",
       "   Forklift_Press_Queue  Forklift_Assembly_Queue  c_TotalProducts  SKU1_VA_Time  SKU1_Transport_Time  SKU1_Wait_Time  SKU2_VA_Time  SKU2_Transport_Time  \\\n",
       "0            142.123962               137.454849          54377.0      1.525651             0.536810        0.587305      1.522853             0.532394   \n",
       "1            142.113663               140.757584          54857.0      1.525665             0.534195        0.684177      1.522836             0.535767   \n",
       "2            148.427689               142.653366          54052.0      1.525644             0.535403        0.898331      1.522821             0.535631   \n",
       "\n",
       "   SKU2_Wait_Time  SKU3_VA_Time  SKU3_Transport_Time  SKU3_Wait_Time  SKU4_VA_Time  SKU4_Transport_Time  SKU4_Wait_Time  Blanking_Queue  Time_Now  \n",
       "0        0.441645      1.525071             0.537617        0.453650      1.523338             0.536243        0.473453       58.361450        24  \n",
       "1        0.401993      1.524986             0.536764        0.473677      1.523344             0.534992        0.464380       62.830601        24  \n",
       "2        0.427815      1.525064             0.535925        0.424090      1.523403             0.535077        0.475330       59.365868        24  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Saved files in cell1]\n",
      " (none)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1) 설정 · 로드 · 공통 유틸\n",
    "# --------------------------------------------\n",
    "# ✔ 데이터 로드/경량 필터 적용, 표시 옵션, 기본 유틸(ensure_dir/topk),\n",
    "#   타임스탬프 OUT_DIR 확정 및 안내.\n",
    "# ============================================\n",
    "begin_cell(\"cell1\")\n",
    "\n",
    "import os, re, json, math, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "CSV_PATH = \"./Final Results Extended.csv\"   # 필요시 변경\n",
    "\n",
    "# 타임스탬프 폴더 확정 (0번 셀에서 만든 DEFAULT_OUT_DIR 사용)\n",
    "OUT_DIR = DEFAULT_OUT_DIR\n",
    "print(f\"[RUN_STAMP] {RUN_STAMP}\")\n",
    "print(f\"[OUT_DIR]   {OUT_DIR}\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 160)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "# ---- 데이터 로드 ----\n",
    "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
    "df = _apply_df_speed_filters(df)\n",
    "print(\"=== Dataset shape ===\", df.shape)\n",
    "display(df.head(3))\n",
    "\n",
    "def topk(s: pd.Series, k=20):\n",
    "    return s.head(k) if len(s) > k else s\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    return path\n",
    "\n",
    "list_saved(\"cell1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0172052-0383-4527-8379-da951ac24b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3602ae30-033b-432b-8731-1bf937836ff4",
   "metadata": {},
   "source": [
    "# 2) 컬럼 인식 · SKU 타깃 · 통합 리드타임(메모리 안전)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9730424-0c05-402f-8308-f324b0094c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Column groups ===\n",
      "Queue cols  (23): ['Blanking_SKU1_Queue', 'Blanking_SKU2_Queue', 'Blanking_SKU3_Queue', 'Blanking_SKU4_Queue', 'Press1_Queue', 'Press2_Queue', 'Press3_Queue', 'Press4_Queue', 'Cell1_Queue', 'Cell2_Queue'] ...\n",
      "Util cols   (13):  ['Blanking_Util', 'Press1_Util', 'Press2_Util', 'Press3_Util', 'Press4_Util', 'Cell1_Util', 'Cell2_Util', 'Cell3_Util', 'Cell4_Util', 'Paint1_Util'] ...\n",
      "Cycle cols  (0): []\n",
      "Cell cols   (16):  ['c_Cell1_SKU1', 'c_Cell1__SKU2', 'c_Cell1__SKU3', 'c_Cell1__SKU4', 'c_Cell2__SKU1', 'c_Cell2__SKU2', 'c_Cell2__SKU3', 'c_Cell2__SKU4', 'c_Cell3__SKU1', 'c_Cell3__SKU2'] ...\n",
      "\n",
      "=== Detected SKUs === ['1', '2', '3', '4']\n",
      "\n",
      "=== SKU targets overview (first 2) ===\n",
      "SKU1 LT: SKU1_LeadTime_composed (VA+WAIT+LIFT), PROD: Total_SKU1 | #cell_cols=3\n",
      "SKU2 LT: SKU2_LeadTime_composed (VA+WAIT+LIFT), PROD: Total_SKU2 | #cell_cols=4\n",
      "[MUSD early] created 8 cols → ['SKU1_VA_dev', 'SKU1_VA_z', 'SKU2_VA_dev', 'SKU2_VA_z', 'SKU3_VA_dev', 'SKU3_VA_z', 'SKU4_VA_dev', 'SKU4_VA_z']\n",
      "\n",
      "[Saved files in cell2]\n",
      " (none)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 2) 컬럼 인식 · SKU 타깃 · 통합 리드타임 계산\n",
    "# --------------------------------------------\n",
    "# ✔ 컬럼 그룹 인식, SKU 자동탐지, SKU별 LT/PROD 타깃 구성,\n",
    "#   통합 리드타임(생산량 가중) 계산.\n",
    "# ✔ (옵션) MUSD 파생피처를 시작 시 자동 생성(MUSD_ON_START).\n",
    "# ============================================\n",
    "begin_cell(\"cell2\")\n",
    "\n",
    "queue_cols = [c for c in df.columns if c.endswith(\"_Queue\")]\n",
    "util_cols  = [c for c in df.columns if c.endswith(\"_Util\")]\n",
    "cycle_cols = [c for c in df.columns if c.startswith(\"c_Cycle\")]\n",
    "cell_cols  = [c for c in df.columns if c.startswith(\"c_Cell\")]\n",
    "\n",
    "print(\"\\n=== Column groups ===\")\n",
    "print(f\"Queue cols  ({len(queue_cols)}): {queue_cols[:10]}{' ...' if len(queue_cols)>10 else ''}\")\n",
    "print(f\"Util cols   ({len(util_cols)}):  {util_cols[:10]}{' ...' if len(util_cols)>10 else ''}\")\n",
    "print(f\"Cycle cols  ({len(cycle_cols)}): {cycle_cols[:10]}\")\n",
    "print(f\"Cell cols   ({len(cell_cols)}):  {cell_cols[:10]}{' ...' if len(cell_cols)>10 else ''}\")\n",
    "\n",
    "# === SKU 자동 탐지 ===\n",
    "sku_ids = sorted({re.findall(r\"SKU(\\d+)_\", c)[0] for c in df.columns if re.findall(r\"SKU(\\d+)_\", c)})\n",
    "print(\"\\n=== Detected SKUs ===\", sku_ids)\n",
    "\n",
    "# 리드타임 컬럼 후보\n",
    "LT_PATTERNS = dict(\n",
    "    VA=[\"_VA_Time_sec\", \"_VA_Time\", \"_VA\"],\n",
    "    WAIT=[\"_Wait_Time_sec\", \"_Wait_Time\", \"_Wait\"],\n",
    "    LIFT=[\"_Transport_Time_sec\", \"_Transport_Time\", \"_Transport\", \"_Lift\"],\n",
    "    TOTAL=[\"_Total_sec\", \"_LeadTime_sec\", \"_LeadTime\"]\n",
    ")\n",
    "def find_first_existing(base: str, suffixes: List[str]) -> Optional[str]:\n",
    "    for s in suffixes:\n",
    "        col = base + s\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "# === SKU별 리드타임/생산량 타깃 ===\n",
    "sku_targets = {}\n",
    "for sid in sku_ids:\n",
    "    base = f\"SKU{sid}\"\n",
    "    col_VA   = find_first_existing(base, LT_PATTERNS[\"VA\"])\n",
    "    col_WAIT = find_first_existing(base, LT_PATTERNS[\"WAIT\"])\n",
    "    col_LIFT = find_first_existing(base, LT_PATTERNS[\"LIFT\"])\n",
    "    col_TOT  = find_first_existing(base, LT_PATTERNS[\"TOTAL\"])\n",
    "\n",
    "    # 리드타임 타깃\n",
    "    if col_TOT:\n",
    "        lt_series = pd.to_numeric(df[col_TOT], errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "        lt_name, lt_method = col_TOT, \"TOTAL_col\"\n",
    "    else:\n",
    "        VA   = pd.to_numeric(df[col_VA],   errors=\"coerce\").fillna(0.0).astype(\"float32\") if col_VA   else 0.0\n",
    "        WAIT = pd.to_numeric(df[col_WAIT], errors=\"coerce\").fillna(0.0).astype(\"float32\") if col_WAIT else 0.0\n",
    "        LIFT = pd.to_numeric(df[col_LIFT], errors=\"coerce\").fillna(0.0).astype(\"float32\") if col_LIFT else 0.0\n",
    "        lt_series = pd.Series(VA, index=df.index) + pd.Series(WAIT, index=df.index) + pd.Series(LIFT, index=df.index)\n",
    "        lt_series = lt_series.astype(\"float32\")\n",
    "        lt_name, lt_method = f\"{base}_LeadTime_composed\", \"VA+WAIT+LIFT\"\n",
    "\n",
    "    # 생산량 타깃: 해당 SKU의 셀 출력 합\n",
    "    cell_cols_sku = [c for c in cell_cols if re.search(fr\"__SKU{sid}\\b\", c)]\n",
    "    if cell_cols_sku:\n",
    "        prod_series = to_numeric_df(df[cell_cols_sku]).sum(axis=1).astype(\"float32\")\n",
    "        prod_name   = f\"Total_SKU{sid}\"\n",
    "    else:\n",
    "        prod_series = pd.Series(0.0, index=df.index, dtype=\"float32\")\n",
    "        prod_name   = f\"Total_SKU{sid}_zeros\"\n",
    "\n",
    "    sku_targets[sid] = dict(\n",
    "        lead_time=lt_series, lead_time_name=lt_name, lead_time_method=lt_method,\n",
    "        production=prod_series, production_name=prod_name, cell_cols=cell_cols_sku\n",
    "    )\n",
    "\n",
    "print(\"\\n=== SKU targets overview (first 2) ===\")\n",
    "for sid in sku_ids[:2]:\n",
    "    print(f\"SKU{sid} LT: {sku_targets[sid]['lead_time_name']} ({sku_targets[sid]['lead_time_method']}), \"\n",
    "          f\"PROD: {sku_targets[sid]['production_name']} | #cell_cols={len(sku_targets[sid]['cell_cols'])}\")\n",
    "\n",
    "# === 통합 타깃 ===\n",
    "# 생산량(통합)\n",
    "if \"c_TotalProducts\" in df.columns:\n",
    "    total_prod = pd.to_numeric(df[\"c_TotalProducts\"], errors=\"coerce\").fillna(0.0).astype(\"float32\")\n",
    "else:\n",
    "    total_prod = to_numeric_df(df[cell_cols]).sum(axis=1).astype(\"float32\")\n",
    "\n",
    "# 리드타임(생산량 가중평균, 메모리 안전)\n",
    "N = len(df)\n",
    "numerator = np.zeros(N, dtype=np.float32)  # Σ(lt_k * prod_k)\n",
    "weights   = np.zeros(N, dtype=np.float32)  # Σ(prod_k)\n",
    "sum_lt    = np.zeros(N, dtype=np.float32)  # fallback 평균 분자\n",
    "k_count   = 0\n",
    "\n",
    "for sid in sku_ids:\n",
    "    lt = sku_targets[sid][\"lead_time\"].values\n",
    "    pr = sku_targets[sid][\"production\"].values\n",
    "    numerator += lt * pr\n",
    "    weights   += pr\n",
    "    sum_lt    += lt\n",
    "    k_count   += 1\n",
    "\n",
    "fallback_mean = (sum_lt / max(k_count, 1)).astype(\"float32\")\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    weighted_lt = np.where(weights > 0.0, numerator / weights, fallback_mean)\n",
    "agg_lead_time = pd.Series(weighted_lt, index=df.index, name=\"Agg_LeadTime_weighted\").astype(\"float32\")\n",
    "\n",
    "del numerator, weights, sum_lt; gc.collect()\n",
    "\n",
    "# (선택) 시작 시 MUSD 파생피처 생성\n",
    "if MUSD_ON_START:\n",
    "    musd_cols = add_musd_features(df, sku_ids)\n",
    "    print(f\"[MUSD early] created {len(musd_cols)} cols → {musd_cols[:min(8, len(musd_cols))]}\")\n",
    "\n",
    "list_saved(\"cell2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2c0b0-f822-47f1-a94e-cd2718ca9f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cac88df8-e0e5-4890-b0cf-9ef4bb02e61e",
   "metadata": {},
   "source": [
    "# 3) 병목 라벨링 · 요약표(전체/통합) · SKU×병목 연계표 (+파일 목록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69e31d3-8079-4680-bf4d-8bd981492de6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\bottleneck_totalProduction.csv (csv)\n",
      "[SAVED] outputs\\082416\\bottleneck_aggLeadTime.csv (csv)\n",
      "\n",
      "=== 생산량 기준 병목 빈도 (상위) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>top1_count</th>\n",
       "      <th>mean_target</th>\n",
       "      <th>std_target</th>\n",
       "      <th>target_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warehouse1_Queue</td>\n",
       "      <td>77631</td>\n",
       "      <td>54858.582031</td>\n",
       "      <td>1095.462769</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forklift_Blanking_Queue</td>\n",
       "      <td>53681</td>\n",
       "      <td>54578.960938</td>\n",
       "      <td>1087.814575</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warehouse_3_Queue</td>\n",
       "      <td>1307</td>\n",
       "      <td>55135.089844</td>\n",
       "      <td>1061.024292</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warehouse_4_Queue</td>\n",
       "      <td>36</td>\n",
       "      <td>56690.417969</td>\n",
       "      <td>646.384399</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forklift_Press_Queue</td>\n",
       "      <td>9</td>\n",
       "      <td>54510.332031</td>\n",
       "      <td>932.098145</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Press4_Queue</td>\n",
       "      <td>6</td>\n",
       "      <td>55440.832031</td>\n",
       "      <td>665.971619</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press2_Queue</td>\n",
       "      <td>5</td>\n",
       "      <td>55408.398438</td>\n",
       "      <td>477.534607</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TotalProduction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bneck  top1_count   mean_target   std_target      target_name\n",
       "0         Warehouse1_Queue       77631  54858.582031  1095.462769  TotalProduction\n",
       "1  Forklift_Blanking_Queue       53681  54578.960938  1087.814575  TotalProduction\n",
       "2        Warehouse_3_Queue        1307  55135.089844  1061.024292  TotalProduction\n",
       "3        Warehouse_4_Queue          36  56690.417969   646.384399  TotalProduction\n",
       "4     Forklift_Press_Queue           9  54510.332031   932.098145  TotalProduction\n",
       "5             Press4_Queue           6  55440.832031   665.971619  TotalProduction\n",
       "6             Press2_Queue           5  55408.398438   477.534607  TotalProduction\n",
       "7      Blanking_SKU3_Queue           1      0.000000          NaN  TotalProduction"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 리드타임 기준 병목 빈도 (상위) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>top1_count</th>\n",
       "      <th>mean_target</th>\n",
       "      <th>std_target</th>\n",
       "      <th>target_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warehouse1_Queue</td>\n",
       "      <td>77631</td>\n",
       "      <td>2.513333</td>\n",
       "      <td>0.023924</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forklift_Blanking_Queue</td>\n",
       "      <td>53681</td>\n",
       "      <td>2.505023</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warehouse_3_Queue</td>\n",
       "      <td>1307</td>\n",
       "      <td>2.577764</td>\n",
       "      <td>0.035883</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warehouse_4_Queue</td>\n",
       "      <td>36</td>\n",
       "      <td>2.568670</td>\n",
       "      <td>0.025048</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forklift_Press_Queue</td>\n",
       "      <td>9</td>\n",
       "      <td>2.501076</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Press4_Queue</td>\n",
       "      <td>6</td>\n",
       "      <td>2.546885</td>\n",
       "      <td>0.043715</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press2_Queue</td>\n",
       "      <td>5</td>\n",
       "      <td>2.540109</td>\n",
       "      <td>0.018334</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AggLeadTime</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bneck  top1_count  mean_target  std_target  target_name\n",
       "0         Warehouse1_Queue       77631     2.513333    0.023924  AggLeadTime\n",
       "1  Forklift_Blanking_Queue       53681     2.505023    0.017277  AggLeadTime\n",
       "2        Warehouse_3_Queue        1307     2.577764    0.035883  AggLeadTime\n",
       "3        Warehouse_4_Queue          36     2.568670    0.025048  AggLeadTime\n",
       "4     Forklift_Press_Queue           9     2.501076    0.016981  AggLeadTime\n",
       "5             Press4_Queue           6     2.546885    0.043715  AggLeadTime\n",
       "6             Press2_Queue           5     2.540109    0.018334  AggLeadTime\n",
       "7      Blanking_SKU3_Queue           1     0.000000         NaN  AggLeadTime"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\sku_bneck_effect_SKU1.csv (csv)\n",
      "[SAVED] outputs\\082416\\sku_bneck_effect_SKU2.csv (csv)\n",
      "[SAVED] outputs\\082416\\sku_bneck_effect_SKU3.csv (csv)\n",
      "[SAVED] outputs\\082416\\sku_bneck_effect_SKU4.csv (csv)\n",
      "\n",
      "[Saved files in cell3]\n",
      " - outputs\\082416\\bottleneck_totalProduction.csv\n",
      " - outputs\\082416\\bottleneck_aggLeadTime.csv\n",
      " - outputs\\082416\\sku_bneck_effect_SKU1.csv\n",
      " - outputs\\082416\\sku_bneck_effect_SKU2.csv\n",
      " - outputs\\082416\\sku_bneck_effect_SKU3.csv\n",
      " - outputs\\082416\\sku_bneck_effect_SKU4.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3) 병목 라벨링 · 요약표(생산/리드타임) · SKU×병목 연계표\n",
    "# --------------------------------------------\n",
    "# ✔ 각 행의 최대 Queue를 병목으로 라벨링(_bneck).\n",
    "# ✔ 생산량/통합 리드타임 기준 병목 빈도·평균/표준편차 집계 및 저장.\n",
    "# ✔ SKU별로 병목군 vs 기타군의 리드타임 집계 저장.\n",
    "# ============================================\n",
    "begin_cell(\"cell3\")\n",
    "\n",
    "Q = to_numeric_df(df[[c for c in df.columns if c.endswith(\"_Queue\")]])\n",
    "if Q.shape[1] == 0:\n",
    "    raise ValueError(\"Queue 계열 컬럼이 없습니다.\")\n",
    "df[\"_bneck\"] = Q.idxmax(axis=1)  # 각 행 최대 Queue의 컬럼명\n",
    "\n",
    "def compute_bneck_stats(target: pd.Series, name: str, out_csv: str):\n",
    "    tmp = pd.DataFrame({\"bneck\": df[\"_bneck\"].astype(\"category\"), \"val\": target.astype(\"float32\")})\n",
    "    stats = tmp.groupby(\"bneck\", observed=False).agg(\n",
    "        top1_count=(\"bneck\", \"count\"),\n",
    "        mean_target=(\"val\", \"mean\"),\n",
    "        std_target=(\"val\", \"std\")\n",
    "    ).sort_values(\"top1_count\", ascending=False).reset_index()\n",
    "    stats[\"target_name\"] = name\n",
    "    save_csv(stats, out_csv, cell_tag=\"cell3\")\n",
    "    return stats\n",
    "\n",
    "bneck_total_prod = compute_bneck_stats(total_prod, \"TotalProduction\", \"bottleneck_totalProduction.csv\")\n",
    "bneck_agg_lt     = compute_bneck_stats(agg_lead_time, \"AggLeadTime\", \"bottleneck_aggLeadTime.csv\")\n",
    "\n",
    "print(\"\\n=== 생산량 기준 병목 빈도 (상위) ===\")\n",
    "display(bneck_total_prod.head(10))\n",
    "print(\"\\n=== 리드타임 기준 병목 빈도 (상위) ===\")\n",
    "display(bneck_agg_lt.head(10))\n",
    "\n",
    "# 빈도 상위 병목 목록\n",
    "TOP_BNECKS = list(bneck_total_prod[\"bneck\"].head(8).values)\n",
    "\n",
    "# SKU × 병목 리드타임 비교표 저장\n",
    "for sid in sku_ids:\n",
    "    lt = sku_targets[sid][\"lead_time\"].astype(\"float32\")\n",
    "    tmp = pd.DataFrame({\"bneck\": df[\"_bneck\"], \"lt\": lt})\n",
    "    tmp[\"bneck_top\"] = np.where(tmp[\"bneck\"].isin(TOP_BNECKS), tmp[\"bneck\"], \"Other\")\n",
    "    grp = tmp.groupby(\"bneck_top\", observed=False)[\"lt\"].agg([\"count\",\"mean\",\"std\"]).sort_values(\"count\", ascending=False).reset_index()\n",
    "    save_csv(grp, f\"sku_bneck_effect_SKU{sid}.csv\", cell_tag=\"cell3\")\n",
    "\n",
    "list_saved(\"cell3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641e783-589a-4493-8002-079ec5dfe3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6f3027e-8854-41d9-b4a2-4dd695682b20",
   "metadata": {},
   "source": [
    "# 4) 피처 구성 · 모델 학습(RF & Ridge) (+BNECK계수 CSV, 파일 목록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc5ed7c-d62c-4c35-87fa-d9ab48e92c6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_leadtime_AGG.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_leadtime_AGG.csv (csv)\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_production_AGG.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_production_AGG.csv (csv)\n",
      "\n",
      "=== AGG Metrics ===\n",
      "{'RF_LT': 0.8874460359017269, 'RG_LT': {'MAE': 0.005, 'RMSE': 0.016, 'R2': 0.5805}, 'RF_PR': 0.9880771185836398, 'RG_PR': {'MAE': 120.093, 'RMSE': 169.142, 'R2': 0.9781}}\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_leadtime_SKU1.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_leadtime_SKU1.csv (csv)\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_production_SKU1.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_production_SKU1.csv (csv)\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_leadtime_SKU2.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_leadtime_SKU2.csv (csv)\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_production_SKU2.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_production_SKU2.csv (csv)\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_leadtime_SKU3.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_leadtime_SKU3.csv (csv)\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_production_SKU3.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_production_SKU3.csv (csv)\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_leadtime_SKU4.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_leadtime_SKU4.csv (csv)\n",
      "[SPEED] Using HistGradientBoostingRegressor.\n",
      "[SAVED] outputs\\082416\\ridge_coef_production_SKU4.csv (csv)\n",
      "[SAVED] outputs\\082416\\ridge_betaStd_production_SKU4.csv (csv)\n",
      "\n",
      "[Saved files in cell4]\n",
      " - outputs\\082416\\ridge_coef_leadtime_AGG.csv\n",
      " - outputs\\082416\\ridge_betaStd_leadtime_AGG.csv\n",
      " - outputs\\082416\\ridge_coef_production_AGG.csv\n",
      " - outputs\\082416\\ridge_betaStd_production_AGG.csv\n",
      " - outputs\\082416\\ridge_coef_leadtime_SKU1.csv\n",
      " - outputs\\082416\\ridge_betaStd_leadtime_SKU1.csv\n",
      " - outputs\\082416\\ridge_coef_production_SKU1.csv\n",
      " - outputs\\082416\\ridge_betaStd_production_SKU1.csv\n",
      " - outputs\\082416\\ridge_coef_leadtime_SKU2.csv\n",
      " - outputs\\082416\\ridge_betaStd_leadtime_SKU2.csv\n",
      " - outputs\\082416\\ridge_coef_production_SKU2.csv\n",
      " - outputs\\082416\\ridge_betaStd_production_SKU2.csv\n",
      " - outputs\\082416\\ridge_coef_leadtime_SKU3.csv\n",
      " - outputs\\082416\\ridge_betaStd_leadtime_SKU3.csv\n",
      " - outputs\\082416\\ridge_coef_production_SKU3.csv\n",
      " - outputs\\082416\\ridge_betaStd_production_SKU3.csv\n",
      " - outputs\\082416\\ridge_coef_leadtime_SKU4.csv\n",
      " - outputs\\082416\\ridge_betaStd_leadtime_SKU4.csv\n",
      " - outputs\\082416\\ridge_coef_production_SKU4.csv\n",
      " - outputs\\082416\\ridge_betaStd_production_SKU4.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4) 피처 구성(누수 방지 + 병목 One-Hot) · 모델 학습(RF/HGBR & Ridge)\n",
    "# --------------------------------------------\n",
    "# ✔ 통합(AGG) 리드타임/생산량 모델 학습 → FI/계수 저장.\n",
    "# ✔ SKU별 리드타임/생산량 모델 학습 → FI/계수 저장.\n",
    "# ✔ 탄력도/what-if에 필요할 '학습 시 피처 리스트'를 보존(FEATS_AG_*).\n",
    "# ============================================\n",
    "begin_cell(\"cell4\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (중요) SKU 루프 제한: 생산량 상위 K개만\n",
    "sku_ids = limit_top_k_skus(sku_ids, sku_targets, k=TOP_SKU_K)\n",
    "\n",
    "# === 통합(AGG) 모델 ===\n",
    "# LeadTime(AGG)\n",
    "X_lt_agg = build_features_for_leadtime(df, exclude_cols=[], add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "y_lt_agg = agg_lead_time.values\n",
    "rf_lt_agg, splits_lt_agg, m_rf_lt_agg, fi_lt_agg, pi_lt_agg = train_rf(X_lt_agg, y_lt_agg)\n",
    "rg_lt_agg, splits_rg_lt_agg, m_rg_lt_agg, coef_lt_agg, beta_std_lt_agg = train_ridge(X_lt_agg, y_lt_agg)\n",
    "\n",
    "# 탄력도/what-if용 AGG 피처 목록 저장\n",
    "FEATS_AG_LT = X_lt_agg.columns.tolist()\n",
    "\n",
    "# 저장 (Series → DataFrame로 명시 저장)\n",
    "if fi_lt_agg is not None:\n",
    "    save_csv(fi_lt_agg.reset_index().rename(columns={\"index\":\"feature\", 0:\"importance\"}), \"fi_leadtime_AGG.csv\", \"cell4\")\n",
    "if pi_lt_agg is not None:\n",
    "    save_csv(pi_lt_agg.reset_index().rename(columns={\"index\":\"feature\", 0:\"perm_importance\"}), \"pi_leadtime_AGG.csv\", \"cell4\")\n",
    "save_csv(coef_lt_agg.reset_index().rename(columns={\"index\":\"feature\", 0:\"coef\"}), \"ridge_coef_leadtime_AGG.csv\", \"cell4\")\n",
    "save_csv(beta_std_lt_agg.reset_index().rename(columns={\"index\":\"feature\", 0:\"beta_std\"}), \"ridge_betaStd_leadtime_AGG.csv\", \"cell4\")\n",
    "\n",
    "del X_lt_agg; gc.collect()\n",
    "\n",
    "# Production(AGG)\n",
    "X_pr_agg = build_features_for_production(df, exclude_cols=[])\n",
    "y_pr_agg = total_prod.values\n",
    "rf_pr_agg, splits_pr_agg, m_rf_pr_agg, fi_pr_agg, pi_pr_agg = train_rf(X_pr_agg, y_pr_agg)\n",
    "rg_pr_agg, splits_rg_pr_agg, m_rg_pr_agg, coef_pr_agg, beta_std_pr_agg = train_ridge(X_pr_agg, y_pr_agg)\n",
    "\n",
    "FEATS_AG_PR = X_pr_agg.columns.tolist()\n",
    "\n",
    "if fi_pr_agg is not None:\n",
    "    save_csv(fi_pr_agg.reset_index().rename(columns={\"index\":\"feature\", 0:\"importance\"}), \"fi_production_AGG.csv\", \"cell4\")\n",
    "if pi_pr_agg is not None:\n",
    "    save_csv(pi_pr_agg.reset_index().rename(columns={\"index\":\"feature\", 0:\"perm_importance\"}), \"pi_production_AGG.csv\", \"cell4\")\n",
    "save_csv(coef_pr_agg.reset_index().rename(columns={\"index\":\"feature\", 0:\"coef\"}), \"ridge_coef_production_AGG.csv\", \"cell4\")\n",
    "save_csv(beta_std_pr_agg.reset_index().rename(columns={\"index\":\"feature\", 0:\"beta_std\"}), \"ridge_betaStd_production_AGG.csv\", \"cell4\")\n",
    "\n",
    "del X_pr_agg; gc.collect()\n",
    "\n",
    "print(\"\\n=== AGG Metrics ===\")\n",
    "print({\"RF_LT\": m_rf_lt_agg, \"RG_LT\": m_rg_lt_agg, \"RF_PR\": m_rf_pr_agg, \"RG_PR\": m_rg_pr_agg})\n",
    "\n",
    "# === SKU별 모델 ===\n",
    "per_sku_results = {}\n",
    "for sid in sku_ids:\n",
    "    # LeadTime\n",
    "    y_lt = sku_targets[sid][\"lead_time\"].values\n",
    "    exclude_lt = set(sku_targets[sid][\"cell_cols\"])\n",
    "    exclude_lt |= {c for c in df.columns if c.startswith(f\"SKU{sid}_\") and time_like_regex.search(c)}\n",
    "    X_lt = build_features_for_leadtime(df, list(exclude_lt), add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "\n",
    "    lead_pack = None\n",
    "    if X_lt.shape[1] > 0:\n",
    "        rf_lt, spl_lt, m_rf_lt, fi_lt, pi_lt = train_rf(X_lt, y_lt)\n",
    "        rg_lt, spl_rg_lt, m_rg_lt, coef_lt, beta_std_lt = train_ridge(X_lt, y_lt)\n",
    "\n",
    "        if fi_lt is not None:\n",
    "            save_csv(fi_lt.reset_index().rename(columns={\"index\":\"feature\", 0:\"importance\"}), f\"fi_leadtime_SKU{sid}.csv\", \"cell4\")\n",
    "        if pi_lt is not None:\n",
    "            save_csv(pi_lt.reset_index().rename(columns={\"index\":\"feature\", 0:\"perm_importance\"}), f\"pi_leadtime_SKU{sid}.csv\", \"cell4\")\n",
    "        save_csv(coef_lt.reset_index().rename(columns={\"index\":\"feature\", 0:\"coef\"}), f\"ridge_coef_leadtime_SKU{sid}.csv\", \"cell4\")\n",
    "        save_csv(beta_std_lt.reset_index().rename(columns={\"index\":\"feature\", 0:\"beta_std\"}), f\"ridge_betaStd_leadtime_SKU{sid}.csv\", \"cell4\")\n",
    "\n",
    "        lead_pack = {\n",
    "            \"rf\": (rf_lt, spl_lt, m_rf_lt),\n",
    "            \"rg\": (rg_lt, spl_rg_lt, m_rg_lt),\n",
    "            \"feats\": X_lt.columns.tolist()\n",
    "        }\n",
    "        del X_lt; gc.collect()\n",
    "    else:\n",
    "        print(f\"[WARN] SKU{sid}: LeadTime features empty → skip\")\n",
    "\n",
    "    # Production\n",
    "    y_pr = sku_targets[sid][\"production\"].values\n",
    "    exclude_pr = set(sku_targets[sid][\"cell_cols\"])\n",
    "    X_pr = build_features_for_production(df, list(exclude_pr))\n",
    "\n",
    "    prod_pack = None\n",
    "    if X_pr.shape[1] > 0:\n",
    "        rf_pr, spl_pr, m_rf_pr, fi_pr, pi_pr = train_rf(X_pr, y_pr)\n",
    "        rg_pr, spl_rg_pr, m_rg_pr, coef_pr, beta_std_pr = train_ridge(X_pr, y_pr)\n",
    "\n",
    "        if fi_pr is not None:\n",
    "            save_csv(fi_pr.reset_index().rename(columns={\"index\":\"feature\", 0:\"importance\"}), f\"fi_production_SKU{sid}.csv\", \"cell4\")\n",
    "        if pi_pr is not None:\n",
    "            save_csv(pi_pr.reset_index().rename(columns={\"index\":\"feature\", 0:\"perm_importance\"}), f\"pi_production_SKU{sid}.csv\", \"cell4\")\n",
    "        save_csv(coef_pr.reset_index().rename(columns={\"index\":\"feature\", 0:\"coef\"}), f\"ridge_coef_production_SKU{sid}.csv\", \"cell4\")\n",
    "        save_csv(beta_std_pr.reset_index().rename(columns={\"index\":\"feature\", 0:\"beta_std\"}), f\"ridge_betaStd_production_SKU{sid}.csv\", \"cell4\")\n",
    "\n",
    "        prod_pack = {\n",
    "            \"rf\": (rf_pr, spl_pr, m_rf_pr),\n",
    "            \"rg\": (rg_pr, spl_rg_pr, m_rg_pr),\n",
    "            \"feats\": X_pr.columns.tolist()\n",
    "        }\n",
    "        del X_pr; gc.collect()\n",
    "\n",
    "    per_sku_results[sid] = {\"lead_time\": lead_pack, \"production\": prod_pack}\n",
    "\n",
    "list_saved(\"cell4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ddf4ed-02b6-4b62-b7eb-d06b4cfc039b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d858eafb-fb01-4fa8-ae78-75a1cdcadf22",
   "metadata": {},
   "source": [
    "# 5) 간이 탄력도(민감도) — splits 미사용, Top-N만 변동 (+파일 목록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8943e164-fca2-4c2c-946d-97f0afda3765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\elasticity_leadtime_AGG_fast_lite.csv (csv)\n",
      "\n",
      "=== AGG 리드타임 탄력도 (상위 N개 피처) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blanking_SKU1_Queue</td>\n",
       "      <td>0.008873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Press1_Util</td>\n",
       "      <td>0.004446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blanking_SKU4_Queue</td>\n",
       "      <td>0.000852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>-0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blanking_SKU2_Queue</td>\n",
       "      <td>-0.002123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press2_Util</td>\n",
       "      <td>-0.040837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Press3_Util</td>\n",
       "      <td>-0.040982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blanking_Util</td>\n",
       "      <td>-0.672543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature     slope\n",
       "1  Blanking_SKU1_Queue  0.008873\n",
       "5          Press1_Util  0.004446\n",
       "4  Blanking_SKU4_Queue  0.000852\n",
       "3  Blanking_SKU3_Queue -0.001244\n",
       "2  Blanking_SKU2_Queue -0.002123\n",
       "6          Press2_Util -0.040837\n",
       "7          Press3_Util -0.040982\n",
       "0        Blanking_Util -0.672543"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\elasticity_production_AGG_fast_lite.csv (csv)\n",
      "\n",
      "=== AGG 생산량 탄력도 (상위 N개 피처) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blanking_Util</td>\n",
       "      <td>225.401591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Press1_Util</td>\n",
       "      <td>3.245672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blanking_SKU2_Queue</td>\n",
       "      <td>1.616548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1.166340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blanking_SKU1_Queue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blanking_SKU4_Queue</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press2_Util</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Press3_Util</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature       slope\n",
       "0        Blanking_Util  225.401591\n",
       "5          Press1_Util    3.245672\n",
       "2  Blanking_SKU2_Queue    1.616548\n",
       "3  Blanking_SKU3_Queue    1.166340\n",
       "1  Blanking_SKU1_Queue    0.000000\n",
       "4  Blanking_SKU4_Queue    0.000000\n",
       "6          Press2_Util    0.000000\n",
       "7          Press3_Util    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\elasticity_leadtime_SKU1_fast_lite.csv (csv)\n",
      "[SAVED] outputs\\082416\\elasticity_leadtime_SKU2_fast_lite.csv (csv)\n",
      "[SAVED] outputs\\082416\\elasticity_leadtime_SKU3_fast_lite.csv (csv)\n",
      "[SAVED] outputs\\082416\\elasticity_leadtime_SKU4_fast_lite.csv (csv)\n",
      "\n",
      "[Saved files in cell5]\n",
      " - outputs\\082416\\elasticity_leadtime_AGG_fast_lite.csv\n",
      " - outputs\\082416\\elasticity_production_AGG_fast_lite.csv\n",
      " - outputs\\082416\\elasticity_leadtime_SKU1_fast_lite.csv\n",
      " - outputs\\082416\\elasticity_leadtime_SKU2_fast_lite.csv\n",
      " - outputs\\082416\\elasticity_leadtime_SKU3_fast_lite.csv\n",
      " - outputs\\082416\\elasticity_leadtime_SKU4_fast_lite.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 5) 간이 탄력도(민감도): splits 미사용, 전체 X 정렬 후 Top-N만 변동\n",
    "# --------------------------------------------\n",
    "# ✔ 학습 시 피처 순서에 맞춰 X를 정렬(reindex)하고,\n",
    "#   Queue/Util 중심 상위 N개 피처만 유한차분(FD)로 ∂ŷ/∂x 추정.\n",
    "# ✔ 결과 CSV 저장 + 화면 제목과 함께 상위 몇 줄 출력.\n",
    "# ============================================\n",
    "begin_cell(\"cell5\")\n",
    "\n",
    "from numpy.random import default_rng\n",
    "RANDOM_STATE = 42\n",
    "_rng = default_rng(RANDOM_STATE)\n",
    "\n",
    "def pick_topN_features_from_X(X: pd.DataFrame, topk: int = ELAS_FEATURES_TOPK,\n",
    "                              only_queue_util: bool = True) -> List[str]:\n",
    "    cols = list(X.columns)\n",
    "    if only_queue_util:\n",
    "        base = [c for c in cols if c.endswith(\"_Queue\") or c.endswith(\"_Util\")]\n",
    "        if base: return base[:topk]\n",
    "    return [c for c in cols if not c.startswith(\"BNECK_\")][:topk]\n",
    "\n",
    "def align_X_for_model(X_built: pd.DataFrame, trained_feats: List[str]) -> pd.DataFrame:\n",
    "    return X_built.reindex(columns=trained_feats, fill_value=0.0)\n",
    "\n",
    "def _suggest_h(x: np.ndarray) -> float:\n",
    "    if x.size == 0: return 1.0\n",
    "    q25, q75 = np.percentile(x, [25, 75]); iqr = q75 - q25\n",
    "    if iqr > 0: return float(iqr * 0.05)\n",
    "    std = np.std(x); return float(std * 0.1 if std > 0 else 1.0)\n",
    "\n",
    "def fd_slope_mean(model, X_full: pd.DataFrame, feature: str, h: Optional[float]=None,\n",
    "                  sample_n: int=ELAS_SAMPLE_N) -> Optional[float]:\n",
    "    if feature not in X_full.columns: return None\n",
    "    n = len(X_full);  Xs = X_full\n",
    "    if n == 0: return None\n",
    "    if sample_n and sample_n < n:\n",
    "        idx = _rng.choice(n, size=sample_n, replace=False)\n",
    "        Xs = X_full.iloc[idx].copy()\n",
    "    else:\n",
    "        Xs = X_full.copy()\n",
    "    x = Xs[feature].to_numpy()\n",
    "    h = _suggest_h(x) if h is None else h\n",
    "    if h == 0: return 0.0\n",
    "    X_minus = Xs.copy(); X_plus = Xs.copy()\n",
    "    X_minus[feature] = x - h\n",
    "    X_plus[feature]  = x + h\n",
    "    y_m = model.predict(X_minus).mean()\n",
    "    y_p = model.predict(X_plus).mean()\n",
    "    return float((y_p - y_m) / (2.0 * h))\n",
    "\n",
    "def run_elasticity_block(tag: str, model, X_full: pd.DataFrame, features: List[str],\n",
    "                         sample_n: int=ELAS_SAMPLE_N) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for f in features:\n",
    "        s = fd_slope_mean(model, X_full, f, h=None, sample_n=sample_n)\n",
    "        rows.append({\"feature\": f, \"slope\": s})\n",
    "    out = pd.DataFrame(rows).dropna().sort_values(\"slope\", ascending=False)\n",
    "    # 함수 내부 저장(원본 호환), 이후 save_csv로 등록(덮어쓰기 OK)\n",
    "    out.to_csv(os.path.join(OUT_DIR, f\"elasticity_{tag}.csv\"), index=False)\n",
    "    return out\n",
    "\n",
    "elasticity_outputs = {}\n",
    "\n",
    "# ---------- AGG (통합) ----------\n",
    "X_base_lt_built = build_features_for_leadtime(df, exclude_cols=[], add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "X_full_lt = align_X_for_model(X_base_lt_built, FEATS_AG_LT)\n",
    "feats_lt = pick_topN_features_from_X(X_full_lt, ELAS_FEATURES_TOPK, True)\n",
    "\n",
    "X_base_pr_built = build_features_for_production(df, exclude_cols=[])\n",
    "X_full_pr = align_X_for_model(X_base_pr_built, FEATS_AG_PR)\n",
    "feats_pr = pick_topN_features_from_X(X_full_pr, ELAS_FEATURES_TOPK, True)\n",
    "\n",
    "if feats_lt:\n",
    "    el_lt = run_elasticity_block(\"leadtime_AGG_fast_lite\", rf_lt_agg, X_full_lt, feats_lt, ELAS_SAMPLE_N)\n",
    "    save_csv(el_lt, \"elasticity_leadtime_AGG_fast_lite.csv\", \"cell5\")\n",
    "    elasticity_outputs[\"leadtime_AGG\"] = el_lt\n",
    "    print(\"\\n=== AGG 리드타임 탄력도 (상위 N개 피처) ===\")\n",
    "    display(el_lt.head(15))\n",
    "else:\n",
    "    print(\"[Elasticity] AGG 리드타임: 후보 피처 없음 → 건너뜀\")\n",
    "\n",
    "if feats_pr:\n",
    "    el_pr = run_elasticity_block(\"production_AGG_fast_lite\", rf_pr_agg, X_full_pr, feats_pr, ELAS_SAMPLE_N)\n",
    "    save_csv(el_pr, \"elasticity_production_AGG_fast_lite.csv\", \"cell5\")\n",
    "    elasticity_outputs[\"production_AGG\"] = el_pr\n",
    "    print(\"\\n=== AGG 생산량 탄력도 (상위 N개 피처) ===\")\n",
    "    display(el_pr.head(15))\n",
    "else:\n",
    "    print(\"[Elasticity] AGG 생산량: 후보 피처 없음 → 건너뜀\")\n",
    "\n",
    "# ---------- SKU별 (선택 저장) ----------\n",
    "for sid, packs in per_sku_results.items():\n",
    "    if packs.get(\"lead_time\") is not None:\n",
    "        exclude_lt = set(sku_targets[sid][\"cell_cols\"])\n",
    "        exclude_lt |= {c for c in df.columns if c.startswith(f\"SKU{sid}_\") and time_like_regex.search(c)}\n",
    "        X_lt_sku_built = build_features_for_leadtime(df, list(exclude_lt), add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "        trained_feats_lt = packs[\"lead_time\"][\"feats\"]\n",
    "        X_lt_full = align_X_for_model(X_lt_sku_built, trained_feats_lt)\n",
    "        cand_lt = [c for c in pick_topN_features_from_X(X_lt_full, ELAS_FEATURES_TOPK, True) if c in trained_feats_lt]\n",
    "        if cand_lt:\n",
    "            rf = packs[\"lead_time\"][\"rf\"][0]\n",
    "            out = run_elasticity_block(f\"leadtime_SKU{sid}_fast_lite\", rf, X_lt_full, cand_lt, ELAS_SAMPLE_N)\n",
    "            save_csv(out, f\"elasticity_leadtime_SKU{sid}_fast_lite.csv\", \"cell5\")\n",
    "\n",
    "list_saved(\"cell5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720a8d5-1b64-4856-9b45-35b9b412636c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1eb80dab-40be-4539-84c4-ec0cfc05c3a0",
   "metadata": {},
   "source": [
    "# 6) What-if 시뮬레이터 (AGG & SKU별) (+설명, 파일 목록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8ac8b6-d268-4ba3-8c16-b32ba70aad1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\whatif_results.json (json)\n",
      "\n",
      "[What-if 시뮬레이션 설명]\n",
      "특정 변수(Queue/Util)를 ± 변화시켰을 때, 리드타임·생산량 평균의 변화를 계산합니다.\n",
      "→ base_mean: 원래 평균, new_mean: 변화 후 평균, delta_mean: 차이(new - base).\n",
      "\n",
      "=== What-if (AGG) ===\n",
      "{\n",
      "  \"lead_time\": {\n",
      "    \"Blanking_Queue_-50\": {\n",
      "      \"base_mean\": 2.510594421587846,\n",
      "      \"new_mean\": 1.8318075097749484,\n",
      "      \"delta_mean\": -0.6787869118128977\n",
      "    },\n",
      "    \"Warehouse1_Queue_-50\": {\n",
      "      \"base_mean\": 2.510594421587846,\n",
      "      \"new_mean\": 2.5106675099329148,\n",
      "      \"delta_mean\": 7.308834506858375e-05\n",
      "    },\n",
      "    \"Quality_Util_+5\": {\n",
      "      \"base_mean\": 2.510594421587846,\n",
      "      \"new_mean\": 2.510832725805052,\n",
      "      \"delta_mean\": 0.00023830421720560935\n",
      "    }\n",
      "  },\n",
      "  \"production\": {\n",
      "    \"Blanking_Queue_-50\": {\n",
      "      \"base_mean\": 54748.176045612076,\n",
      "      \"new_mean\": 54746.31936813327,\n",
      "      \"delta_mean\": -1.856677478805068\n",
      "    },\n",
      "    \"Warehouse1_Queue_-50\": {\n",
      "      \"base_mean\": 54748.176045612076,\n",
      "      \"new_mean\": 54748.18151975673,\n",
      "      \"delta_mean\": 0.005474144651088864\n",
      "    },\n",
      "    \"Quality_Util_+5\": {\n",
      "      \"base_mean\": 54748.176045612076,\n",
      "      \"new_mean\": 57600.20967776429,\n",
      "      \"delta_mean\": 2852.033632152212\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "[Saved files in cell6]\n",
      " - outputs\\082416\\whatif_results.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 6) What-if 시뮬레이터 (AGG & SKU별)\n",
    "# --------------------------------------------\n",
    "# ✔ WHATIF_SCENARIOS(예: Blanking_Queue −50, Quality_Util +5)를 적용하여\n",
    "#   평균 리드타임/생산량 변화(base/new/delta)를 계산하고 JSON 저장.\n",
    "# ✔ 결과 앞에 간단 설명을 출력.\n",
    "# ============================================\n",
    "begin_cell(\"cell6\")\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def simulate_delta(model, X_base: pd.DataFrame, deltas: Dict[str, float]) -> Tuple[float, float, float]:\n",
    "    X_sim = X_base.copy()\n",
    "    for k, v in deltas.items():\n",
    "        if k in X_sim.columns:\n",
    "            X_sim[k] = X_sim[k] + v\n",
    "    base_mean = float(model.predict(X_base).mean())\n",
    "    new_mean  = float(model.predict(X_sim).mean())\n",
    "    return base_mean, new_mean, new_mean - base_mean\n",
    "\n",
    "def align_X_for_model(X_built: pd.DataFrame, trained_feats: List[str]) -> pd.DataFrame:\n",
    "    return X_built.reindex(columns=trained_feats, fill_value=0.0)\n",
    "\n",
    "whatif = {\"AGG\": {\"lead_time\": {}, \"production\": {}}, \"SKU\": {}}\n",
    "\n",
    "# ---------- AGG(통합) ----------\n",
    "X_lt_agg_built = build_features_for_leadtime(df, exclude_cols=[], add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "X_full_lt_agg  = align_X_for_model(X_lt_agg_built, FEATS_AG_LT)\n",
    "sc_lt = get_scenarios(X_full_lt_agg.columns)\n",
    "for name, v in sc_lt.items():\n",
    "    base_m, new_m, d_m = simulate_delta(rf_lt_agg, X_full_lt_agg, {name: v})\n",
    "    whatif[\"AGG\"][\"lead_time\"][f\"{name}_{v:+g}\"] = {\"base_mean\": base_m, \"new_mean\": new_m, \"delta_mean\": d_m}\n",
    "\n",
    "X_pr_agg_built = build_features_for_production(df, exclude_cols=[])\n",
    "X_full_pr_agg  = align_X_for_model(X_pr_agg_built, FEATS_AG_PR)\n",
    "sc_pr = get_scenarios(X_full_pr_agg.columns)\n",
    "for name, v in sc_pr.items():\n",
    "    base_m, new_m, d_m = simulate_delta(rf_pr_agg, X_full_pr_agg, {name: v})\n",
    "    whatif[\"AGG\"][\"production\"][f\"{name}_{v:+g}\"] = {\"base_mean\": base_m, \"new_mean\": new_m, \"delta_mean\": d_m}\n",
    "\n",
    "# ---------- SKU별 ----------\n",
    "for sid, packs in per_sku_results.items():\n",
    "    whatif[\"SKU\"][sid] = {}\n",
    "    if packs[\"lead_time\"] is not None:\n",
    "        exclude_lt = set(sku_targets[sid][\"cell_cols\"])\n",
    "        exclude_lt |= {c for c in df.columns if c.startswith(f\"SKU{sid}_\") and time_like_regex.search(c)}\n",
    "        X_lt_sku_built = build_features_for_leadtime(df, list(exclude_lt), add_bneck_onehot=True, top_bneck_list=TOP_BNECKS)\n",
    "        trained_feats_lt = packs[\"lead_time\"][\"feats\"]\n",
    "        X_lt_full = align_X_for_model(X_lt_sku_built, trained_feats_lt)\n",
    "        lt_map = {}\n",
    "        for name, v in WHATIF_SCENARIOS.items():\n",
    "            if name in X_lt_full.columns:\n",
    "                base_m, new_m, d_m = simulate_delta(packs[\"lead_time\"][\"rf\"][0], X_lt_full, {name: v})\n",
    "                lt_map[f\"{name}_{v:+g}\"] = {\"base_mean\": base_m, \"new_mean\": new_m, \"delta_mean\": d_m}\n",
    "        whatif[\"SKU\"][sid][\"lead_time\"] = lt_map\n",
    "    if packs[\"production\"] is not None:\n",
    "        exclude_pr = set(sku_targets[sid][\"cell_cols\"])\n",
    "        X_pr_sku_built = build_features_for_production(df, list(exclude_pr))\n",
    "        trained_feats_pr = packs[\"production\"][\"feats\"]\n",
    "        X_pr_full = align_X_for_model(X_pr_sku_built, trained_feats_pr)\n",
    "        pr_map = {}\n",
    "        for name, v in WHATIF_SCENARIOS.items():\n",
    "            if name in X_pr_full.columns:\n",
    "                base_m, new_m, d_m = simulate_delta(packs[\"production\"][\"rf\"][0], X_pr_full, {name: v})\n",
    "                pr_map[f\"{name}_{v:+g}\"] = {\"base_mean\": base_m, \"new_mean\": new_m, \"delta_mean\": d_m}\n",
    "        whatif[\"SKU\"][sid][\"production\"] = pr_map\n",
    "\n",
    "save_json(whatif, \"whatif_results.json\", \"cell6\")\n",
    "\n",
    "# --- 설명 + 결과 일부 출력 ---\n",
    "print(\"\\n[What-if 시뮬레이션 설명]\")\n",
    "print(\"특정 변수(Queue/Util)를 ± 변화시켰을 때, 리드타임·생산량 평균의 변화를 계산합니다.\")\n",
    "print(\"→ base_mean: 원래 평균, new_mean: 변화 후 평균, delta_mean: 차이(new - base).\")\n",
    "print(\"\\n=== What-if (AGG) ===\")\n",
    "print(json.dumps(whatif[\"AGG\"], ensure_ascii=False, indent=2))\n",
    "\n",
    "list_saved(\"cell6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eae0ce1-4b6f-4be9-b4de-6ea9009c41a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "695ab228-2f16-4b10-a5d0-18d576eac1dc",
   "metadata": {},
   "source": [
    "# 7a) 품질 단계 탈락(불량) 프록시 생성 + 관계/해석 (+파일 목록)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb0634d6-4427-4e15-91f7-3ccbc292280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEFECT PROXY] '_quality_reject_proxy' 생성 완료. 예시 통계: {'min': 0.0, 'median': 0.5141528248786926, 'max': 1.0}\n",
      "\n",
      "=== 병목 ↔ 불량 Proxy 관계 (기초) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>count</th>\n",
       "      <th>mean_defect</th>\n",
       "      <th>std_defect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warehouse_4_Queue</td>\n",
       "      <td>36</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.187337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Press2_Queue</td>\n",
       "      <td>5</td>\n",
       "      <td>0.528022</td>\n",
       "      <td>0.216524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Warehouse1_Queue</td>\n",
       "      <td>77631</td>\n",
       "      <td>0.521246</td>\n",
       "      <td>0.210814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Warehouse_3_Queue</td>\n",
       "      <td>1307</td>\n",
       "      <td>0.504420</td>\n",
       "      <td>0.216034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forklift_Blanking_Queue</td>\n",
       "      <td>53681</td>\n",
       "      <td>0.497501</td>\n",
       "      <td>0.211187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Forklift_Press_Queue</td>\n",
       "      <td>9</td>\n",
       "      <td>0.479962</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Press4_Queue</td>\n",
       "      <td>6</td>\n",
       "      <td>0.447602</td>\n",
       "      <td>0.117323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bneck  count  mean_defect  std_defect\n",
       "0        Warehouse_4_Queue     36     0.553382    0.187337\n",
       "1             Press2_Queue      5     0.528022    0.216524\n",
       "2         Warehouse1_Queue  77631     0.521246    0.210814\n",
       "3        Warehouse_3_Queue   1307     0.504420    0.216034\n",
       "4  Forklift_Blanking_Queue  53681     0.497501    0.211187\n",
       "5     Forklift_Press_Queue      9     0.479962    0.117338\n",
       "6             Press4_Queue      6     0.447602    0.117323\n",
       "7      Blanking_SKU3_Queue      1     0.000000         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\bneck_vs_defectProxy_basic.csv (csv)\n",
      "\n",
      "[Saved files in cell7a]\n",
      " - outputs\\082416\\bneck_vs_defectProxy_basic.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 7a) 품질 프록시 생성(_quality_reject_proxy)\n",
    "# --------------------------------------------\n",
    "# ✔ PAINT(병렬)·QUALITY Util/Queue·최종산출Δ을 활용해\n",
    "#   '탈락/재작업' 지표를 0~1 스케일로 구성하여 df에 부착.\n",
    "# ✔ 병목 ↔ 불량 프록시 관계(기초) 표도 함께 출력/저장.\n",
    "# ============================================\n",
    "begin_cell(\"cell7a\")\n",
    "\n",
    "def _safe_col(df, name, default=0.0):\n",
    "    return pd.to_numeric(df[name], errors=\"coerce\").fillna(default).astype(\"float32\") if name in df.columns else pd.Series(default, index=df.index, dtype=\"float32\")\n",
    "\n",
    "# 1) 원천 시계열\n",
    "u_p1   = _safe_col(df, \"Paint1_Util\")\n",
    "u_p2   = _safe_col(df, \"Paint2_Util\")\n",
    "u_q    = _safe_col(df, \"Quality_Util\")\n",
    "q_q    = _safe_col(df, \"Quality_Queue\")\n",
    "tot    = _safe_col(df, \"c_TotalProducts\")\n",
    "\n",
    "# 2) 최종 산출 증가분(Δ)\n",
    "delta_final_raw = tot.diff().fillna(0.0).clip(lower=0).astype(\"float32\")\n",
    "delta_final     = delta_final_raw.rolling(window=5, min_periods=1).mean().astype(\"float32\")\n",
    "\n",
    "# 3) 상/하류 지수\n",
    "upstream_idx = (u_p1 + u_p2 + u_q).astype(\"float32\")\n",
    "quality_load = (q_q).astype(\"float32\")\n",
    "downstream_y = (delta_final).astype(\"float32\")\n",
    "\n",
    "def _z(x):\n",
    "    mu, sd = float(np.nanmean(x)), float(np.nanstd(x))\n",
    "    if not np.isfinite(sd) or sd == 0:\n",
    "        return pd.Series(0.0, index=df.index, dtype=\"float32\")\n",
    "    return ((x - mu) / sd).astype(\"float32\")\n",
    "\n",
    "zu = _z(upstream_idx); zq = _z(quality_load); zy = _z(downstream_y)\n",
    "raw_defect_proxy = (zu + zq - zy).astype(\"float32\")\n",
    "\n",
    "win = 25\n",
    "proxy_smooth = raw_defect_proxy.rolling(window=win, min_periods=1).mean()\n",
    "mn, mx = float(proxy_smooth.quantile(0.01)), float(proxy_smooth.quantile(0.99))\n",
    "den = (mx - mn) if (mx - mn) > 1e-6 else 1.0\n",
    "quality_reject_proxy = ((proxy_smooth - mn) / den).clip(0, 1).astype(\"float32\")\n",
    "\n",
    "df[\"_quality_reject_proxy\"] = quality_reject_proxy\n",
    "print(\"[DEFECT PROXY] '_quality_reject_proxy' 생성 완료. 예시 통계:\",\n",
    "      {\"min\": float(quality_reject_proxy.min()),\n",
    "       \"median\": float(quality_reject_proxy.median()),\n",
    "       \"max\": float(quality_reject_proxy.max())})\n",
    "\n",
    "# 병목 ↔ 불량 proxy 관계(기초)\n",
    "if \"_bneck\" in df.columns and \"_quality_reject_proxy\" in df.columns:\n",
    "    tmp = pd.DataFrame({\n",
    "        \"bneck\": df[\"_bneck\"],\n",
    "        \"defect_proxy\": df[\"_quality_reject_proxy\"].astype(\"float32\")\n",
    "    })\n",
    "    stats = tmp.groupby(\"bneck\", observed=False).agg(\n",
    "        count=(\"defect_proxy\", \"count\"),\n",
    "        mean_defect=(\"defect_proxy\", \"mean\"),\n",
    "        std_defect=(\"defect_proxy\", \"std\")\n",
    "    ).sort_values(\"mean_defect\", ascending=False).reset_index()\n",
    "    print(\"\\n=== 병목 ↔ 불량 Proxy 관계 (기초) ===\")\n",
    "    display(stats.head(15))\n",
    "    save_csv(stats, \"bneck_vs_defectProxy_basic.csv\", \"cell7a\")\n",
    "else:\n",
    "    print(\"bneck 또는 defect proxy 컬럼이 없습니다.\")\n",
    "\n",
    "list_saved(\"cell7a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d5854-ba20-4d68-84c7-b875f9d51f4a",
   "metadata": {},
   "source": [
    "# 7) 병목 ↔ 불량 프록시 심화 분석 (신뢰도, CI, SKU/래그/층화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281fa8da-8196-4f11-9c97-a2e72c756fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\bneck_vs_defectProxy_main_CI.csv (csv)\n",
      "[SAVED] outputs\\082416\\bneck_vs_defectProxy_lowCount_CI.csv (csv)\n",
      "\n",
      "=== 병목 ↔ 불량 Proxy (표본≥200) — 전체 평균=0.511 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>count</th>\n",
       "      <th>mean_defect</th>\n",
       "      <th>std_defect</th>\n",
       "      <th>lift_vs_overall</th>\n",
       "      <th>rel_lift_%</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>sig_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Warehouse1_Queue</td>\n",
       "      <td>77631</td>\n",
       "      <td>0.521246</td>\n",
       "      <td>0.210814</td>\n",
       "      <td>0.009774</td>\n",
       "      <td>1.910962</td>\n",
       "      <td>0.519763</td>\n",
       "      <td>0.522729</td>\n",
       "      <td>★</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Warehouse_3_Queue</td>\n",
       "      <td>1307</td>\n",
       "      <td>0.504420</td>\n",
       "      <td>0.216034</td>\n",
       "      <td>-0.007052</td>\n",
       "      <td>-1.378685</td>\n",
       "      <td>0.492708</td>\n",
       "      <td>0.516132</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forklift_Blanking_Queue</td>\n",
       "      <td>53681</td>\n",
       "      <td>0.497501</td>\n",
       "      <td>0.211187</td>\n",
       "      <td>-0.013971</td>\n",
       "      <td>-2.731488</td>\n",
       "      <td>0.495714</td>\n",
       "      <td>0.499288</td>\n",
       "      <td>★</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     bneck  count  mean_defect  std_defect  lift_vs_overall  rel_lift_%    ci_low   ci_high sig_95\n",
       "5         Warehouse1_Queue  77631     0.521246    0.210814         0.009774    1.910962  0.519763  0.522729      ★\n",
       "6        Warehouse_3_Queue   1307     0.504420    0.216034        -0.007052   -1.378685  0.492708  0.516132       \n",
       "1  Forklift_Blanking_Queue  53681     0.497501    0.211187        -0.013971   -2.731488  0.495714  0.499288      ★"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 병목 ↔ 불량 Proxy (표본<200) — 참고용 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bneck</th>\n",
       "      <th>count</th>\n",
       "      <th>mean_defect</th>\n",
       "      <th>std_defect</th>\n",
       "      <th>lift_vs_overall</th>\n",
       "      <th>rel_lift_%</th>\n",
       "      <th>ci_low</th>\n",
       "      <th>ci_high</th>\n",
       "      <th>sig_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Warehouse_4_Queue</td>\n",
       "      <td>36</td>\n",
       "      <td>0.553382</td>\n",
       "      <td>0.187337</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>8.194092</td>\n",
       "      <td>0.492186</td>\n",
       "      <td>0.614579</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Press2_Queue</td>\n",
       "      <td>5</td>\n",
       "      <td>0.528022</td>\n",
       "      <td>0.216524</td>\n",
       "      <td>0.016550</td>\n",
       "      <td>3.235831</td>\n",
       "      <td>0.338231</td>\n",
       "      <td>0.717814</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forklift_Press_Queue</td>\n",
       "      <td>9</td>\n",
       "      <td>0.479962</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>-0.031510</td>\n",
       "      <td>-6.160611</td>\n",
       "      <td>0.403301</td>\n",
       "      <td>0.556623</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Press4_Queue</td>\n",
       "      <td>6</td>\n",
       "      <td>0.447602</td>\n",
       "      <td>0.117323</td>\n",
       "      <td>-0.063870</td>\n",
       "      <td>-12.487465</td>\n",
       "      <td>0.353724</td>\n",
       "      <td>0.541480</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blanking_SKU3_Queue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.511472</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bneck  count  mean_defect  std_defect  lift_vs_overall  rel_lift_%    ci_low   ci_high sig_95\n",
       "7     Warehouse_4_Queue     36     0.553382    0.187337         0.041910    8.194092  0.492186  0.614579       \n",
       "3          Press2_Queue      5     0.528022    0.216524         0.016550    3.235831  0.338231  0.717814       \n",
       "2  Forklift_Press_Queue      9     0.479962    0.117338        -0.031510   -6.160611  0.403301  0.556623       \n",
       "4          Press4_Queue      6     0.447602    0.117323        -0.063870  -12.487465  0.353724  0.541480       \n",
       "0   Blanking_SKU3_Queue      1     0.000000         NaN        -0.511472 -100.000000       NaN       NaN       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[요약] 표본≥200 중 lift 최대: Warehouse1_Queue (lift=0.010, rel=1.9%, 95% CI [0.008, 0.011] ★)\n",
      "\n",
      "=== 병목 × SKU 평균 불량 Proxy ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sku</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bneck</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Blanking_SKU3_Queue</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forklift_Blanking_Queue</th>\n",
       "      <td>0.497078</td>\n",
       "      <td>0.506164</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.494360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forklift_Press_Queue</th>\n",
       "      <td>0.407522</td>\n",
       "      <td>0.275847</td>\n",
       "      <td>0.516404</td>\n",
       "      <td>0.527135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Press2_Queue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Press4_Queue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warehouse1_Queue</th>\n",
       "      <td>0.524061</td>\n",
       "      <td>0.525224</td>\n",
       "      <td>0.517986</td>\n",
       "      <td>0.512809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warehouse_3_Queue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543214</td>\n",
       "      <td>0.502751</td>\n",
       "      <td>0.520273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Warehouse_4_Queue</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.483111</td>\n",
       "      <td>0.498602</td>\n",
       "      <td>0.588946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sku                             1         2         3         4\n",
       "bneck                                                          \n",
       "Blanking_SKU3_Queue      0.000000       NaN       NaN       NaN\n",
       "Forklift_Blanking_Queue  0.497078  0.506164  0.494624  0.494360\n",
       "Forklift_Press_Queue     0.407522  0.275847  0.516404  0.527135\n",
       "Press2_Queue                  NaN  0.528022       NaN       NaN\n",
       "Press4_Queue                  NaN       NaN       NaN  0.447602\n",
       "Warehouse1_Queue         0.524061  0.525224  0.517986  0.512809\n",
       "Warehouse_3_Queue             NaN  0.543214  0.502751  0.520273\n",
       "Warehouse_4_Queue             NaN  0.483111  0.498602  0.588946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\bneck_x_sku_defectProxy.csv (csv)\n",
      "\n",
      "=== Warehouse1_Queue 병목 vs 비-병목 (SKU별, n≥200) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>n_focus</th>\n",
       "      <th>n_other</th>\n",
       "      <th>mean_focus</th>\n",
       "      <th>mean_other</th>\n",
       "      <th>lift</th>\n",
       "      <th>rel_lift_%</th>\n",
       "      <th>z_approx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27738</td>\n",
       "      <td>1633</td>\n",
       "      <td>0.524061</td>\n",
       "      <td>0.496719</td>\n",
       "      <td>0.027342</td>\n",
       "      <td>5.232476</td>\n",
       "      <td>5.138274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14526</td>\n",
       "      <td>19623</td>\n",
       "      <td>0.517987</td>\n",
       "      <td>0.495140</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>4.525352</td>\n",
       "      <td>9.890108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21558</td>\n",
       "      <td>13539</td>\n",
       "      <td>0.525224</td>\n",
       "      <td>0.506246</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>3.664424</td>\n",
       "      <td>8.181109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13809</td>\n",
       "      <td>20250</td>\n",
       "      <td>0.512809</td>\n",
       "      <td>0.494511</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>3.645392</td>\n",
       "      <td>7.884097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SKU  n_focus  n_other  mean_focus  mean_other      lift  rel_lift_%  z_approx\n",
       "0   1    27738     1633    0.524061    0.496719  0.027342    5.232476  5.138274\n",
       "2   3    14526    19623    0.517987    0.495140  0.022847    4.525352  9.890108\n",
       "1   2    21558    13539    0.525224    0.506246  0.018978    3.664424  8.181109\n",
       "3   4    13809    20250    0.512809    0.494511  0.018297    3.645392  7.884097"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\sku_cmp_Warehouse1_Queue.csv (csv)\n",
      "\n",
      "=== Warehouse1_Queue ↔ Defect Proxy 상관 (래그) ===\n",
      "Lag -6: 0.0042\n",
      "Lag -5: 0.0041\n",
      "Lag -4: 0.0051\n",
      "Lag -3: 0.0056\n",
      "Lag -2: 0.0051\n",
      "Lag -1: 0.0053\n",
      "Lag +0: 0.0620\n",
      "Lag +1: 0.0625\n",
      "Lag +2: 0.0620\n",
      "Lag +3: 0.0614\n",
      "Lag +4: 0.0605\n",
      "Lag +5: 0.0636\n",
      "Lag +6: 0.0631\n",
      "[SAVED] outputs\\082416\\corr_lag_Warehouse1_Queue_vs_defectProxy.csv (csv)\n",
      "\n",
      "=== 창고1 Queue 분위수별 불량 Proxy 평균 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>n</th>\n",
       "      <th>proxy_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.001, 108.222]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.488169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(108.222, 124.823]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.497153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(124.823, 138.934]</td>\n",
       "      <td>13267</td>\n",
       "      <td>0.500140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(138.934, 153.135]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.501666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(153.135, 168.504]</td>\n",
       "      <td>13267</td>\n",
       "      <td>0.507277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(168.504, 186.166]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.514875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(186.166, 208.301]</td>\n",
       "      <td>13267</td>\n",
       "      <td>0.518185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(208.301, 240.038]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.522366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(240.038, 296.61]</td>\n",
       "      <td>13267</td>\n",
       "      <td>0.527139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(296.61, 1828.135]</td>\n",
       "      <td>13268</td>\n",
       "      <td>0.537749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  bin      n  proxy_mean\n",
       "0   (-0.001, 108.222]  13268    0.488169\n",
       "1  (108.222, 124.823]  13268    0.497153\n",
       "2  (124.823, 138.934]  13267    0.500140\n",
       "3  (138.934, 153.135]  13268    0.501666\n",
       "4  (153.135, 168.504]  13267    0.507277\n",
       "5  (168.504, 186.166]  13268    0.514875\n",
       "6  (186.166, 208.301]  13267    0.518185\n",
       "7  (208.301, 240.038]  13268    0.522366\n",
       "8   (240.038, 296.61]  13267    0.527139\n",
       "9  (296.61, 1828.135]  13268    0.537749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\quantile_trend_Warehouse1_Queue.csv (csv)\n",
      "[임계치] Warehouse1_Queue ≥ 240.0 를 고위험으로 간주\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_w1q_risk</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>106140</td>\n",
       "      <td>0.506231</td>\n",
       "      <td>0.211275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26536</td>\n",
       "      <td>0.532436</td>\n",
       "      <td>0.210230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _w1q_risk   count      mean       std\n",
       "0          0  106140  0.506231  0.211275\n",
       "1          1   26536  0.532436  0.210230"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\risk_summary_Warehouse1_Queue.csv (csv)\n",
      "\n",
      "[층화] Quality_Util 레벨별 병목 lift\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_a</th>\n",
       "      <th>n_b</th>\n",
       "      <th>mean_a</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22901.0</td>\n",
       "      <td>21326.0</td>\n",
       "      <td>0.500582</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>0.020487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26020.0</td>\n",
       "      <td>18205.0</td>\n",
       "      <td>0.520903</td>\n",
       "      <td>0.500898</td>\n",
       "      <td>0.020005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28710.0</td>\n",
       "      <td>15514.0</td>\n",
       "      <td>0.538039</td>\n",
       "      <td>0.518102</td>\n",
       "      <td>0.019937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_a      n_b    mean_a    mean_b      lift\n",
       "0  22901.0  21326.0  0.500582  0.480096  0.020487\n",
       "1  26020.0  18205.0  0.520903  0.500898  0.020005\n",
       "2  28710.0  15514.0  0.538039  0.518102  0.019937"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\stratified_lift_by_QualityUtil.csv (csv)\n",
      "\n",
      "[Saved files in cell7]\n",
      " - outputs\\082416\\bneck_vs_defectProxy_main_CI.csv\n",
      " - outputs\\082416\\bneck_vs_defectProxy_lowCount_CI.csv\n",
      " - outputs\\082416\\bneck_x_sku_defectProxy.csv\n",
      " - outputs\\082416\\sku_cmp_Warehouse1_Queue.csv\n",
      " - outputs\\082416\\corr_lag_Warehouse1_Queue_vs_defectProxy.csv\n",
      " - outputs\\082416\\quantile_trend_Warehouse1_Queue.csv\n",
      " - outputs\\082416\\risk_summary_Warehouse1_Queue.csv\n",
      " - outputs\\082416\\stratified_lift_by_QualityUtil.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 7) 병목 ↔ 불량 프록시 심화 분석 (신뢰도, CI, SKU/래그/층화)\n",
    "# --------------------------------------------\n",
    "# ✔ 표본수 하한(기본 200) 적용, 전체평균 대비 lift/rel_lift/95% CI/유의성 표.\n",
    "# ✔ 병목×SKU 피벗, 병목군 vs 비-병목군(SKU별) 비교, 래그 상관, 분위수 트렌드,\n",
    "#   임계치 기반 리스크, 층화(layers)까지 저장/출력.\n",
    "# ============================================\n",
    "begin_cell(\"cell7\")\n",
    "\n",
    "tgt_name = \"_quality_reject_proxy\"\n",
    "min_count = 200\n",
    "overall_mean = float(df[tgt_name].mean())\n",
    "\n",
    "# 요약 통계 + CI\n",
    "tmp = pd.DataFrame({\"bneck\": df[\"_bneck\"], \"defect_proxy\": df[tgt_name].astype(\"float32\")})\n",
    "stats = (\n",
    "    tmp.groupby(\"bneck\", observed=False)\n",
    "       .agg(count=(\"defect_proxy\",\"count\"),\n",
    "            mean_defect=(\"defect_proxy\",\"mean\"),\n",
    "            std_defect=(\"defect_proxy\",\"std\"))\n",
    "       .reset_index()\n",
    ")\n",
    "stats[\"se\"] = stats[\"std_defect\"]/np.sqrt(stats[\"count\"].clip(lower=1))\n",
    "stats[\"ci_low\"]  = stats[\"mean_defect\"] - 1.96*stats[\"se\"]\n",
    "stats[\"ci_high\"] = stats[\"mean_defect\"] + 1.96*stats[\"se\"]\n",
    "stats[\"lift_vs_overall\"] = stats[\"mean_defect\"] - overall_mean\n",
    "stats[\"rel_lift_%\"] = 100.0 * stats[\"lift_vs_overall\"] / overall_mean\n",
    "stats[\"z\"] = (stats[\"mean_defect\"] - overall_mean) / stats[\"se\"].replace(0, np.nan)\n",
    "stats[\"sig_95\"] = np.where(stats[\"z\"].abs() >= 1.96, \"★\", \"\")\n",
    "\n",
    "stats_strong = stats[stats[\"count\"] >= min_count].copy().sort_values([\"rel_lift_%\",\"count\"], ascending=[False,False])\n",
    "stats_weak   = stats[stats[\"count\"] <  min_count].copy().sort_values([\"rel_lift_%\",\"count\"], ascending=[False,False])\n",
    "\n",
    "save_csv(stats_strong, \"bneck_vs_defectProxy_main_CI.csv\", \"cell7\")\n",
    "save_csv(stats_weak,   \"bneck_vs_defectProxy_lowCount_CI.csv\", \"cell7\")\n",
    "\n",
    "print(f\"\\n=== 병목 ↔ 불량 Proxy (표본≥{min_count}) — 전체 평균={overall_mean:.3f} ===\")\n",
    "cols_show = [\"bneck\",\"count\",\"mean_defect\",\"std_defect\",\"lift_vs_overall\",\"rel_lift_%\",\"ci_low\",\"ci_high\",\"sig_95\"]\n",
    "display(stats_strong[cols_show].head(15))\n",
    "if len(stats_weak):\n",
    "    print(f\"\\n=== 병목 ↔ 불량 Proxy (표본<{min_count}) — 참고용 ===\")\n",
    "    display(stats_weak[cols_show].head(15))\n",
    "\n",
    "if len(stats_strong):\n",
    "    top = stats_strong.iloc[0]\n",
    "    print(f\"\\n[요약] 표본≥{min_count} 중 lift 최대: {top['bneck']} \"\n",
    "          f\"(lift={top['lift_vs_overall']:.3f}, rel={top['rel_lift_%']:.1f}%, 95% CI [{top['ci_low']-overall_mean:.3f}, {top['ci_high']-overall_mean:.3f}] {top['sig_95']})\")\n",
    "\n",
    "# 병목 × SKU 피벗\n",
    "cell_sku_cols = [c for c in df.columns if re.match(r\"^c_Cell\\d+__?SKU\\d+$\", c)]\n",
    "sku_ids_all = sorted(set(re.findall(r\"SKU(\\d+)\", \" \".join(cell_sku_cols))), key=lambda x:int(x))\n",
    "sku_by_row = pd.DataFrame({s: df.filter(regex=fr\"^c_Cell\\d+__?SKU{s}$\").sum(axis=1).astype(\"float32\") for s in sku_ids_all})\n",
    "df[\"_sku_dom\"] = sku_by_row.idxmax(axis=1).str.extract(r\"(\\d+)\")\n",
    "tmp2 = pd.DataFrame({\"bneck\": df[\"_bneck\"], \"sku\": df[\"_sku_dom\"], \"defect_proxy\": df[tgt_name]})\n",
    "mat = tmp2.pivot_table(index=\"bneck\", columns=\"sku\", values=\"defect_proxy\", aggfunc=\"mean\")\n",
    "print(\"\\n=== 병목 × SKU 평균 불량 Proxy ===\")\n",
    "display(mat)\n",
    "save_csv(mat.reset_index(), \"bneck_x_sku_defectProxy.csv\", \"cell7\")\n",
    "\n",
    "# SKU별 병목 vs 비병목 비교 (Warehouse1_Queue 예시)\n",
    "focus = \"Warehouse1_Queue\"\n",
    "res = []\n",
    "for sku in sorted(df[\"_sku_dom\"].dropna().unique(), key=lambda x:int(x)):\n",
    "    sub = df[df[\"_sku_dom\"] == sku]\n",
    "    a = sub[sub[\"_bneck\"] == focus][tgt_name].dropna()\n",
    "    b = sub[sub[\"_bneck\"] != focus][tgt_name].dropna()\n",
    "    if len(a) >= min_count and len(b) >= min_count:\n",
    "        mean_a, mean_b = float(a.mean()), float(b.mean())\n",
    "        lift = mean_a - mean_b\n",
    "        rel = 100.0 * lift / (float(sub[tgt_name].mean()) + 1e-9)\n",
    "        se = np.sqrt(a.var(ddof=1)/len(a) + b.var(ddof=1)/len(b))\n",
    "        z = (lift / se) if se > 0 else np.nan\n",
    "        res.append({\"SKU\": sku, \"n_focus\": len(a), \"n_other\": len(b),\n",
    "                    \"mean_focus\": mean_a, \"mean_other\": mean_b,\n",
    "                    \"lift\": lift, \"rel_lift_%\": rel, \"z_approx\": z})\n",
    "sku_cmp = pd.DataFrame(res).sort_values([\"rel_lift_%\",\"n_focus\"], ascending=[False,False])\n",
    "print(f\"\\n=== {focus} 병목 vs 비-병목 (SKU별, n≥{min_count}) ===\")\n",
    "display(sku_cmp)\n",
    "save_csv(sku_cmp, f\"sku_cmp_{focus.replace(' ','_')}.csv\", \"cell7\")\n",
    "\n",
    "# 래그 상관\n",
    "series_x = df[focus].astype(\"float32\")\n",
    "series_y = df[tgt_name].astype(\"float32\")\n",
    "\n",
    "def corr_lag(x, y, lag):\n",
    "    if lag > 0:\n",
    "        return x.shift(lag).corr(y)\n",
    "    elif lag < 0:\n",
    "        return x.corr(y.shift(-lag))\n",
    "    else:\n",
    "        return x.corr(y)\n",
    "\n",
    "lags = range(-6, 7)\n",
    "corrs = {lag: corr_lag(series_x, series_y, lag) for lag in lags}\n",
    "corr_df = pd.DataFrame({\"lag\": list(corrs.keys()), \"corr\": list(corrs.values())})\n",
    "print(\"\\n=== Warehouse1_Queue ↔ Defect Proxy 상관 (래그) ===\")\n",
    "for lag in sorted(corrs):\n",
    "    print(f\"Lag {lag:+d}: {corrs[lag]:.4f}\")\n",
    "save_csv(corr_df, \"corr_lag_Warehouse1_Queue_vs_defectProxy.csv\", \"cell7\")\n",
    "\n",
    "# 분위수별 트렌드\n",
    "x = df[focus].astype(\"float32\")\n",
    "y = df[tgt_name].astype(\"float32\")\n",
    "bins = pd.qcut(x, 10, duplicates=\"drop\")\n",
    "trend = pd.DataFrame({\"bin\": bins, \"proxy\": y}).groupby(\"bin\", observed=False).agg(n=(\"proxy\",\"count\"), proxy_mean=(\"proxy\",\"mean\")).reset_index()\n",
    "print(\"\\n=== 창고1 Queue 분위수별 불량 Proxy 평균 ===\")\n",
    "display(trend)\n",
    "save_csv(trend, \"quantile_trend_Warehouse1_Queue.csv\", \"cell7\")\n",
    "\n",
    "# 임계치 리스크\n",
    "thr = df[focus].quantile(0.80)\n",
    "df[\"_w1q_risk\"] = (df[focus] >= thr).astype(int)\n",
    "summary_risk = df.groupby(\"_w1q_risk\")[\"_quality_reject_proxy\"].agg([\"count\",\"mean\",\"std\"]).reset_index()\n",
    "print(f\"[임계치] {focus} ≥ {thr:.1f} 를 고위험으로 간주\")\n",
    "display(summary_risk)\n",
    "save_csv(summary_risk, \"risk_summary_Warehouse1_Queue.csv\", \"cell7\")\n",
    "\n",
    "# 층화(예: Quality_Util 3분위)\n",
    "q_bins = pd.qcut(df[\"Quality_Util\"], q=3, labels=[\"low\",\"mid\",\"high\"])\n",
    "def layer_lift(layer):\n",
    "    sub = df[q_bins == layer]\n",
    "    a = sub[sub[\"_bneck\"]==focus][tgt_name]\n",
    "    b = sub[sub[\"_bneck\"]!=focus][tgt_name]\n",
    "    return pd.Series({\n",
    "        \"n_a\": len(a), \"n_b\": len(b),\n",
    "        \"mean_a\": a.mean(), \"mean_b\": b.mean(),\n",
    "        \"lift\": a.mean()-b.mean()\n",
    "    })\n",
    "layer_df = pd.concat([layer_lift(\"low\"), layer_lift(\"mid\"), layer_lift(\"high\")], axis=1).T\n",
    "print(\"\\n[층화] Quality_Util 레벨별 병목 lift\")\n",
    "display(layer_df)\n",
    "save_csv(layer_df.reset_index().rename(columns={\"index\":\"Quality_Util_level\"}), \"stratified_lift_by_QualityUtil.csv\", \"cell7\")\n",
    "\n",
    "list_saved(\"cell7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92412a07-851c-4002-8289-4530b999678a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee4cd208-144a-4ea3-a45d-60eade1dcc2f",
   "metadata": {},
   "source": [
    "# 8) (옵션) mu/sd 기반 편차 파생피처 (수동 호출 예시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4950459e-8c22-4e11-9f00-866214678f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Saved files in cell8]\n",
      " (none)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 8) (옵션) mu/sd 기반 편차 파생피처 (수동 호출 예시)\n",
    "# --------------------------------------------\n",
    "# ✔ 이미 2번 셀에서 MUSD_ON_START=True로 생성했으므로 일반적으로 불필요.\n",
    "# ✔ 필요 시 수동으로 재생성/추가할 때만 사용.\n",
    "# ============================================\n",
    "begin_cell(\"cell8\")\n",
    "\n",
    "# 필요 시 주석 해제해 실행\n",
    "# musd_cols_manual = add_musd_features(df, sku_ids)\n",
    "# print(\"[MUSD manual] created:\", musd_cols_manual)\n",
    "\n",
    "list_saved(\"cell8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c163d1-31df-4c13-867f-beec136f4b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da2d667b-ffca-43ab-8a02-2b22ea23f1ef",
   "metadata": {},
   "source": [
    "# 9) 요약 리포트 저장 (+파일 목록 총괄)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4215fe00-862e-49ed-8883-f3f6b21ebec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] outputs\\082416\\SUMMARY.json (json)\n",
      "\n",
      "=== SUMMARY ===\n",
      "{\n",
      "  \"run_stamp\": \"082416\",\n",
      "  \"out_dir\": \"./outputs\\\\082416\",\n",
      "  \"cwd\": \"D:\\\\Project\\\\Python_Source\\\\Test01\\\\0819\",\n",
      "  \"dataset_shape\": [\n",
      "    132676,\n",
      "    78\n",
      "  ],\n",
      "  \"detected_skus\": [\n",
      "    \"1\",\n",
      "    \"2\",\n",
      "    \"3\",\n",
      "    \"4\"\n",
      "  ],\n",
      "  \"top_bottlenecks_used\": [\n",
      "    \"Warehouse1_Queue\",\n",
      "    \"Forklift_Blanking_Queue\",\n",
      "    \"Warehouse_3_Queue\",\n",
      "    \"Warehouse_4_Queue\",\n",
      "    \"Forklift_Press_Queue\",\n",
      "    \"Press4_Queue\",\n",
      "    \"Press2_Queue\",\n",
      "    \"Blanking_SKU3_Queue\"\n",
      "  ],\n",
      "  \"metrics\": {\n",
      "    \"AGG\": {\n",
      "      \"RF_LT\": 0.8874460359017269,\n",
      "      \"RG_LT\": {\n",
      "        \"MAE\": 0.005,\n",
      "        \"RMSE\": 0.016,\n",
      "        \"R2\": 0.5805\n",
      "      },\n",
      "      \"RF_PR\": 0.9880771185836398,\n",
      "      \"RG_PR\": {\n",
      "        \"MAE\": 120.093,\n",
      "        \"RMSE\": 169.142,\n",
      "        \"R2\": 0.9781\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"outputs\": {\n",
      "    \"bottleneck_total\": \"./outputs\\\\082416\\\\bottleneck_totalProduction.csv\",\n",
      "    \"bottleneck_aggLT\": \"./outputs\\\\082416\\\\bottleneck_aggLeadTime.csv\",\n",
      "    \"sku_bneck_effect\": \"./outputs\\\\082416\\\\sku_bneck_effect_SKU*.csv\",\n",
      "    \"agg_fi_pi_lt\": [\n",
      "      \"fi_leadtime_AGG.csv\",\n",
      "      \"pi_leadtime_AGG.csv\",\n",
      "      \"fi_leadtime_AGG_top20.png\",\n",
      "      \"ridge_coef_leadtime_AGG.csv\",\n",
      "      \"ridge_betaStd_leadtime_AGG.csv\",\n",
      "      \"elasticity_leadtime_AGG_fast_lite.csv\"\n",
      "    ],\n",
      "    \"agg_fi_pi_pr\": [\n",
      "      \"fi_production_AGG.csv\",\n",
      "      \"pi_production_AGG.csv\",\n",
      "      \"fi_production_AGG_top20.png\",\n",
      "      \"ridge_coef_production_AGG.csv\",\n",
      "      \"ridge_betaStd_production_AGG.csv\",\n",
      "      \"elasticity_production_AGG_fast_lite.csv\"\n",
      "    ],\n",
      "    \"per_sku_elasticity\": \"elasticity_(leadtime|production)_SKU*_fast.csv\",\n",
      "    \"whatif\": \"./outputs\\\\082416\\\\whatif_results.json\",\n",
      "    \"defect_proxy\": [\n",
      "      \"bneck_vs_defectProxy_basic.csv\",\n",
      "      \"bneck_vs_defectProxy_main_CI.csv\",\n",
      "      \"bneck_vs_defectProxy_lowCount_CI.csv\",\n",
      "      \"bneck_x_sku_defectProxy.csv\",\n",
      "      \"corr_lag_Warehouse1_Queue_vs_defectProxy.csv\",\n",
      "      \"quantile_trend_Warehouse1_Queue.csv\",\n",
      "      \"risk_summary_Warehouse1_Queue.csv\",\n",
      "      \"stratified_lift_by_QualityUtil.csv\"\n",
      "    ]\n",
      "  },\n",
      "  \"file_log\": {\n",
      "    \"cell1\": [],\n",
      "    \"cell2\": [],\n",
      "    \"cell3\": [\n",
      "      \"outputs\\\\082416\\\\bottleneck_totalProduction.csv\",\n",
      "      \"outputs\\\\082416\\\\bottleneck_aggLeadTime.csv\",\n",
      "      \"outputs\\\\082416\\\\sku_bneck_effect_SKU1.csv\",\n",
      "      \"outputs\\\\082416\\\\sku_bneck_effect_SKU2.csv\",\n",
      "      \"outputs\\\\082416\\\\sku_bneck_effect_SKU3.csv\",\n",
      "      \"outputs\\\\082416\\\\sku_bneck_effect_SKU4.csv\"\n",
      "    ],\n",
      "    \"cell4\": [\n",
      "      \"outputs\\\\082416\\\\ridge_coef_leadtime_AGG.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_leadtime_AGG.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_coef_production_AGG.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_production_AGG.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_coef_leadtime_SKU1.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_leadtime_SKU1.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_coef_production_SKU1.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_production_SKU1.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_coef_leadtime_SKU2.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_leadtime_SKU2.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_coef_production_SKU2.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_production_SKU2.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_coef_leadtime_SKU3.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_leadtime_SKU3.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_coef_production_SKU3.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_production_SKU3.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_coef_leadtime_SKU4.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_leadtime_SKU4.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_coef_production_SKU4.csv\",\n",
      "      \"outputs\\\\082416\\\\ridge_betaStd_production_SKU4.csv\"\n",
      "    ],\n",
      "    \"cell5\": [\n",
      "      \"outputs\\\\082416\\\\elasticity_leadtime_AGG_fast_lite.csv\",\n",
      "      \"outputs\\\\082416\\\\elasticity_production_AGG_fast_lite.csv\",\n",
      "      \"outputs\\\\082416\\\\elasticity_leadtime_SKU1_fast_lite.csv\",\n",
      "      \"outputs\\\\082416\\\\elasticity_leadtime_SKU2_fast_lite.csv\",\n",
      "      \"outputs\\\\082416\\\\elasticity_leadtime_SKU3_fast_lite.csv\",\n",
      "      \"outputs\\\\082416\\\\elasticity_leadtime_SKU4_fast_lite.csv\"\n",
      "    ],\n",
      "    \"cell6\": [\n",
      "      \"outputs\\\\082416\\\\whatif_results.json\"\n",
      "    ],\n",
      "    \"cell7a\": [\n",
      "      \"outputs\\\\082416\\\\bneck_vs_defectProxy_basic.csv\"\n",
      "    ],\n",
      "    \"cell7\": [\n",
      "      \"outputs\\\\082416\\\\bneck_vs_defectProxy_main_CI.csv\",\n",
      "      \"outputs\\\\082416\\\\bneck_vs_defectProxy_lowCount_CI.csv\",\n",
      "      \"outputs\\\\082416\\\\bneck_x_sku_defectProxy.csv\",\n",
      "      \"outputs\\\\082416\\\\sku_cmp_Warehouse1_Queue.csv\",\n",
      "      \"outputs\\\\082416\\\\corr_lag_Warehouse1_Queue_vs_defectProxy.csv\",\n",
      "      \"outputs\\\\082416\\\\quantile_trend_Warehouse1_Queue.csv\",\n",
      "      \"outputs\\\\082416\\\\risk_summary_Warehouse1_Queue.csv\",\n",
      "      \"outputs\\\\082416\\\\stratified_lift_by_QualityUtil.csv\"\n",
      "    ],\n",
      "    \"cell8\": [],\n",
      "    \"cell9\": [\n",
      "      \"outputs\\\\082416\\\\SUMMARY.json\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "[Saved files in cell9]\n",
      " - outputs\\082416\\SUMMARY.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 9) 요약 리포트 저장 (SUMMARY.json)\n",
    "# --------------------------------------------\n",
    "# ✔ 데이터셋/모델 성능/사용된 상위 병목/출력 파일 안내를 한 곳에 저장.\n",
    "# ✔ 탄력도 파일명은 fast/fast_lite 중 실제 존재하는 것을 기록.\n",
    "# ✔ 타임스탬프/출력 디렉터리/셀별 파일 로그 포함.\n",
    "# ============================================\n",
    "begin_cell(\"cell9\")\n",
    "\n",
    "def pick_existing(*names):\n",
    "    for n in names:\n",
    "        if os.path.exists(os.path.join(OUT_DIR, n)):\n",
    "            return n\n",
    "    return names[0]\n",
    "\n",
    "summary = {\n",
    "    \"run_stamp\": RUN_STAMP,\n",
    "    \"out_dir\": OUT_DIR,\n",
    "    \"cwd\": os.getcwd(),\n",
    "    \"dataset_shape\": tuple(df.shape),\n",
    "    \"detected_skus\": sku_ids,\n",
    "    \"top_bottlenecks_used\": TOP_BNECKS,\n",
    "    \"metrics\": {\n",
    "        \"AGG\": {\n",
    "            \"RF_LT\": m_rf_lt_agg, \"RG_LT\": m_rg_lt_agg,\n",
    "            \"RF_PR\": m_rf_pr_agg, \"RG_PR\": m_rg_pr_agg,\n",
    "        }\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"bottleneck_total\": os.path.join(OUT_DIR, \"bottleneck_totalProduction.csv\"),\n",
    "        \"bottleneck_aggLT\": os.path.join(OUT_DIR, \"bottleneck_aggLeadTime.csv\"),\n",
    "        \"sku_bneck_effect\": os.path.join(OUT_DIR, \"sku_bneck_effect_SKU*.csv\"),\n",
    "        \"agg_fi_pi_lt\": [\n",
    "            \"fi_leadtime_AGG.csv\",\n",
    "            \"pi_leadtime_AGG.csv\",\n",
    "            \"fi_leadtime_AGG_top20.png\",\n",
    "            \"ridge_coef_leadtime_AGG.csv\",\n",
    "            \"ridge_betaStd_leadtime_AGG.csv\",\n",
    "            pick_existing(\"elasticity_leadtime_AGG_fast.csv\",\"elasticity_leadtime_AGG_fast_lite.csv\")\n",
    "        ],\n",
    "        \"agg_fi_pi_pr\": [\n",
    "            \"fi_production_AGG.csv\",\n",
    "            \"pi_production_AGG.csv\",\n",
    "            \"fi_production_AGG_top20.png\",\n",
    "            \"ridge_coef_production_AGG.csv\",\n",
    "            \"ridge_betaStd_production_AGG.csv\",\n",
    "            pick_existing(\"elasticity_production_AGG_fast.csv\",\"elasticity_production_AGG_fast_lite.csv\")\n",
    "        ],\n",
    "        \"per_sku_elasticity\": \"elasticity_(leadtime|production)_SKU*_fast.csv\",\n",
    "        \"whatif\": os.path.join(OUT_DIR, \"whatif_results.json\"),\n",
    "        \"defect_proxy\": [\n",
    "            \"bneck_vs_defectProxy_basic.csv\",\n",
    "            \"bneck_vs_defectProxy_main_CI.csv\",\n",
    "            \"bneck_vs_defectProxy_lowCount_CI.csv\",\n",
    "            \"bneck_x_sku_defectProxy.csv\",\n",
    "            \"corr_lag_Warehouse1_Queue_vs_defectProxy.csv\",\n",
    "            \"quantile_trend_Warehouse1_Queue.csv\",\n",
    "            \"risk_summary_Warehouse1_Queue.csv\",\n",
    "            \"stratified_lift_by_QualityUtil.csv\"\n",
    "        ]\n",
    "    },\n",
    "    # 파일 로깅 요약(셀별)\n",
    "    \"file_log\": {k: v for k, v in SAVED_FILES.items()}\n",
    "}\n",
    "\n",
    "save_json(summary, \"SUMMARY.json\", \"cell9\")\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(json.dumps(summary, ensure_ascii=False, indent=2))\n",
    "\n",
    "list_saved(\"cell9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36480a9d-3136-4e75-a8c3-5a3cf9bd256e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853feb50-47e2-4994-95fc-c8c13c4e9ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8449fbdf-ab4e-4651-a21d-01c459336ac9",
   "metadata": {},
   "source": [
    "# 실행 요약 & 인사이트 (RUN_STAMP: `082416`)\n",
    "\n",
    "**출력 폴더:** `./outputs/082416`  \n",
    "**데이터셋:** 132,676행 × 66열(경량 필터 후) / 최종 파생 포함 78열  \n",
    "**SKU:** 1, 2, 3, 4\n",
    "\n",
    "---\n",
    "\n",
    "## 1) 병목(Bottleneck) 개요\n",
    "- **최상위 병목(생산량·리드타임 공통):** `Warehouse1_Queue` → 관측치 77,631건으로 **지배적**.\n",
    "- 그다음: `Forklift_Blanking_Queue`(53,681), `Warehouse_3_Queue`(1,307), `Warehouse_4_Queue` 등.\n",
    "- **리드타임 평균(AGG):**\n",
    "  - `Warehouse1_Queue`: 2.513\n",
    "  - `Forklift_Blanking_Queue`: 2.505\n",
    "  - `Warehouse_3_Queue`: **2.578** (상대적으로 더 길다)\n",
    "\n",
    "> 해석: **창고 1 대기열(W1Q)**이 “가장 자주” 병목이며, **창고 3 대기열**에 걸리면 리드타임이 특히 길어질 가능성.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) 예측 모델 성능(통합 AGG 타깃)\n",
    "- **리드타임**\n",
    "  - RF(HGBR) in-sample \\(R²\\): **0.887**\n",
    "  - Ridge hold-out: **R²=0.581**, RMSE=0.016\n",
    "- **생산량**\n",
    "  - RF(HGBR) in-sample \\(R²\\): **0.988**\n",
    "  - Ridge hold-out: **R²=0.978**, RMSE=169.142\n",
    "\n",
    "> 해석: **생산량 예측력은 매우 높음**. 리드타임은 선형 모델 기준 **중간 수준**(비선형 트리에서는 더 잘 맞지만 과적합 가능성 유의).\n",
    "\n",
    "---\n",
    "\n",
    "## 3) 민감도/탄력도(AGG, 상위 N 특성)\n",
    "- **생산량 ↑에 가장 민감:** `Blanking_Util` **+225.40** (Press1_Util +3.25)\n",
    "- **리드타임 ↓와 강한 연관(음의 기울기):** `Blanking_Util` **−0.673**  \n",
    "  (Press2/3_Util도 완만한 음의 기울기)\n",
    "\n",
    "> 해석: **Blanking 설비 가동률**을 올리면 (상관 기반 추정이지만) **생산량은 크게↑, 리드타임은 단축**되는 신호.  \n",
    "> 주의: FD-기울기는 **국소 상관**이며, **인과**가 아님.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) What-if(단변수 시나리오) 요약\n",
    "- **`Quality_Util` +5** → **생산량 평균 +2,852** (큰 폭 증가), 리드타임 영향 미미\n",
    "- **`Blanking_Queue` −50** → **리드타임 −0.679** (의미 있는 단축), 생산량 영향 미미(−1.86)\n",
    "- **`Warehouse1_Queue` −50** → 리드타임/생산량 **영향 거의 없음**\n",
    "\n",
    "> 해석:  \n",
    "> - **품질 공정 가동률(인력/설비 가용)** 소폭 증대가 **생산량을 유의하게 끌어올릴** 여지.  \n",
    "> - **Blanking 대기열 완화**는 **리드타임 단축**에 효과.  \n",
    "> - **W1Q 단순 감축**은 평균 수준에선 영향이 제한적(구조적 병목이거나 다른 요인 병행 필요).\n",
    "\n",
    "---\n",
    "\n",
    "## 5) 품질 프록시(불량 지표) 인사이트\n",
    "- 전체 평균: **0.511**\n",
    "- **병목별 리프트(표본≥200, 95% CI)**  \n",
    "  - `Warehouse1_Queue`: **+0.0098 (상대 +1.9%)** ★ 유의  \n",
    "  - `Forklift_Blanking_Queue`: **−2.73%** ★ 유의  \n",
    "  - `Warehouse_3_Queue`: −1.38% (비유의)\n",
    "\n",
    "- **SKU별(예: Warehouse1_Queue 병목 vs 비병목)**\n",
    "  - **SKU1:** **+0.0273** (z≈5.14)  \n",
    "  - **SKU3:** **+0.0228** (z≈9.89)  \n",
    "  - **SKU2:** +0.0190, **SKU4:** +0.0183  \n",
    "  → **W1Q 병목일 때 전 SKU에서 불량 프록시 상승**(특히 SKU1/3)\n",
    "\n",
    "- **래그 상관(W1Q ↔ 불량):** Lag 0~+6 범위에서 **≈0.062**로 **작지만 일관된 양(+)의 상관**  \n",
    "  → **W1Q 증가가 동시/약간 미래 시점의 불량 프록시 상승과 동행**.\n",
    "\n",
    "- **분위수 트렌드(W1Q):** 하위→상위 분위수로 **0.488 → 0.538**로 상승.  \n",
    "  **임계치(80%):** **W1Q ≥ 240** → **고위험 그룹 평균 0.532** (vs 0.506)\n",
    "\n",
    "- **층화(Quality_Util 3분위):** low/mid/high 모두에서 **lift ≈ +0.02**로 **일관 상승**\n",
    "\n",
    "> 해석: **W1Q가 높을수록 불량 위험이 커지는 패턴**이 **일관**.  \n",
    "> **W1Q≥240**은 **운영 경보 임계치**로 합리적.\n",
    "\n",
    "---\n",
    "\n",
    "## 6) 실행 제안(체크리스트)\n",
    "1. **창고1 대기열(W1Q) 실시간 경보:** `W1Q ≥ 240` 발생 시  \n",
    "   - 즉시 **품질 게이트 강화**(추가 검사/리워크 라우팅),  \n",
    "   - **SKU1·SKU3 우선 완화**(자원 재배치, 재작업 버퍼 확보).\n",
    "2. **품질 공정 가동률(Quality_Util) +5 구현 테스트:**  \n",
    "   - 인력 증원/교대 재배치/셋업 단축으로 **+2,800 수준 생산량 상향** 기대치 검증(A/B).\n",
    "3. **Blanking 대기열 완화 과제:**  \n",
    "   - 병목 원인(상·하류 싱크, 자재 핸들링, 지게차 배차) 점검 → **리드타임 단축** 효과 검증.\n",
    "4. **W1Q 단순 감축의 한계 보완:**  \n",
    "   - 창고 동선/적치 정책/피킹 규칙 개선 등 **구조적 개선** 병행.\n",
    "5. **모니터링 보드:**  \n",
    "   - `Blanking_Util`, `W1Q`, `Quality_Util`, `Press1_Util`을 **Leading KPI**로 대시보드화,  \n",
    "   - 분위수/임계치 기반 **붉은불 알람**.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) 주의 & 한계\n",
    "- **탄력도/What-if는 상관 기반의 국소 근사**(단변수 FD) → **인과 아님**.  \n",
    "- RF(HGBR) 점수는 **in-sample**. 일반화는 **Ridge 결과**를 우선 참고.  \n",
    "- **경량 모드(열 패턴·행 샘플) 적용** → 운영 반영 전 **전량 데이터/교차검증** 권장.  \n",
    "- 시간 단위/스케일은 원 데이터 정의에 따름(상대 비교·추이 중심 해석 권장).\n",
    "\n",
    "---\n",
    "\n",
    "## 8) 산출물(폴더: `./outputs/082416`)\n",
    "- 병목 요약: `bottleneck_totalProduction.csv`, `bottleneck_aggLeadTime.csv`  \n",
    "- SKU×병목: `sku_bneck_effect_SKU*.csv`  \n",
    "- AGG 계수/표준화계수: `ridge_coef_*_AGG.csv`, `ridge_betaStd_*_AGG.csv`  \n",
    "- 탄력도: `elasticity_leadtime_AGG_fast_lite.csv`, `elasticity_production_AGG_fast_lite.csv`, `elasticity_leadtime_SKU*_fast_lite.csv`  \n",
    "- What-if: `whatif_results.json`  \n",
    "- 품질 프록시 분석:  \n",
    "  `bneck_vs_defectProxy_basic.csv`, `bneck_vs_defectProxy_main_CI.csv`,  \n",
    "  `bneck_x_sku_defectProxy.csv`, `sku_cmp_Warehouse1_Queue.csv`,  \n",
    "  `corr_lag_Warehouse1_Queue_vs_defectProxy.csv`,  \n",
    "  `quantile_trend_Warehouse1_Queue.csv`, `risk_summary_Warehouse1_Queue.csv`,  \n",
    "  `stratified_lift_by_QualityUtil.csv`  \n",
    "- 최종 요약: `SUMMARY.json`\n",
    "\n",
    "> 다음에 보고서를 자동 생성하려면 이 셀의 요약을 그대로 복사해 PowerPoint/Notion에 붙여 넣고,  \n",
    "> 위 CSV/JSON에서 그래프만 추가로 시각화하면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25424ed1-7f9e-49ef-a4ec-5ddef84c24ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ee10d-c3e8-4977-8b98-239a48e55342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb46829-2fe0-493d-8586-cbb7f9721dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0f85f-575b-4a45-9c35-287045e7c473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25083e-40ad-4733-b5c5-47799fc2b995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4336a2-312c-4493-8cbd-042188a5cd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da95930-f061-4852-b1eb-93a3aa05a3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
